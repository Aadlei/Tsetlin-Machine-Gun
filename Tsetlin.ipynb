{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:06.506707Z",
     "start_time": "2025-12-14T18:08:04.657520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Check for NVIDIA GPU\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ NVIDIA GPU detected!\")\n",
    "        print(\"\\nGPU Info:\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"✗ No NVIDIA GPU found\")\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ nvidia-smi not found - no NVIDIA GPU or drivers not installed\")\n",
    "\n",
    "# Check CUDA availability in PyTorch (if you have it)\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nPyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"\\nPyTorch not installed (not needed for GTM)\")"
   ],
   "id": "c0be253d33be751e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ NVIDIA GPU detected!\n",
      "\n",
      "GPU Info:\n",
      "Sun Dec 14 18:08:04 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM3-32GB           On  |   00000000:57:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             49W /  350W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "PyTorch CUDA available: True\n",
      "CUDA device: Tesla V100-SXM3-32GB\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Methods - Optimized Version",
   "id": "4e5dbf9bcd5c3f2d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:07.663242Z",
     "start_time": "2025-12-14T18:08:06.922614Z"
    }
   },
   "source": [
    "from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "from GraphTsetlinMachine.graphs import Graphs\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "NUMBER_OF_CLAUSES = 400\n",
    "T = 2000\n",
    "S = 5.0\n",
    "DEPTH = 8\n",
    "MESSAGE_SIZE = 512\n",
    "MESSAGE_BITS = 2\n",
    "BOARD_DIM = 3\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"Tsetlin.ipynb\"))\n",
    "HEX_DIR = os.path.join(NOTEBOOK_DIR, \"TsetlinMachine/hex\")\n",
    "\n",
    "if not os.path.exists(HEX_DIR):\n",
    "    raise FileNotFoundError(f\"ERROR: Cannot find hex.c at {HEX_DIR}\")\n",
    "\n",
    "print(\"Building hex using make...\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"make\"],\n",
    "        cwd=HEX_DIR,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    print(\"=== Make Output ===\")\n",
    "    print(result.stdout)\n",
    "    if result.stderr.strip():\n",
    "        print(\"=== Make Errors ===\")\n",
    "        print(result.stderr)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n✓ Build successful!\")\n",
    "    else:\n",
    "        print(\"\\n❌ Build failed! See errors above.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Exception when running make:\", e)\n",
    "\n",
    "def c_position_to_node_id(c_position, board_dim=BOARD_DIM):\n",
    "    padded_dim = board_dim + 2\n",
    "    i = c_position // padded_dim\n",
    "    j = c_position % padded_dim\n",
    "    node_id = (i - 1) * board_dim + (j - 1)\n",
    "\n",
    "    if node_id < 0 or node_id >= board_dim * board_dim:\n",
    "        return None\n",
    "    return node_id\n",
    "\n",
    "def get_hex_edges(board_dim=BOARD_DIM):\n",
    "    edges = []\n",
    "    neighbor_offsets = [(0, 1), (0, -1), (-1, 1), (1, -1), (-1, 0), (1, 0)]\n",
    "\n",
    "    for i in range(board_dim):\n",
    "        for j in range(board_dim):\n",
    "            node_id = i * board_dim + j\n",
    "            for di, dj in neighbor_offsets:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < board_dim and 0 <= nj < board_dim:\n",
    "                    neighbor_id = ni * board_dim + nj\n",
    "                    edges.append((node_id, neighbor_id))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def parse_game_output(output):\n",
    "    games = []\n",
    "    current_game = None\n",
    "\n",
    "    for line in output.split('\\n'):\n",
    "        line = line.strip()\n",
    "\n",
    "        if line == \"GAME_START\":\n",
    "            current_game = {'moves': [], 'winner': -1}\n",
    "        elif line.startswith(\"MOVE\"):\n",
    "            if current_game is not None:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 3:\n",
    "                    position = int(parts[1])\n",
    "                    player = int(parts[2])\n",
    "                    current_game['moves'].append((position, player))\n",
    "        elif line.startswith(\"WINNER\"):\n",
    "            if current_game is not None:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    current_game['winner'] = int(parts[1])\n",
    "        elif line == \"GAME_END\":\n",
    "            if current_game and current_game['winner'] != -1:\n",
    "                games.append(current_game)\n",
    "            current_game = None\n",
    "\n",
    "    return games\n",
    "\n",
    "def create_training_data_from_game(moves, winner, board_dim=BOARD_DIM):\n",
    "    \"\"\"\n",
    "    Create ONE training sample per game:\n",
    "      - board_state: final board (0=empty, 1=player0, 2=player1)\n",
    "      - label: winner of the game (0 or 1)\n",
    "\n",
    "    We keep node_features as before for compatibility, but the main\n",
    "    object we care about is the final board_state.\n",
    "    \"\"\"\n",
    "    num_nodes = board_dim * board_dim\n",
    "    board_state = np.zeros(num_nodes, dtype=np.int32)\n",
    "    edges = get_hex_edges(board_dim)  # not used in new Graphs, but kept\n",
    "\n",
    "    # Play through the whole game to get the final board\n",
    "    for c_position, player in moves:\n",
    "        node_id = c_position_to_node_id(c_position, board_dim)\n",
    "        if node_id is None:\n",
    "            print(f\"Skipping invalid move: c_pos={c_position}\")\n",
    "            continue\n",
    "        board_state[node_id] = player + 1  # 1 = player 0, 2 = player 1\n",
    "\n",
    "    # Build node_features from the FINAL full board_state\n",
    "    node_features = np.zeros((num_nodes, 3), dtype=np.int32)\n",
    "    for nid in range(num_nodes):\n",
    "        if board_state[nid] == 1:\n",
    "            node_features[nid, 0] = 1  # player_0 stone\n",
    "        elif board_state[nid] == 2:\n",
    "            node_features[nid, 1] = 1  # player_1 stone\n",
    "        else:\n",
    "            node_features[nid, 2] = 1  # empty\n",
    "\n",
    "    label = int(winner)  # 0 or 1\n",
    "\n",
    "    sample = {\n",
    "        'board_state': board_state.reshape(board_dim, board_dim),\n",
    "        'node_features': node_features,   # still there if you need it\n",
    "        'edges': edges,                   # unused in new Graph building\n",
    "        'position': -1,                   # not used now\n",
    "        'player': -1,                     # not used now\n",
    "        'label': label\n",
    "    }\n",
    "\n",
    "    # Return as a list to match old API\n",
    "    return [sample]\n",
    "\n",
    "\n",
    "def prepare_training_data(games, board_dim=BOARD_DIM):\n",
    "    \"\"\"\n",
    "    Turn a list of games into a list of FINAL-state → winner samples.\n",
    "    Exactly one sample per game.\n",
    "    \"\"\"\n",
    "    all_samples = []\n",
    "\n",
    "    print(f\"Processing {len(games)} games into training samples...\")\n",
    "\n",
    "    # Game-level statistics\n",
    "    player_0_wins = sum(1 for g in games if g['winner'] == 0)\n",
    "    player_1_wins = sum(1 for g in games if g['winner'] == 1)\n",
    "    print(f\"Game outcomes (per game):\")\n",
    "    print(f\"  Player 0 wins: {player_0_wins}\")\n",
    "    print(f\"  Player 1 wins: {player_1_wins}\")\n",
    "\n",
    "    for game in tqdm(games, desc=\"Processing games\"):\n",
    "        samples = create_training_data_from_game(game['moves'], game['winner'], board_dim)\n",
    "        all_samples.extend(samples)\n",
    "\n",
    "    if len(all_samples) == 0:\n",
    "        print(\"ERROR: No training samples created! Check your logic.\")\n",
    "        return all_samples\n",
    "\n",
    "    labels = [s['label'] for s in all_samples]\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"\\nLabel distribution (winner classes, per FINAL board):\")\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"  Winner {label}: {count} games ({count/len(labels)*100:.1f}%)\")\n",
    "\n",
    "    # Quick sanity check of final board states\n",
    "    print(\"\\nSample final board state check (first 5 samples):\")\n",
    "    for i in range(min(5, len(all_samples))):\n",
    "        sample = all_samples[i]\n",
    "        pieces = np.sum(sample['node_features'][:, :2])\n",
    "        empties = np.sum(sample['node_features'][:, 2])\n",
    "        print(f\"  Sample {i}: {pieces} stones, {empties} empty cells, label(winner)={sample['label']}\")\n",
    "\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    return all_samples\n",
    "\n",
    "\n",
    "def generate_game_data(num_games=1000, hex_dir=HEX_DIR):\n",
    "    hex_executable = os.path.join(hex_dir, \"hex\")\n",
    "\n",
    "    if not os.path.exists(hex_executable):\n",
    "        print(f\"Executable not found at {hex_executable}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Generating {num_games} games...\")\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [hex_executable, str(num_games)],\n",
    "            cwd=hex_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=120\n",
    "        )\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error running hex executable:\")\n",
    "            print(result.stderr)\n",
    "            return []\n",
    "\n",
    "        games = parse_game_output(result.stdout)\n",
    "        print(f\"Successfully parsed {len(games)} games from output\")\n",
    "        return games\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running hex executable: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def prepare_gtm_data_multinode(training_samples, board_dim=BOARD_DIM,\n",
    "                                hypervector_size=1024, hypervector_bits=2,\n",
    "                                init_with=None):\n",
    "    \"\"\"\n",
    "    Multi-node graph representation: 121 nodes per graph with Hex connectivity.\n",
    "    Args:\n",
    "        init_with: Optional Graphs object to copy hypervectors from (for evaluation)\n",
    "    \"\"\"\n",
    "    Y = np.array([s['label'] for s in training_samples], dtype=np.int32)\n",
    "    num_graphs = len(training_samples)\n",
    "    num_nodes_per_graph = board_dim * board_dim\n",
    "\n",
    "    symbols = [\"Empty\", \"Player0\", \"Player1\"]\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"CREATING MULTI-NODE GRAPH REPRESENTATION\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Graphs: {num_graphs}, Nodes per graph: {num_nodes_per_graph} ({board_dim}×{board_dim})\")\n",
    "\n",
    "    graphs = Graphs(\n",
    "        num_graphs,\n",
    "        symbols=symbols,\n",
    "        hypervector_size=hypervector_size,\n",
    "        hypervector_bits=hypervector_bits,\n",
    "        init_with=init_with\n",
    "    )\n",
    "\n",
    "    # Hex neighbor offsets\n",
    "    neighbor_offsets = [(0, 1), (0, -1), (-1, 1), (1, -1), (-1, 0), (1, 0)]\n",
    "\n",
    "    # Pre-calculate edges per node (needed for add_graph_node)\n",
    "    edges_per_node = np.zeros(num_nodes_per_graph, dtype=np.uint32)\n",
    "    for i in range(board_dim):\n",
    "        for j in range(board_dim):\n",
    "            node_id = i * board_dim + j\n",
    "            edge_count = sum(1 for di, dj in neighbor_offsets\n",
    "                           if 0 <= i+di < board_dim and 0 <= j+dj < board_dim)\n",
    "            edges_per_node[node_id] = edge_count\n",
    "\n",
    "    # Step 1: Set node counts\n",
    "    print(\"Step 1: Configuring nodes...\")\n",
    "    for graph_id in range(num_graphs):\n",
    "        graphs.set_number_of_graph_nodes(graph_id, num_nodes_per_graph)\n",
    "\n",
    "    graphs.prepare_node_configuration()\n",
    "\n",
    "    # Step 2: Add nodes with edge counts\n",
    "    print(\"Step 2: Adding nodes...\")\n",
    "    for graph_id in range(num_graphs):\n",
    "        for node_id in range(num_nodes_per_graph):\n",
    "            graphs.add_graph_node(graph_id, node_id, edges_per_node[node_id])\n",
    "\n",
    "    graphs.prepare_edge_configuration()\n",
    "\n",
    "    # Step 3: Add edges\n",
    "    print(\"Step 3: Adding edges...\")\n",
    "    for graph_id in range(num_graphs):\n",
    "        for i in range(board_dim):\n",
    "            for j in range(board_dim):\n",
    "                node_id = i * board_dim + j\n",
    "                for di, dj in neighbor_offsets:\n",
    "                    ni, nj = i + di, j + dj\n",
    "                    if 0 <= ni < board_dim and 0 <= nj < board_dim:\n",
    "                        neighbor_id = ni * board_dim + nj\n",
    "                        graphs.add_graph_node_edge(graph_id, node_id, neighbor_id, \"hex_edge\")\n",
    "\n",
    "    # Step 4: Add node properties\n",
    "    print(\"Step 4: Adding properties...\")\n",
    "    for graph_id in range(num_graphs):\n",
    "        node_features = training_samples[graph_id]['node_features']\n",
    "        for node_id in range(num_nodes_per_graph):\n",
    "            if node_features[node_id, 0] == 1:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"Player0\")\n",
    "            elif node_features[node_id, 1] == 1:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"Player1\")\n",
    "            else:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"Empty\")\n",
    "\n",
    "    # Step 5: Encode\n",
    "    print(\"Step 5: Encoding...\")\n",
    "    graphs.encode()\n",
    "\n",
    "    print(f\"✓ Multi-node graphs created!\\n{'='*70}\\n\")\n",
    "    return graphs, Y\n",
    "\n",
    "\n",
    "\n",
    "def train_model(graphs, Y, epochs=100):\n",
    "    \"\"\"Train with hyperparameters from global config\"\"\"\n",
    "    print(\"Initializing Graph Tsetlin Machine...\")\n",
    "    print(f\"  Clauses: {NUMBER_OF_CLAUSES}\")\n",
    "    print(f\"  T: {T}\")\n",
    "    print(f\"  s: {S}\")\n",
    "    print(f\"  Depth: {DEPTH}\")\n",
    "    print(f\"  Message Size: {MESSAGE_SIZE}\")\n",
    "\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        number_of_clauses=NUMBER_OF_CLAUSES,\n",
    "        T=T,\n",
    "        s=S,\n",
    "        number_of_state_bits=8,\n",
    "        depth=DEPTH,\n",
    "        message_size=MESSAGE_SIZE,\n",
    "        message_bits=MESSAGE_BITS,\n",
    "        max_included_literals=32,\n",
    "        grid=(16 * 13, 1, 1),\n",
    "        block=(128, 1, 1)\n",
    "    )\n",
    "\n",
    "    # Class balancing: oversample minority class of winner\n",
    "    class_0_indices = np.where(Y == 0)[0]\n",
    "    class_1_indices = np.where(Y == 1)[0]\n",
    "\n",
    "    print(f\"\\nClass distribution before balancing (winner classes):\")\n",
    "    print(f\"  Winner 0: {len(class_0_indices)} states\")\n",
    "    print(f\"  Winner 1: {len(class_1_indices)} states\")\n",
    "\n",
    "    if len(class_0_indices) > 0 and len(class_1_indices) > 0:\n",
    "        # Balance by repeating minority class\n",
    "        if len(class_0_indices) < len(class_1_indices):\n",
    "            oversample_ratio = len(class_1_indices) // len(class_0_indices)\n",
    "            class_0_indices = np.tile(class_0_indices, oversample_ratio)\n",
    "        else:\n",
    "            oversample_ratio = len(class_0_indices) // len(class_1_indices)\n",
    "            class_1_indices = np.tile(class_1_indices, oversample_ratio)\n",
    "\n",
    "        balanced_indices = np.concatenate([class_0_indices, class_1_indices])\n",
    "        np.random.shuffle(balanced_indices)\n",
    "        print(f\"After balancing: {len(balanced_indices)} total samples\")\n",
    "    else:\n",
    "        balanced_indices = np.arange(len(Y))\n",
    "        print(\"Warning: only one winner class present; no balancing applied.\")\n",
    "\n",
    "    print(f\"\\nStarting training for {epochs} epochs...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    start_total = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        # NOTE: current GTM implementation uses full graph set; balancing\n",
    "        # is mainly informational here. To actually subsample, GTM would need\n",
    "        # support for graph subsets.\n",
    "        tm.fit(graphs, Y, epochs=1, incremental=True)\n",
    "        elapsed = time.time() - start_epoch\n",
    "\n",
    "        predictions = tm.predict(graphs)\n",
    "        accuracy = 100 * (predictions == Y).mean()\n",
    "\n",
    "        class_0_mask = (Y == 0)\n",
    "        class_1_mask = (Y == 1)\n",
    "        class_0_acc = 100 * (predictions[class_0_mask] == 0).mean() if class_0_mask.any() else 0\n",
    "        class_1_acc = 100 * (predictions[class_1_mask] == 1).mean() if class_1_mask.any() else 0\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Acc: {accuracy:.2f}% \"\n",
    "              f\"(Winner 0 states: {class_0_acc:.1f}%, Winner 1 states: {class_1_acc:.1f}%) - {elapsed:.2f}s\")\n",
    "\n",
    "    total_time = time.time() - start_total\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"✓ Training completed in {total_time:.2f}s ({total_time/60:.2f} minutes)\")\n",
    "\n",
    "    print(\"\\nFinal Evaluation...\")\n",
    "    predictions = tm.predict(graphs)\n",
    "\n",
    "    accuracy = 100 * (predictions == Y).mean()\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    for class_id in [0, 1]:\n",
    "        mask = Y == class_id\n",
    "        if mask.any():\n",
    "            class_acc = 100 * (predictions[mask] == class_id).mean()\n",
    "            print(f\"Winner {class_id} states: {class_acc:.2f}% \"\n",
    "                  f\"({(predictions[mask] == class_id).sum()}/{mask.sum()})\")\n",
    "\n",
    "    return tm, predictions\n",
    "\n",
    "def save_model(tm, filepath=\"TsetlinMachine/hex_tm_model.pkl\",\n",
    "               board_dim=11, additional_info=None):\n",
    "    \"\"\"Save trained model with metadata\"\"\"\n",
    "    print(f\"Saving model to {filepath}...\")\n",
    "\n",
    "    state_dict = tm.save(fname=filepath)\n",
    "\n",
    "    print(f\"✓ Model saved successfully to {filepath}\")\n",
    "    return state_dict"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building hex using make...\n",
      "=== Make Output ===\n",
      "make: 'hex' is up to date.\n",
      "\n",
      "\n",
      "✓ Build successful!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Game Data\n",
    "\n",
    "Run this cell to generate Hex games and create training samples."
   ],
   "id": "generate_data_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:08.196363Z",
     "start_time": "2025-12-14T18:08:07.750827Z"
    }
   },
   "source": [
    "# Generate games\n",
    "NUM_GAMES = 10000\n",
    "\n",
    "print(f\"Generating {NUM_GAMES} Hex games...\")\n",
    "games = generate_game_data(NUM_GAMES)\n",
    "\n",
    "if not games:\n",
    "    raise Exception(\"No games generated! Check hex executable.\")\n",
    "\n",
    "print(f\"\\n✓ Successfully generated {len(games)} games\")\n",
    "\n",
    "# Process into training samples (FINAL state -> winner)\n",
    "training_samples = prepare_training_data(games, BOARD_DIM)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC: Checking final board states:\")\n",
    "print(\"=\"*60)\n",
    "for i in range(min(10, len(training_samples))):\n",
    "    sample = training_samples[i]\n",
    "    non_zero = np.sum(sample['node_features'][:, :2])  # Count player pieces\n",
    "    empty = np.sum(sample['node_features'][:, 2])      # Count empty cells\n",
    "    print(f\"Sample {i}: {non_zero} stones on board, {empty} empty cells, label(winner)={sample['label']}\")\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(f\"\\n✓ Training data ready: {len(training_samples)} samples\")\n"
   ],
   "id": "generate_data_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 Hex games...\n",
      "Generating 10000 games...\n",
      "Successfully parsed 10000 games from output\n",
      "\n",
      "✓ Successfully generated 10000 games\n",
      "Processing 10000 games into training samples...\n",
      "Game outcomes (per game):\n",
      "  Player 0 wins: 6676\n",
      "  Player 1 wins: 3324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games: 100%|██████████| 10000/10000 [00:00<00:00, 29120.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution (winner classes, per FINAL board):\n",
      "  Winner 0: 6676 games (66.8%)\n",
      "  Winner 1: 3324 games (33.2%)\n",
      "\n",
      "Sample final board state check (first 5 samples):\n",
      "  Sample 0: 9 stones, 0 empty cells, label(winner)=0\n",
      "  Sample 1: 7 stones, 2 empty cells, label(winner)=0\n",
      "  Sample 2: 7 stones, 2 empty cells, label(winner)=0\n",
      "  Sample 3: 7 stones, 2 empty cells, label(winner)=0\n",
      "  Sample 4: 9 stones, 0 empty cells, label(winner)=0\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "DIAGNOSTIC: Checking final board states:\n",
      "============================================================\n",
      "Sample 0: 9 stones on board, 0 empty cells, label(winner)=0\n",
      "Sample 1: 7 stones on board, 2 empty cells, label(winner)=0\n",
      "Sample 2: 7 stones on board, 2 empty cells, label(winner)=0\n",
      "Sample 3: 7 stones on board, 2 empty cells, label(winner)=0\n",
      "Sample 4: 9 stones on board, 0 empty cells, label(winner)=0\n",
      "Sample 5: 7 stones on board, 2 empty cells, label(winner)=0\n",
      "Sample 6: 9 stones on board, 0 empty cells, label(winner)=0\n",
      "Sample 7: 6 stones on board, 3 empty cells, label(winner)=1\n",
      "Sample 8: 6 stones on board, 3 empty cells, label(winner)=1\n",
      "Sample 9: 9 stones on board, 0 empty cells, label(winner)=0\n",
      "============================================================\n",
      "\n",
      "\n",
      "✓ Training data ready: 10000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Graph Tsetlin Machine\n",
    "\n",
    "Convert training samples into the GTM Graphs format."
   ],
   "id": "prepare_gtm_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:13.147653Z",
     "start_time": "2025-12-14T18:08:08.220002Z"
    }
   },
   "source": [
    "graphs, Y = prepare_gtm_data_multinode(\n",
    "    training_samples,\n",
    "    board_dim=BOARD_DIM,\n",
    "    hypervector_size=1024,\n",
    "    hypervector_bits=2\n",
    ")"
   ],
   "id": "prepare_gtm_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING MULTI-NODE GRAPH REPRESENTATION\n",
      "======================================================================\n",
      "  Graphs: 10000, Nodes per graph: 9 (3×3)\n",
      "Step 1: Configuring nodes...\n",
      "Step 2: Adding nodes...\n",
      "Step 3: Adding edges...\n",
      "Step 4: Adding properties...\n",
      "Step 5: Encoding...\n",
      "✓ Multi-node graphs created!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Graph Tsetlin Machine\n",
    "\n",
    "Train the model on the prepared graph data."
   ],
   "id": "train_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:13.214725Z",
     "start_time": "2025-12-14T18:08:13.212718Z"
    }
   },
   "source": "#tm, predictions = train_model(graphs, Y, epochs=50)",
   "id": "train_cell",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:13.226702Z",
     "start_time": "2025-12-14T18:08:13.223268Z"
    }
   },
   "cell_type": "code",
   "source": "#save_model(tm=tm, filepath=\"TsetlinMachine/hex_tm_model.pkl\", board_dim=BOARD_DIM, additional_info=None)",
   "id": "12a00a1c579f4d95",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Trained Model (Optional)\n",
    "\n",
    "Use this to load a previously trained model."
   ],
   "id": "load_model_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:13.238112Z",
     "start_time": "2025-12-14T18:08:13.236561Z"
    }
   },
   "source": "",
   "id": "load_model_cell",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:13.305350Z",
     "start_time": "2025-12-14T18:08:13.244791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "\n",
    "def evaluate_model(model_path=\"TsetlinMachine/hex_tm_model.pkl\",\n",
    "                   num_test_games=100000, verbose=True):\n",
    "    \"\"\"Complete model evaluation\"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"MODEL EVALUATION\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "    # Generate test data\n",
    "    if verbose:\n",
    "        print(f\"\\nGenerating {num_test_games} test games...\")\n",
    "    test_games = generate_game_data(num_test_games)\n",
    "\n",
    "    test_samples = []\n",
    "    for g in test_games:\n",
    "        samples = create_training_data_from_game(g[\"moves\"], g[\"winner\"], BOARD_DIM)\n",
    "        test_samples.extend(samples)\n",
    "\n",
    "    Y_test = np.array([s[\"label\"] for s in test_samples], dtype=np.int32)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"✓ Created {len(test_samples)} test samples\")\n",
    "        print(f\"  Winner 0: {np.sum(Y_test==0)}, Winner 1: {np.sum(Y_test==1)}\")\n",
    "\n",
    "    # Prepare graphs\n",
    "    if verbose:\n",
    "        print(f\"Preparing multi-node graphs for evaluation...\")\n",
    "\n",
    "    graphs_test, _ = prepare_gtm_data_multinode(\n",
    "        test_samples,\n",
    "        board_dim=BOARD_DIM,\n",
    "        hypervector_size=1024,\n",
    "        hypervector_bits=2,\n",
    "        init_with=graphs\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"✓ Graphs prepared\\nMaking predictions...\")\n",
    "\n",
    "    # Predict\n",
    "    predictions = tm.predict(graphs_test).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    overall_acc = 100 * (predictions == Y_test).mean()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RESULTS - {len(test_samples)} samples from {num_test_games} games\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nOverall Accuracy: {overall_acc:.2f}%\")\n",
    "\n",
    "    # Per-class accuracy\n",
    "    for winner in [0, 1]:\n",
    "        mask = Y_test == winner\n",
    "        if mask.any():\n",
    "            acc = 100 * (predictions[mask] == winner).mean()\n",
    "            correct = (predictions[mask] == winner).sum()\n",
    "            total = mask.sum()\n",
    "            print(f\"Winner {winner} Accuracy: {acc:.2f}% ({correct}/{total})\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(Y_test, predictions)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"              Predicted\")\n",
    "    print(f\"              0      1\")\n",
    "    print(f\"Actual  0  [{cm[0,0]:4d}  {cm[0,1]:4d}]\")\n",
    "    print(f\"        1  [{cm[1,0]:4d}  {cm[1,1]:4d}]\")\n",
    "\n",
    "    # Additional metrics\n",
    "    p0 = precision_score(Y_test, predictions, pos_label=0, zero_division=0)\n",
    "    r0 = recall_score(Y_test, predictions, pos_label=0, zero_division=0)\n",
    "    f1_0 = f1_score(Y_test, predictions, pos_label=0, zero_division=0)\n",
    "\n",
    "    p1 = precision_score(Y_test, predictions, pos_label=1, zero_division=0)\n",
    "    r1 = recall_score(Y_test, predictions, pos_label=1, zero_division=0)\n",
    "    f1_1 = f1_score(Y_test, predictions, pos_label=1, zero_division=0)\n",
    "\n",
    "    print(f\"\\nDetailed Metrics:\")\n",
    "    print(f\"  Winner 0: Precision={p0:.3f}, Recall={r0:.3f}, F1={f1_0:.3f}\")\n",
    "    print(f\"  Winner 1: Precision={p1:.3f}, Recall={r1:.3f}, F1={f1_1:.3f}\")\n",
    "\n",
    "    return {\n",
    "        'accuracy': overall_acc,\n",
    "        'predictions': predictions,\n",
    "        'labels': Y_test,\n",
    "        'confusion_matrix': cm,\n",
    "        'metrics': {'p0': p0, 'r0': r0, 'f1_0': f1_0, 'p1': p1, 'r1': r1, 'f1_1': f1_1}\n",
    "    }"
   ],
   "id": "5feccd4e2254f885",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:13.314540Z",
     "start_time": "2025-12-14T18:08:13.312413Z"
    }
   },
   "cell_type": "code",
   "source": "#results = evaluate_model(num_test_games=100000)\n",
   "id": "2a5fa0dfa43a2d2d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiments and Scenarios",
   "id": "c05dda3572274adf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:08:14.444846Z",
     "start_time": "2025-12-14T18:08:13.323931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Configuration\n",
    "BOARD_DIM = 3\n",
    "TRAIN_GAMES = 10000\n",
    "TEST_GAMES = 10000\n",
    "EPOCHS = 50\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"3×3 HEX GTM EXPERIMENTS: MODEL CAPACITY & DEPTH ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Board Size: {BOARD_DIM}×{BOARD_DIM}\")\n",
    "print(f\"  Training Games: {TRAIN_GAMES:,}\")\n",
    "print(f\"  Test Games: {TEST_GAMES:,}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[1/2] Generating training data...\")\n",
    "train_games = generate_game_data(TRAIN_GAMES)\n",
    "train_samples = prepare_training_data(train_games, BOARD_DIM)\n",
    "Y_train_label = np.array([s['label'] for s in train_samples], dtype=np.int32)\n",
    "\n",
    "print(f\"✓ Training samples: {len(train_samples)}\")\n",
    "print(f\"  Winner 0: {np.sum(Y_train_label==0)} ({100*np.mean(Y_train_label==0):.1f}%)\")\n",
    "print(f\"  Winner 1: {np.sum(Y_train_label==1)} ({100*np.mean(Y_train_label==1):.1f}%)\")\n",
    "\n",
    "print(\"\\n[2/2] Generating test data...\")\n",
    "test_games = generate_game_data(TEST_GAMES)\n",
    "test_samples = prepare_training_data(test_games, BOARD_DIM)\n",
    "Y_test = np.array([s['label'] for s in test_samples], dtype=np.int32)\n",
    "\n",
    "print(f\"✓ Test samples: {len(test_samples)}\")\n",
    "print(f\"  Winner 0: {np.sum(Y_test==0)} ({100*np.mean(Y_test==0):.1f}%)\")\n",
    "print(f\"  Winner 1: {np.sum(Y_test==1)} ({100*np.mean(Y_test==1):.1f}%)\")\n",
    "\n",
    "print(\"\\n✓ Data generation complete!\")"
   ],
   "id": "9321842959add1c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "3×3 HEX GTM EXPERIMENTS: MODEL CAPACITY & DEPTH ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  Board Size: 3×3\n",
      "  Training Games: 10,000\n",
      "  Test Games: 10,000\n",
      "  Epochs: 50\n",
      "======================================================================\n",
      "\n",
      "[1/2] Generating training data...\n",
      "Generating 10000 games...\n",
      "Successfully parsed 10000 games from output\n",
      "Processing 10000 games into training samples...\n",
      "Game outcomes (per game):\n",
      "  Player 0 wins: 6676\n",
      "  Player 1 wins: 3324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games: 100%|██████████| 10000/10000 [00:00<00:00, 28048.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution (winner classes, per FINAL board):\n",
      "  Winner 0: 6676 games (66.8%)\n",
      "  Winner 1: 3324 games (33.2%)\n",
      "\n",
      "Sample final board state check (first 5 samples):\n",
      "  Sample 0: 9 stones, 0 empty cells, label(winner)=0\n",
      "  Sample 1: 7 stones, 2 empty cells, label(winner)=0\n",
      "  Sample 2: 7 stones, 2 empty cells, label(winner)=0\n",
      "  Sample 3: 7 stones, 2 empty cells, label(winner)=0\n",
      "  Sample 4: 9 stones, 0 empty cells, label(winner)=0\n",
      "============================================================\n",
      "\n",
      "✓ Training samples: 10000\n",
      "  Winner 0: 6676 (66.8%)\n",
      "  Winner 1: 3324 (33.2%)\n",
      "\n",
      "[2/2] Generating test data...\n",
      "Generating 10000 games...\n",
      "Successfully parsed 10000 games from output\n",
      "Processing 10000 games into training samples...\n",
      "Game outcomes (per game):\n",
      "  Player 0 wins: 6676\n",
      "  Player 1 wins: 3324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games: 100%|██████████| 10000/10000 [00:00<00:00, 28453.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution (winner classes, per FINAL board):\n",
      "  Winner 0: 6676 games (66.8%)\n",
      "  Winner 1: 3324 games (33.2%)\n",
      "\n",
      "Sample final board state check (first 5 samples):\n",
      "  Sample 0: 9 stones, 0 empty cells, label(winner)=0\n",
      "  Sample 1: 7 stones, 2 empty cells, label(winner)=0\n",
      "  Sample 2: 7 stones, 2 empty cells, label(winner)=0\n",
      "  Sample 3: 7 stones, 2 empty cells, label(winner)=0\n",
      "  Sample 4: 9 stones, 0 empty cells, label(winner)=0\n",
      "============================================================\n",
      "\n",
      "✓ Test samples: 10000\n",
      "  Winner 0: 6676 (66.8%)\n",
      "  Winner 1: 3324 (33.2%)\n",
      "\n",
      "✓ Data generation complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-14T18:08:14.482042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 2: MODEL CAPACITY (CLAUSE COUNT)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Experiment configurations\n",
    "exp2_configs = [\n",
    "    {\"name\": \"Minimal\", \"clauses\": 100, \"T\": 500},\n",
    "    {\"name\": \"Small\", \"clauses\": 200, \"T\": 1000},\n",
    "    {\"name\": \"Medium\", \"clauses\": 400, \"T\": 2000},\n",
    "    {\"name\": \"Large\", \"clauses\": 800, \"T\": 4000},\n",
    "    {\"name\": \"XLarge\", \"clauses\": 1600, \"T\": 8000},\n",
    "]\n",
    "\n",
    "# Fixed parameters\n",
    "EXP2_DEPTH = 8\n",
    "EXP2_S = 5.0\n",
    "EXP2_MSG_SIZE = 512\n",
    "\n",
    "exp2_results = []\n",
    "exp2_predictions = []\n",
    "exp2_learning_curves = []\n",
    "\n",
    "for config in exp2_configs:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Running: {config['name']} - {config['clauses']} clauses, T={config['T']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Prepare graphs\n",
    "    print(\"  Preparing graphs...\")\n",
    "    graphs_train, Y_train = prepare_gtm_data_multinode(\n",
    "        train_samples,\n",
    "        board_dim=BOARD_DIM,\n",
    "        hypervector_size=1024,\n",
    "        hypervector_bits=2\n",
    "    )\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # Initialize model\n",
    "    print(f\"  Initializing GTM ({config['clauses']} clauses)...\")\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        number_of_clauses=config['clauses'],\n",
    "        T=config['T'],\n",
    "        s=EXP2_S,\n",
    "        depth=EXP2_DEPTH,\n",
    "        message_size=EXP2_MSG_SIZE,\n",
    "        message_bits=2\n",
    "    )\n",
    "\n",
    "    # Training with epoch tracking\n",
    "    print(f\"  Training for {EPOCHS} epochs...\")\n",
    "    epoch_history = []\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS), desc=\"  Progress\"):\n",
    "        tm.fit(graphs_train, Y_train, epochs=1, incremental=True)\n",
    "\n",
    "        # Evaluate on training set\n",
    "        preds_train = tm.predict(graphs_train)\n",
    "        train_acc = 100 * (preds_train == Y_train).mean()\n",
    "\n",
    "        # Per-class accuracy\n",
    "        class_0_mask = Y_train == 0\n",
    "        class_1_mask = Y_train == 1\n",
    "        class_0_acc = 100 * (preds_train[class_0_mask] == 0).mean() if class_0_mask.any() else 0\n",
    "        class_1_acc = 100 * (preds_train[class_1_mask] == 1).mean() if class_1_mask.any() else 0\n",
    "\n",
    "        epoch_history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_acc': train_acc,\n",
    "            'class_0_acc': class_0_acc,\n",
    "            'class_1_acc': class_1_acc,\n",
    "            'gap': abs(class_0_acc - class_1_acc)\n",
    "        })\n",
    "\n",
    "    # Prepare test graphs\n",
    "    print(\"  Preparing test graphs...\")\n",
    "    graphs_test, _ = prepare_gtm_data_multinode(\n",
    "        test_samples,\n",
    "        board_dim=BOARD_DIM,\n",
    "        init_with=graphs_train  # CRITICAL\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"  Evaluating on test set...\")\n",
    "    test_preds = tm.predict(graphs_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_acc = 100 * accuracy_score(Y_test, test_preds)\n",
    "    test_class_0_acc = 100 * (test_preds[Y_test==0] == 0).mean()\n",
    "    test_class_1_acc = 100 * (test_preds[Y_test==1] == 1).mean()\n",
    "\n",
    "    # Classification report\n",
    "    precision_0 = precision_score(Y_test, test_preds, pos_label=0, zero_division=0)\n",
    "    recall_0 = recall_score(Y_test, test_preds, pos_label=0, zero_division=0)\n",
    "    f1_0 = f1_score(Y_test, test_preds, pos_label=0, zero_division=0)\n",
    "\n",
    "    precision_1 = precision_score(Y_test, test_preds, pos_label=1, zero_division=0)\n",
    "    recall_1 = recall_score(Y_test, test_preds, pos_label=1, zero_division=0)\n",
    "    f1_1 = f1_score(Y_test, test_preds, pos_label=1, zero_division=0)\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Store results\n",
    "    result = {\n",
    "        'experiment': config['name'],\n",
    "        'clauses': config['clauses'],\n",
    "        'T': config['T'],\n",
    "        'depth': EXP2_DEPTH,\n",
    "        's': EXP2_S,\n",
    "        'test_acc': test_acc,\n",
    "        'test_class_0_acc': test_class_0_acc,\n",
    "        'test_class_1_acc': test_class_1_acc,\n",
    "        'class_gap': abs(test_class_0_acc - test_class_1_acc),\n",
    "        'precision_0': precision_0,\n",
    "        'recall_0': recall_0,\n",
    "        'f1_0': f1_0,\n",
    "        'precision_1': precision_1,\n",
    "        'recall_1': recall_1,\n",
    "        'f1_1': f1_1,\n",
    "        'training_time_sec': training_time,\n",
    "        'epoch_history': epoch_history\n",
    "    }\n",
    "\n",
    "    exp2_results.append(result)\n",
    "    exp2_predictions.append(test_preds)\n",
    "    exp2_learning_curves.append(pd.DataFrame(epoch_history))\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n  Results Summary:\")\n",
    "    print(f\"    Training Time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"    Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"    Winner 0: {test_class_0_acc:.2f}% (P={precision_0:.3f}, R={recall_0:.3f}, F1={f1_0:.3f})\")\n",
    "    print(f\"    Winner 1: {test_class_1_acc:.2f}% (P={precision_1:.3f}, R={recall_1:.3f}, F1={f1_1:.3f})\")\n",
    "    print(f\"    Class Gap: {abs(test_class_0_acc - test_class_1_acc):.2f}%\")\n",
    "\n",
    "print(\"\\n✓ Experiment 2 complete!\")"
   ],
   "id": "c6d8d6c596c4b171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPERIMENT 2: MODEL CAPACITY (CLAUSE COUNT)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Running: Minimal - 100 clauses, T=500\n",
      "======================================================================\n",
      "  Preparing graphs...\n",
      "\n",
      "======================================================================\n",
      "CREATING MULTI-NODE GRAPH REPRESENTATION\n",
      "======================================================================\n",
      "  Graphs: 10000, Nodes per graph: 9 (3×3)\n",
      "Step 1: Configuring nodes...\n",
      "Step 2: Adding nodes...\n",
      "Step 3: Adding edges...\n",
      "Step 4: Adding properties...\n",
      "Step 5: Encoding...\n",
      "✓ Multi-node graphs created!\n",
      "======================================================================\n",
      "\n",
      "  Initializing GTM (100 clauses)...\n",
      "Initialization of sparse structure.\n",
      "  Training for 50 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Progress:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 3: MESSAGE PASSING DEPTH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Experiment configurations\n",
    "exp3_configs = [\n",
    "    {\"name\": \"NoMP\", \"depth\": 1},\n",
    "    {\"name\": \"Shallow\", \"depth\": 3},\n",
    "    {\"name\": \"Medium\", \"depth\": 5},\n",
    "    {\"name\": \"Deep\", \"depth\": 8},\n",
    "    {\"name\": \"VeryDeep\", \"depth\": 12},\n",
    "]\n",
    "\n",
    "# Fixed parameters\n",
    "EXP3_CLAUSES = 400\n",
    "EXP3_T = 2000\n",
    "EXP3_S = 5.0\n",
    "EXP3_MSG_SIZE = 512\n",
    "\n",
    "exp3_results = []\n",
    "exp3_predictions = []\n",
    "exp3_learning_curves = []\n",
    "\n",
    "for config in exp3_configs:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Running: {config['name']} - Depth={config['depth']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Prepare graphs\n",
    "    print(\"  Preparing graphs...\")\n",
    "    graphs_train, Y_train = prepare_gtm_data_multinode(\n",
    "        train_samples,\n",
    "        board_dim=BOARD_DIM,\n",
    "        hypervector_size=1024,\n",
    "        hypervector_bits=2\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    print(f\"  Initializing GTM (depth={config['depth']})...\")\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        number_of_clauses=EXP3_CLAUSES,\n",
    "        T=EXP3_T,\n",
    "        s=EXP3_S,\n",
    "        depth=config['depth'],\n",
    "        message_size=EXP3_MSG_SIZE,\n",
    "        message_bits=2\n",
    "    )\n",
    "\n",
    "    # Training with epoch tracking\n",
    "    print(f\"  Training for {EPOCHS} epochs...\")\n",
    "    epoch_history = []\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS), desc=\"  Progress\"):\n",
    "        tm.fit(graphs_train, Y_train, epochs=1, incremental=True)\n",
    "\n",
    "        # Evaluate on training set\n",
    "        preds_train = tm.predict(graphs_train)\n",
    "        train_acc = 100 * (preds_train == Y_train).mean()\n",
    "\n",
    "        # Per-class accuracy\n",
    "        class_0_mask = Y_train == 0\n",
    "        class_1_mask = Y_train == 1\n",
    "        class_0_acc = 100 * (preds_train[class_0_mask] == 0).mean() if class_0_mask.any() else 0\n",
    "        class_1_acc = 100 * (preds_train[class_1_mask] == 1).mean() if class_1_mask.any() else 0\n",
    "\n",
    "        epoch_history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_acc': train_acc,\n",
    "            'class_0_acc': class_0_acc,\n",
    "            'class_1_acc': class_1_acc,\n",
    "            'gap': abs(class_0_acc - class_1_acc)\n",
    "        })\n",
    "\n",
    "    # Prepare test graphs\n",
    "    print(\"  Preparing test graphs...\")\n",
    "    graphs_test, _ = prepare_gtm_data_multinode(\n",
    "        test_samples,\n",
    "        board_dim=BOARD_DIM,\n",
    "        init_with=graphs_train  # CRITICAL\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"  Evaluating on test set...\")\n",
    "    test_preds = tm.predict(graphs_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_acc = 100 * accuracy_score(Y_test, test_preds)\n",
    "    test_class_0_acc = 100 * (test_preds[Y_test==0] == 0).mean()\n",
    "    test_class_1_acc = 100 * (test_preds[Y_test==1] == 1).mean()\n",
    "\n",
    "    # Classification metrics\n",
    "    precision_0 = precision_score(Y_test, test_preds, pos_label=0, zero_division=0)\n",
    "    recall_0 = recall_score(Y_test, test_preds, pos_label=0, zero_division=0)\n",
    "    f1_0 = f1_score(Y_test, test_preds, pos_label=0, zero_division=0)\n",
    "\n",
    "    precision_1 = precision_score(Y_test, test_preds, pos_label=1, zero_division=0)\n",
    "    recall_1 = recall_score(Y_test, test_preds, pos_label=1, zero_division=0)\n",
    "    f1_1 = f1_score(Y_test, test_preds, pos_label=1, zero_division=0)\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Store results\n",
    "    result = {\n",
    "        'experiment': config['name'],\n",
    "        'depth': config['depth'],\n",
    "        'clauses': EXP3_CLAUSES,\n",
    "        'T': EXP3_T,\n",
    "        's': EXP3_S,\n",
    "        'test_acc': test_acc,\n",
    "        'test_class_0_acc': test_class_0_acc,\n",
    "        'test_class_1_acc': test_class_1_acc,\n",
    "        'class_gap': abs(test_class_0_acc - test_class_1_acc),\n",
    "        'precision_0': precision_0,\n",
    "        'recall_0': recall_0,\n",
    "        'f1_0': f1_0,\n",
    "        'precision_1': precision_1,\n",
    "        'recall_1': recall_1,\n",
    "        'f1_1': f1_1,\n",
    "        'training_time_sec': training_time,\n",
    "        'epoch_history': epoch_history\n",
    "    }\n",
    "\n",
    "    exp3_results.append(result)\n",
    "    exp3_predictions.append(test_preds)\n",
    "    exp3_learning_curves.append(pd.DataFrame(epoch_history))\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n  Results Summary:\")\n",
    "    print(f\"    Training Time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"    Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"    Winner 0: {test_class_0_acc:.2f}% (P={precision_0:.3f}, R={recall_0:.3f}, F1={f1_0:.3f})\")\n",
    "    print(f\"    Winner 1: {test_class_1_acc:.2f}% (P={precision_1:.3f}, R={recall_1:.3f}, F1={f1_1:.3f})\")\n",
    "    print(f\"    Class Gap: {abs(test_class_0_acc - test_class_1_acc):.2f}%\")\n",
    "\n",
    "print(\"\\n✓ Experiment 3 complete!\")"
   ],
   "id": "56638b06c39841de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[EXPERIMENT 2: MODEL CAPACITY]\")\n",
    "print(\"-\" * 70)\n",
    "exp2_df = pd.DataFrame([{\n",
    "    'Config': r['experiment'],\n",
    "    'Clauses': r['clauses'],\n",
    "    'T': r['T'],\n",
    "    'Test Acc (%)': f\"{r['test_acc']:.2f}\",\n",
    "    'Winner 0 (%)': f\"{r['test_class_0_acc']:.2f}\",\n",
    "    'Winner 1 (%)': f\"{r['test_class_1_acc']:.2f}\",\n",
    "    'Gap (%)': f\"{r['class_gap']:.2f}\",\n",
    "    'Time (min)': f\"{r['training_time_sec']/60:.1f}\"\n",
    "} for r in exp2_results])\n",
    "print(exp2_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n[EXPERIMENT 3: MESSAGE PASSING DEPTH]\")\n",
    "print(\"-\" * 70)\n",
    "exp3_df = pd.DataFrame([{\n",
    "    'Config': r['experiment'],\n",
    "    'Depth': r['depth'],\n",
    "    'Test Acc (%)': f\"{r['test_acc']:.2f}\",\n",
    "    'Winner 0 (%)': f\"{r['test_class_0_acc']:.2f}\",\n",
    "    'Winner 1 (%)': f\"{r['test_class_1_acc']:.2f}\",\n",
    "    'Gap (%)': f\"{r['class_gap']:.2f}\",\n",
    "    'Time (min)': f\"{r['training_time_sec']/60:.1f}\"\n",
    "} for r in exp3_results])\n",
    "print(exp3_df.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 6: DETAILED METRICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[EXPERIMENT 2: MODEL CAPACITY - DETAILED METRICS]\")\n",
    "print(\"-\" * 70)\n",
    "for result in exp2_results:\n",
    "    print(f\"\\n{result['experiment']} ({result['clauses']} clauses, T={result['T']}):\")\n",
    "    print(f\"  Overall Accuracy: {result['test_acc']:.2f}%\")\n",
    "    print(f\"  Winner 0: Precision={result['precision_0']:.3f}, Recall={result['recall_0']:.3f}, F1={result['f1_0']:.3f}\")\n",
    "    print(f\"  Winner 1: Precision={result['precision_1']:.3f}, Recall={result['recall_1']:.3f}, F1={result['f1_1']:.3f}\")\n",
    "\n",
    "print(\"\\n[EXPERIMENT 3: MESSAGE PASSING DEPTH - DETAILED METRICS]\")\n",
    "print(\"-\" * 70)\n",
    "for result in exp3_results:\n",
    "    print(f\"\\n{result['experiment']} (Depth={result['depth']}):\")\n",
    "    print(f\"  Overall Accuracy: {result['test_acc']:.2f}%\")\n",
    "    print(f\"  Winner 0: Precision={result['precision_0']:.3f}, Recall={result['recall_0']:.3f}, F1={result['f1_0']:.3f}\")\n",
    "    print(f\"  Winner 1: Precision={result['precision_1']:.3f}, Recall={result['recall_1']:.3f}, F1={result['f1_1']:.3f}\")\n",
    "\n"
   ],
   "id": "c2104860dac36933",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nGenerating learning curves...\")\n",
    "\n",
    "# Experiment 2\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (result, curve) in enumerate(zip(exp2_results, exp2_learning_curves)):\n",
    "    if idx >= 6:\n",
    "        break\n",
    "\n",
    "    axes[idx].plot(curve['epoch'], curve['train_acc'],\n",
    "                  label='Overall', linewidth=2.5, color='black')\n",
    "    axes[idx].plot(curve['epoch'], curve['class_0_acc'],\n",
    "                  label='Winner 0', linestyle='--', linewidth=2, color='blue')\n",
    "    axes[idx].plot(curve['epoch'], curve['class_1_acc'],\n",
    "                  label='Winner 1', linestyle='--', linewidth=2, color='red')\n",
    "\n",
    "    axes[idx].set_title(f\"{result['experiment']}\\n{result['clauses']} clauses, T={result['T']}\",\n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Epoch', fontsize=10)\n",
    "    axes[idx].set_ylabel('Training Accuracy (%)', fontsize=10)\n",
    "    axes[idx].legend(fontsize=9)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].set_ylim([0, 105])\n",
    "\n",
    "if len(exp2_results) < 6:\n",
    "    axes[5].axis('off')\n",
    "\n",
    "plt.suptitle('Experiment 2: Learning Curves (Model Capacity)',\n",
    "            fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('exp2_learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved exp2_learning_curves.png\")\n",
    "plt.show()\n",
    "\n",
    "# Experiment 3\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (result, curve) in enumerate(zip(exp3_results, exp3_learning_curves)):\n",
    "    if idx >= 6:\n",
    "        break\n",
    "\n",
    "    axes[idx].plot(curve['epoch'], curve['train_acc'],\n",
    "                  label='Overall', linewidth=2.5, color='black')\n",
    "    axes[idx].plot(curve['epoch'], curve['class_0_acc'],\n",
    "                  label='Winner 0', linestyle='--', linewidth=2, color='blue')\n",
    "    axes[idx].plot(curve['epoch'], curve['class_1_acc'],\n",
    "                  label='Winner 1', linestyle='--', linewidth=2, color='red')\n",
    "\n",
    "    axes[idx].set_title(f\"{result['experiment']}\\nDepth={result['depth']}\",\n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Epoch', fontsize=10)\n",
    "    axes[idx].set_ylabel('Training Accuracy (%)', fontsize=10)\n",
    "    axes[idx].legend(fontsize=9)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].set_ylim([0, 105])\n",
    "\n",
    "if len(exp3_results) < 6:\n",
    "    axes[5].axis('off')\n",
    "\n",
    "plt.suptitle('Experiment 3: Learning Curves (Message Passing Depth)',\n",
    "            fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('exp3_learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved exp3_learning_curves.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 8: VISUALIZATIONS - CONFUSION MATRICES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nGenerating confusion matrices...\")\n",
    "\n",
    "# Experiment 2\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (result, preds) in enumerate(zip(exp2_results, exp2_predictions)):\n",
    "    if idx >= 6:\n",
    "        break\n",
    "\n",
    "    cm = confusion_matrix(Y_test, preds)\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               ax=axes[idx], cbar=False, annot_kws={'size': 14})\n",
    "\n",
    "    axes[idx].set_title(f\"{result['experiment']}\\n{result['clauses']} clauses\\nAcc: {result['test_acc']:.1f}%\",\n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Predicted Winner', fontsize=10)\n",
    "    axes[idx].set_ylabel('Actual Winner', fontsize=10)\n",
    "\n",
    "if len(exp2_results) < 6:\n",
    "    axes[5].axis('off')\n",
    "\n",
    "plt.suptitle('Experiment 2: Confusion Matrices (Model Capacity)',\n",
    "            fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('exp2_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved exp2_confusion_matrices.png\")\n",
    "plt.show()\n",
    "\n",
    "# Experiment 3\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (result, preds) in enumerate(zip(exp3_results, exp3_predictions)):\n",
    "    if idx >= 6:\n",
    "        break\n",
    "\n",
    "    cm = confusion_matrix(Y_test, preds)\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
    "               ax=axes[idx], cbar=False, annot_kws={'size': 14})\n",
    "\n",
    "    axes[idx].set_title(f\"{result['experiment']}\\nDepth={result['depth']}\\nAcc: {result['test_acc']:.1f}%\",\n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Predicted Winner', fontsize=10)\n",
    "    axes[idx].set_ylabel('Actual Winner', fontsize=10)\n",
    "\n",
    "if len(exp3_results) < 6:\n",
    "    axes[5].axis('off')\n",
    "\n",
    "plt.suptitle('Experiment 3: Confusion Matrices (Message Passing Depth)',\n",
    "            fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('exp3_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved exp3_confusion_matrices.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 9: VISUALIZATIONS - COMPARISON PLOTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nGenerating comparison plots...\")\n",
    "\n",
    "# Experiment 2: Accuracy vs Clauses\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "clauses = [r['clauses'] for r in exp2_results]\n",
    "test_accs = [r['test_acc'] for r in exp2_results]\n",
    "class_0_accs = [r['test_class_0_acc'] for r in exp2_results]\n",
    "class_1_accs = [r['test_class_1_acc'] for r in exp2_results]\n",
    "\n",
    "ax1.plot(clauses, test_accs, marker='o', linewidth=2.5, markersize=10,\n",
    "        color='darkgreen', label='Overall')\n",
    "ax1.set_xlabel('Number of Clauses', fontsize=12)\n",
    "ax1.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('Overall Accuracy vs Model Capacity', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "ax2.plot(clauses, class_0_accs, marker='o', linewidth=2.5, markersize=10,\n",
    "        color='blue', label='Winner 0')\n",
    "ax2.plot(clauses, class_1_accs, marker='s', linewidth=2.5, markersize=10,\n",
    "        color='red', label='Winner 1')\n",
    "ax2.fill_between(clauses, class_0_accs, class_1_accs, alpha=0.2, color='gray')\n",
    "ax2.set_xlabel('Number of Clauses', fontsize=12)\n",
    "ax2.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Per-Class Accuracy vs Model Capacity', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('exp2_capacity_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved exp2_capacity_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# Experiment 3: Accuracy vs Depth\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "depths = [r['depth'] for r in exp3_results]\n",
    "test_accs = [r['test_acc'] for r in exp3_results]\n",
    "class_0_accs = [r['test_class_0_acc'] for r in exp3_results]\n",
    "class_1_accs = [r['test_class_1_acc'] for r in exp3_results]\n",
    "\n",
    "ax1.plot(depths, test_accs, marker='o', linewidth=2.5, markersize=10,\n",
    "        color='purple', label='Overall')\n",
    "ax1.set_xlabel('Message Passing Depth', fontsize=12)\n",
    "ax1.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('Overall Accuracy vs Depth', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axvline(x=3, color='gray', linestyle='--', alpha=0.5, label='Min Required (3)')\n",
    "ax1.legend(fontsize=10)\n",
    "\n",
    "ax2.plot(depths, class_0_accs, marker='o', linewidth=2.5, markersize=10,\n",
    "        color='blue', label='Winner 0')\n",
    "ax2.plot(depths, class_1_accs, marker='s', linewidth=2.5, markersize=10,\n",
    "        color='red', label='Winner 1')\n",
    "ax2.fill_between(depths, class_0_accs, class_1_accs, alpha=0.2, color='gray')\n",
    "ax2.set_xlabel('Message Passing Depth', fontsize=12)\n",
    "ax2.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Per-Class Accuracy vs Depth', fontsize=13, fontweight='bold')\n",
    "ax2.axvline(x=3, color='gray', linestyle='--', alpha=0.5, label='Min Required (3)')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('exp3_depth_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved exp3_depth_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 10: VISUALIZATIONS - CLASS GAP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nGenerating class gap comparison...\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Experiment 2\n",
    "gaps_exp2 = [r['class_gap'] for r in exp2_results]\n",
    "names_exp2 = [r['experiment'] for r in exp2_results]\n",
    "\n",
    "ax1.bar(range(len(gaps_exp2)), gaps_exp2, color='coral', alpha=0.7,\n",
    "       edgecolor='darkred', linewidth=2)\n",
    "ax1.set_xlabel('Configuration', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy Gap (%)', fontsize=12)\n",
    "ax1.set_title('Exp 2: Winner 0 vs Winner 1 Gap\\n(Lower is Better)',\n",
    "             fontsize=13, fontweight='bold')\n",
    "ax1.set_xticks(range(len(names_exp2)))\n",
    "ax1.set_xticklabels(names_exp2, rotation=45, ha='right')\n",
    "ax1.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Experiment 3\n",
    "gaps_exp3 = [r['class_gap'] for r in exp3_results]\n",
    "names_exp3 = [r['experiment'] for r in exp3_results]\n",
    "\n",
    "ax2.bar(range(len(gaps_exp3)), gaps_exp3, color='lightblue', alpha=0.7,\n",
    "       edgecolor='darkblue', linewidth=2)\n",
    "ax2.set_xlabel('Configuration', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy Gap (%)', fontsize=12)\n",
    "ax2.set_title('Exp 3: Winner 0 vs Winner 1 Gap\\n(Lower is Better)',\n",
    "             fontsize=13, fontweight='bold')\n",
    "ax2.set_xticks(range(len(names_exp3)))\n",
    "ax2.set_xticklabels(names_exp3, rotation=45, ha='right')\n",
    "ax2.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_gap_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved class_gap_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 11: SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nSaving results...\")\n",
    "\n",
    "# Save CSV\n",
    "exp2_df.to_csv('exp2_results.csv', index=False)\n",
    "exp3_df.to_csv('exp3_results.csv', index=False)\n",
    "print(\"  ✓ Saved exp2_results.csv\")\n",
    "print(\"  ✓ Saved exp3_results.csv\")\n",
    "\n",
    "# Save JSON\n",
    "all_results = {\n",
    "    'experiment_2_capacity': exp2_results,\n",
    "    'experiment_3_depth': exp3_results,\n",
    "    'configuration': {\n",
    "        'board_dim': BOARD_DIM,\n",
    "        'train_games': TRAIN_GAMES,\n",
    "        'test_games': TEST_GAMES,\n",
    "        'epochs': EPOCHS\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('experiments_results.json', 'w') as f:\n",
    "    json.dump(all_results, f, indent=2, default=str)\n",
    "print(\"  ✓ Saved experiments_results.json\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 12: BEST CONFIGURATIONS SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "# Find best configurations\n",
    "best_exp2 = max(exp2_results, key=lambda x: x['test_acc'])\n",
    "best_exp3 = max(exp3_results, key=lambda x: x['test_acc'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST CONFIGURATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[EXPERIMENT 2: MODEL CAPACITY]\")\n",
    "print(f\"  Best Config: {best_exp2['experiment']}\")\n",
    "print(f\"  Clauses: {best_exp2['clauses']}, T: {best_exp2['T']}\")\n",
    "print(f\"  Test Accuracy: {best_exp2['test_acc']:.2f}%\")\n",
    "print(f\"  Winner 0: {best_exp2['test_class_0_acc']:.2f}%\")\n",
    "print(f\"  Winner 1: {best_exp2['test_class_1_acc']:.2f}%\")\n",
    "print(f\"  Class Gap: {best_exp2['class_gap']:.2f}%\")\n",
    "\n",
    "print(\"\\n[EXPERIMENT 3: MESSAGE PASSING DEPTH]\")\n",
    "print(f\"  Best Config: {best_exp3['experiment']}\")\n",
    "print(f\"  Depth: {best_exp3['depth']}\")\n",
    "print(f\"  Test Accuracy: {best_exp3['test_acc']:.2f}%\")\n",
    "print(f\"  Winner 0: {best_exp3['test_class_0_acc']:.2f}%\")\n",
    "print(f\"  Winner 1: {best_exp3['test_class_1_acc']:.2f}%\")\n",
    "print(f\"  Class Gap: {best_exp3['class_gap']:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENTS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  Learning Curves:\")\n",
    "print(\"    - exp2_learning_curves.png\")\n",
    "print(\"    - exp3_learning_curves.png\")\n",
    "print(\"  Confusion Matrices:\")\n",
    "print(\"    - exp2_confusion_matrices.png\")\n",
    "print(\"    - exp3_confusion_matrices.png\")\n",
    "print(\"  Comparison Plots:\")\n",
    "print(\"    - exp2_capacity_comparison.png\")\n",
    "print(\"    - exp3_depth_comparison.png\")\n",
    "print(\"    - class_gap_comparison.png\")\n",
    "print(\"  Data Files:\")\n",
    "print(\"    - exp2_results.csv\")\n",
    "print(\"    - exp3_results.csv\")\n",
    "print(\"    - experiments_results.json\")\n",
    "print(\"\\n✓ All experiments completed successfully!\")\n",
    "print(\"✓ Ready for report writing!\")"
   ],
   "id": "73b9cd265e4591cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
