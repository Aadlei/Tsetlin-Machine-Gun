{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Methods - Optimized Version",
   "id": "4e5dbf9bcd5c3f2d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T16:18:03.881923Z",
     "start_time": "2025-12-05T16:18:03.846693Z"
    }
   },
   "source": [
    "from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "from GraphTsetlinMachine.graphs import Graphs\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "BOARD_DIM = 11\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"Tsetlin.ipynb\"))\n",
    "HEX_DIR = os.path.join(NOTEBOOK_DIR, \"TsetlinMachine/hex\")\n",
    "\n",
    "if not os.path.exists(HEX_DIR):\n",
    "    raise FileNotFoundError(f\"ERROR: Cannot find hex.c at {HEX_DIR}\")\n",
    "\n",
    "print(\"Building hex using make...\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"make\"],\n",
    "        cwd=HEX_DIR,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    print(\"=== Make Output ===\")\n",
    "    print(result.stdout)\n",
    "    if result.stderr.strip():\n",
    "        print(\"=== Make Errors ===\")\n",
    "        print(result.stderr)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n✓ Build successful!\")\n",
    "    else:\n",
    "        print(\"\\n❌ Build failed! See errors above.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Exception when running make:\", e)\n",
    "\n",
    "def c_position_to_node_id(c_position, board_dim=BOARD_DIM):\n",
    "    padded_dim = board_dim + 2\n",
    "    i = c_position // padded_dim\n",
    "    j = c_position % padded_dim\n",
    "    node_id = (i - 1) * board_dim + (j - 1)\n",
    "\n",
    "    if node_id < 0 or node_id >= board_dim * board_dim:\n",
    "        return None\n",
    "    return node_id\n",
    "\n",
    "def get_hex_edges(board_dim=BOARD_DIM):\n",
    "    edges = []\n",
    "    neighbor_offsets = [(0, 1), (0, -1), (-1, 1), (1, -1), (-1, 0), (1, 0)]\n",
    "\n",
    "    for i in range(board_dim):\n",
    "        for j in range(board_dim):\n",
    "            node_id = i * board_dim + j\n",
    "            for di, dj in neighbor_offsets:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < board_dim and 0 <= nj < board_dim:\n",
    "                    neighbor_id = ni * board_dim + nj\n",
    "                    edges.append((node_id, neighbor_id))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def parse_game_output(output):\n",
    "    games = []\n",
    "    current_game = None\n",
    "\n",
    "    for line in output.split('\\n'):\n",
    "        line = line.strip()\n",
    "\n",
    "        if line == \"GAME_START\":\n",
    "            current_game = {'moves': [], 'winner': -1}\n",
    "        elif line.startswith(\"MOVE\"):\n",
    "            if current_game is not None:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 3:\n",
    "                    position = int(parts[1])\n",
    "                    player = int(parts[2])\n",
    "                    current_game['moves'].append((position, player))\n",
    "        elif line.startswith(\"WINNER\"):\n",
    "            if current_game is not None:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    current_game['winner'] = int(parts[1])\n",
    "        elif line == \"GAME_END\":\n",
    "            if current_game and current_game['winner'] != -1:\n",
    "                games.append(current_game)\n",
    "            current_game = None\n",
    "\n",
    "    return games\n",
    "\n",
    "def create_training_data_from_game(moves, winner, board_dim=BOARD_DIM):\n",
    "    \"\"\"\n",
    "    Create ONE training sample per game:\n",
    "      - board_state: final board (0=empty, 1=player0, 2=player1)\n",
    "      - label: winner of the game (0 or 1)\n",
    "\n",
    "    We keep node_features as before for compatibility, but the main\n",
    "    object we care about is the final board_state.\n",
    "    \"\"\"\n",
    "    num_nodes = board_dim * board_dim\n",
    "    board_state = np.zeros(num_nodes, dtype=np.int32)\n",
    "    edges = get_hex_edges(board_dim)  # not used in new Graphs, but kept\n",
    "\n",
    "    # Play through the whole game to get the final board\n",
    "    for c_position, player in moves:\n",
    "        node_id = c_position_to_node_id(c_position, board_dim)\n",
    "        if node_id is None:\n",
    "            print(f\"Skipping invalid move: c_pos={c_position}\")\n",
    "            continue\n",
    "        board_state[node_id] = player + 1  # 1 = player 0, 2 = player 1\n",
    "\n",
    "    # Build node_features from the FINAL full board_state\n",
    "    node_features = np.zeros((num_nodes, 3), dtype=np.int32)\n",
    "    for nid in range(num_nodes):\n",
    "        if board_state[nid] == 1:\n",
    "            node_features[nid, 0] = 1  # player_0 stone\n",
    "        elif board_state[nid] == 2:\n",
    "            node_features[nid, 1] = 1  # player_1 stone\n",
    "        else:\n",
    "            node_features[nid, 2] = 1  # empty\n",
    "\n",
    "    label = int(winner)  # 0 or 1\n",
    "\n",
    "    sample = {\n",
    "        'board_state': board_state.reshape(board_dim, board_dim),\n",
    "        'node_features': node_features,   # still there if you need it\n",
    "        'edges': edges,                   # unused in new Graph building\n",
    "        'position': -1,                   # not used now\n",
    "        'player': -1,                     # not used now\n",
    "        'label': label\n",
    "    }\n",
    "\n",
    "    # Return as a list to match old API\n",
    "    return [sample]\n",
    "\n",
    "\n",
    "def prepare_training_data(games, board_dim=BOARD_DIM):\n",
    "    \"\"\"\n",
    "    Turn a list of games into a list of FINAL-state → winner samples.\n",
    "    Exactly one sample per game.\n",
    "    \"\"\"\n",
    "    all_samples = []\n",
    "\n",
    "    print(f\"Processing {len(games)} games into training samples...\")\n",
    "\n",
    "    # Game-level statistics\n",
    "    player_0_wins = sum(1 for g in games if g['winner'] == 0)\n",
    "    player_1_wins = sum(1 for g in games if g['winner'] == 1)\n",
    "    print(f\"Game outcomes (per game):\")\n",
    "    print(f\"  Player 0 wins: {player_0_wins}\")\n",
    "    print(f\"  Player 1 wins: {player_1_wins}\")\n",
    "\n",
    "    for game in tqdm(games, desc=\"Processing games\"):\n",
    "        samples = create_training_data_from_game(game['moves'], game['winner'], board_dim)\n",
    "        all_samples.extend(samples)\n",
    "\n",
    "    if len(all_samples) == 0:\n",
    "        print(\"ERROR: No training samples created! Check your logic.\")\n",
    "        return all_samples\n",
    "\n",
    "    labels = [s['label'] for s in all_samples]\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"\\nLabel distribution (winner classes, per FINAL board):\")\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"  Winner {label}: {count} games ({count/len(labels)*100:.1f}%)\")\n",
    "\n",
    "    # Quick sanity check of final board states\n",
    "    print(\"\\nSample final board state check (first 5 samples):\")\n",
    "    for i in range(min(5, len(all_samples))):\n",
    "        sample = all_samples[i]\n",
    "        pieces = np.sum(sample['node_features'][:, :2])\n",
    "        empties = np.sum(sample['node_features'][:, 2])\n",
    "        print(f\"  Sample {i}: {pieces} stones, {empties} empty cells, label(winner)={sample['label']}\")\n",
    "\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    return all_samples\n",
    "\n",
    "\n",
    "def generate_game_data(num_games=1000, hex_dir=HEX_DIR):\n",
    "    hex_executable = os.path.join(hex_dir, \"hex\")\n",
    "\n",
    "    if not os.path.exists(hex_executable):\n",
    "        print(f\"Executable not found at {hex_executable}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Generating {num_games} games...\")\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [hex_executable, str(num_games)],\n",
    "            cwd=hex_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=120\n",
    "        )\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error running hex executable:\")\n",
    "            print(result.stderr)\n",
    "            return []\n",
    "\n",
    "        games = parse_game_output(result.stdout)\n",
    "        print(f\"Successfully parsed {len(games)} games from output\")\n",
    "        return games\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running hex executable: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def prepare_gtm_data(training_samples, board_dim=BOARD_DIM,\n",
    "                     hypervector_size=1024, hypervector_bits=2):\n",
    "    \"\"\"\n",
    "    Build a Graphs object where each board cell is a node, etc...\n",
    "    \"\"\"\n",
    "    from GraphTsetlinMachine.graphs import Graphs\n",
    "\n",
    "    Y = np.array([s['label'] for s in training_samples], dtype=np.int32)\n",
    "\n",
    "    num_graphs = len(training_samples)\n",
    "    num_nodes = board_dim * board_dim\n",
    "\n",
    "    symbols = ['player_0', 'player_1', 'empty']\n",
    "\n",
    "    print(\"Creating multi-node Hex Graphs object...\")\n",
    "    print(f\"  Number of graphs: {num_graphs}\")\n",
    "    print(f\"  Nodes per graph: {num_nodes} ({board_dim} x {board_dim})\")\n",
    "    # 🔧 avoid printing the whole object, just its length\n",
    "    print(f\"  Number of symbols: {len(symbols)}\")\n",
    "    print(f\"  Hypervector size: {hypervector_size}, bits: {hypervector_bits}\")\n",
    "\n",
    "    graphs, Y = prepare_gtm_data(\n",
    "        training_samples,\n",
    "        board_dim=BOARD_DIM,\n",
    "        hypervector_size=hypervector_size,\n",
    "        hypervector_bits=hypervector_bits\n",
    "    )\n",
    "\n",
    "    # 1) Set number of nodes\n",
    "    print(\"Step 1: Setting number of nodes per graph...\")\n",
    "    for graph_id in tqdm(range(num_graphs), desc=\"Setting nodes\"):\n",
    "        graphs.set_number_of_graph_nodes(graph_id, num_nodes)\n",
    "\n",
    "    # 2) Node configuration\n",
    "    print(\"Step 2: Preparing node configuration...\")\n",
    "    graphs.prepare_node_configuration()\n",
    "\n",
    "    # 3) Add nodes with edge counts\n",
    "    print(\"Step 3: Adding nodes with edge counts...\")\n",
    "    hex_edges = get_hex_edges(board_dim)\n",
    "\n",
    "    edge_counts = np.zeros(num_nodes, dtype=np.uint32)\n",
    "    for src, _ in hex_edges:\n",
    "        edge_counts[src] += 1\n",
    "\n",
    "    for graph_id in tqdm(range(num_graphs), desc=\"Adding nodes\"):\n",
    "        for node_id in range(num_nodes):\n",
    "            graphs.add_graph_node(graph_id, node_id, int(edge_counts[node_id]))\n",
    "\n",
    "    # 4) Edge configuration\n",
    "    print(\"Step 4: Preparing edge configuration...\")\n",
    "    graphs.prepare_edge_configuration()\n",
    "\n",
    "    # 5) Add edges\n",
    "    print(\"Step 5: Adding edges...\")\n",
    "    edge_type_name = \"hex_neighbor\"\n",
    "    if edge_type_name not in graphs.edge_type_id:\n",
    "        graphs.edge_type_id[edge_type_name] = len(graphs.edge_type_id)\n",
    "    edge_type_id = graphs.edge_type_id[edge_type_name]\n",
    "\n",
    "    edge_data = [(src, dst, edge_type_id) for (src, dst) in hex_edges]\n",
    "\n",
    "    for graph_id in tqdm(range(num_graphs), desc=\"Populating edges\"):\n",
    "        node_index = graphs.node_index[graph_id]\n",
    "\n",
    "        for src_node_id, dest_node_id, etype in edge_data:\n",
    "            base = graphs.edge_index[node_index + src_node_id]\n",
    "            offset = graphs.graph_node_edge_counter[node_index + src_node_id]\n",
    "            edge_idx = base + offset\n",
    "\n",
    "            graphs.edge[edge_idx][0] = dest_node_id\n",
    "            graphs.edge[edge_idx][1] = etype\n",
    "            graphs.graph_node_edge_counter[node_index + src_node_id] += 1\n",
    "\n",
    "    # 6) Add node properties\n",
    "    print(\"Step 6: Adding node properties (stone occupancy)...\")\n",
    "    for graph_id in tqdm(range(num_graphs), desc=\"Adding properties\"):\n",
    "        node_features = training_samples[graph_id]['node_features']\n",
    "        for node_id in range(num_nodes):\n",
    "            if node_features[node_id, 0] == 1:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"player_0\")\n",
    "            elif node_features[node_id, 1] == 1:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"player_1\")\n",
    "            else:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"empty\")\n",
    "\n",
    "    # 7) Encode graphs\n",
    "    print(\"Step 7: Encoding graphs...\")\n",
    "    graphs.encode()\n",
    "\n",
    "    print(f\"\\n✓ Prepared {num_graphs} multi-node Hex graphs\")\n",
    "    unique_labels, label_counts = np.unique(Y, return_counts=True)\n",
    "    label_dist = \", \".join([f\"Winner {lab}={cnt}\" for lab, cnt in zip(unique_labels, label_counts)])\n",
    "    print(f\"  Label distribution: {label_dist}\")\n",
    "\n",
    "    return graphs, Y\n",
    "\n",
    "\n",
    "\n",
    "def train_model(graphs, Y, epochs=100):\n",
    "    \"\"\"\n",
    "    Train a MultiClassGraphTsetlinMachine to predict the WINNER (0 or 1)\n",
    "    from a given board state.\n",
    "    \"\"\"\n",
    "    NUMBER_OF_CLAUSES = 3000\n",
    "    T = 25000\n",
    "    S = 10.0\n",
    "    DEPTH = 3\n",
    "    MESSAGE_SIZE = 128\n",
    "    MESSAGE_BITS = 2\n",
    "\n",
    "    print(\"Initializing Graph Tsetlin Machine...\")\n",
    "    print(f\"  Clauses: {NUMBER_OF_CLAUSES}\")\n",
    "    print(f\"  T: {T}\")\n",
    "    print(f\"  s: {S}\")\n",
    "    print(f\"  Depth: {DEPTH}\")\n",
    "    print(f\"  Message Size: {MESSAGE_SIZE}\")\n",
    "\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        number_of_clauses=NUMBER_OF_CLAUSES,\n",
    "        T=T,\n",
    "        s=S,\n",
    "        number_of_state_bits=8,\n",
    "        depth=DEPTH,\n",
    "        message_size=MESSAGE_SIZE,\n",
    "        message_bits=MESSAGE_BITS,\n",
    "        max_included_literals=32,\n",
    "        grid=(16 * 13, 1, 1),\n",
    "        block=(128, 1, 1)\n",
    "    )\n",
    "\n",
    "    # Class balancing: oversample minority class of winner\n",
    "    class_0_indices = np.where(Y == 0)[0]\n",
    "    class_1_indices = np.where(Y == 1)[0]\n",
    "\n",
    "    print(f\"\\nClass distribution before balancing (winner classes):\")\n",
    "    print(f\"  Winner 0: {len(class_0_indices)} states\")\n",
    "    print(f\"  Winner 1: {len(class_1_indices)} states\")\n",
    "\n",
    "    if len(class_0_indices) > 0 and len(class_1_indices) > 0:\n",
    "        # Balance by repeating minority class\n",
    "        if len(class_0_indices) < len(class_1_indices):\n",
    "            oversample_ratio = len(class_1_indices) // len(class_0_indices)\n",
    "            class_0_indices = np.tile(class_0_indices, oversample_ratio)\n",
    "        else:\n",
    "            oversample_ratio = len(class_0_indices) // len(class_1_indices)\n",
    "            class_1_indices = np.tile(class_1_indices, oversample_ratio)\n",
    "\n",
    "        balanced_indices = np.concatenate([class_0_indices, class_1_indices])\n",
    "        np.random.shuffle(balanced_indices)\n",
    "        print(f\"After balancing: {len(balanced_indices)} total samples\")\n",
    "    else:\n",
    "        balanced_indices = np.arange(len(Y))\n",
    "        print(\"Warning: only one winner class present; no balancing applied.\")\n",
    "\n",
    "    print(f\"\\nStarting training for {epochs} epochs...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    start_total = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        # NOTE: current GTM implementation uses full graph set; balancing\n",
    "        # is mainly informational here. To actually subsample, GTM would need\n",
    "        # support for graph subsets.\n",
    "        tm.fit(graphs, Y, epochs=1, incremental=True)\n",
    "        elapsed = time.time() - start_epoch\n",
    "\n",
    "        predictions = tm.predict(graphs)\n",
    "        accuracy = 100 * (predictions == Y).mean()\n",
    "\n",
    "        class_0_mask = (Y == 0)\n",
    "        class_1_mask = (Y == 1)\n",
    "        class_0_acc = 100 * (predictions[class_0_mask] == 0).mean() if class_0_mask.any() else 0\n",
    "        class_1_acc = 100 * (predictions[class_1_mask] == 1).mean() if class_1_mask.any() else 0\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Acc: {accuracy:.2f}% \"\n",
    "              f\"(Winner 0 states: {class_0_acc:.1f}%, Winner 1 states: {class_1_acc:.1f}%) - {elapsed:.2f}s\")\n",
    "\n",
    "    total_time = time.time() - start_total\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"✓ Training completed in {total_time:.2f}s ({total_time/60:.2f} minutes)\")\n",
    "\n",
    "    print(\"\\nFinal Evaluation...\")\n",
    "    predictions = tm.predict(graphs)\n",
    "\n",
    "    accuracy = 100 * (predictions == Y).mean()\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    for class_id in [0, 1]:\n",
    "        mask = Y == class_id\n",
    "        if mask.any():\n",
    "            class_acc = 100 * (predictions[mask] == class_id).mean()\n",
    "            print(f\"Winner {class_id} states: {class_acc:.2f}% \"\n",
    "                  f\"({(predictions[mask] == class_id).sum()}/{mask.sum()})\")\n",
    "\n",
    "    return tm, predictions\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building hex using make...\n",
      "=== Make Output ===\n",
      "make: 'hex' is up to date.\n",
      "\n",
      "\n",
      "✓ Build successful!\n"
     ]
    }
   ],
   "execution_count": 316
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Game Data\n",
    "\n",
    "Run this cell to generate Hex games and create training samples."
   ],
   "id": "generate_data_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:18:04.540662Z",
     "start_time": "2025-12-05T16:18:03.934070Z"
    }
   },
   "source": [
    "# Generate games\n",
    "NUM_GAMES = 1000  # Adjust as needed\n",
    "\n",
    "print(f\"Generating {NUM_GAMES} Hex games...\")\n",
    "games = generate_game_data(NUM_GAMES)\n",
    "\n",
    "if not games:\n",
    "    raise Exception(\"No games generated! Check hex executable.\")\n",
    "\n",
    "print(f\"\\n✓ Successfully generated {len(games)} games\")\n",
    "\n",
    "# Process into training samples (FINAL state -> winner)\n",
    "training_samples = prepare_training_data(games, BOARD_DIM)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC: Checking final board states:\")\n",
    "print(\"=\"*60)\n",
    "for i in range(min(10, len(training_samples))):\n",
    "    sample = training_samples[i]\n",
    "    non_zero = np.sum(sample['node_features'][:, :2])  # Count player pieces\n",
    "    empty = np.sum(sample['node_features'][:, 2])      # Count empty cells\n",
    "    print(f\"Sample {i}: {non_zero} stones on board, {empty} empty cells, label(winner)={sample['label']}\")\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(f\"\\n✓ Training data ready: {len(training_samples)} samples\")\n"
   ],
   "id": "generate_data_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1000 Hex games...\n",
      "Generating 1000 games...\n",
      "Successfully parsed 1000 games from output\n",
      "\n",
      "✓ Successfully generated 1000 games\n",
      "Processing 1000 games into training samples...\n",
      "Game outcomes (per game):\n",
      "  Player 0 wins: 505\n",
      "  Player 1 wins: 495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games: 100%|██████████| 1000/1000 [00:00<00:00, 2336.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution (winner classes, per FINAL board):\n",
      "  Winner 0: 505 games (50.5%)\n",
      "  Winner 1: 495 games (49.5%)\n",
      "\n",
      "Sample final board state check (first 5 samples):\n",
      "  Sample 0: 116 stones, 5 empty cells, label(winner)=1\n",
      "  Sample 1: 115 stones, 6 empty cells, label(winner)=0\n",
      "  Sample 2: 108 stones, 13 empty cells, label(winner)=1\n",
      "  Sample 3: 115 stones, 6 empty cells, label(winner)=0\n",
      "  Sample 4: 112 stones, 9 empty cells, label(winner)=1\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "DIAGNOSTIC: Checking final board states:\n",
      "============================================================\n",
      "Sample 0: 116 stones on board, 5 empty cells, label(winner)=1\n",
      "Sample 1: 115 stones on board, 6 empty cells, label(winner)=0\n",
      "Sample 2: 108 stones on board, 13 empty cells, label(winner)=1\n",
      "Sample 3: 115 stones on board, 6 empty cells, label(winner)=0\n",
      "Sample 4: 112 stones on board, 9 empty cells, label(winner)=1\n",
      "Sample 5: 111 stones on board, 10 empty cells, label(winner)=0\n",
      "Sample 6: 102 stones on board, 19 empty cells, label(winner)=1\n",
      "Sample 7: 106 stones on board, 15 empty cells, label(winner)=1\n",
      "Sample 8: 109 stones on board, 12 empty cells, label(winner)=0\n",
      "Sample 9: 120 stones on board, 1 empty cells, label(winner)=1\n",
      "============================================================\n",
      "\n",
      "\n",
      "✓ Training data ready: 1000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 317
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Graph Tsetlin Machine\n",
    "\n",
    "Convert training samples into the GTM Graphs format."
   ],
   "id": "prepare_gtm_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:18:04.993172Z",
     "start_time": "2025-12-05T16:18:04.561133Z"
    }
   },
   "source": [
    "from GraphTsetlinMachine.graphs import Graphs\n",
    "\n",
    "# Extract labels (winner 0/1 per FINAL board)\n",
    "Y = np.array([s['label'] for s in training_samples], dtype=np.uint32)\n",
    "\n",
    "print(\"Preparing data in GTM Graphs format (MNIST-style)...\")\n",
    "\n",
    "# --- Define symbols: one for each (player, cell) ---\n",
    "\n",
    "symbols = []\n",
    "for i in range(BOARD_DIM):\n",
    "    for j in range(BOARD_DIM):\n",
    "        symbols.append(f\"P0_{i}_{j}\")  # player 0 stone at (i,j)\n",
    "        symbols.append(f\"P1_{i}_{j}\")  # player 1 stone at (i,j)\n",
    "\n",
    "num_nodes = 1  # ONE node per graph, just like 'Image Node' in MNIST example\n",
    "\n",
    "graphs = Graphs(\n",
    "    number_of_graphs=len(training_samples),\n",
    "    symbols=symbols,\n",
    "    hypervector_size=1024,\n",
    "    hypervector_bits=2,\n",
    "    double_hashing=False,\n",
    "    # one_hot_encoding=False by default unless you want one-hot\n",
    ")\n",
    "\n",
    "print(\"Step 1: Setting number of nodes for each graph to 1...\")\n",
    "for graph_id in range(len(training_samples)):\n",
    "    graphs.set_number_of_graph_nodes(graph_id, num_nodes)\n",
    "\n",
    "print(\"Step 2: Preparing node configuration...\")\n",
    "graphs.prepare_node_configuration()\n",
    "\n",
    "print(\"Step 3: Adding the single 'Board' node to each graph...\")\n",
    "for graph_id in range(len(training_samples)):\n",
    "    number_of_outgoing_edges = 0  # we don't use edges here\n",
    "    graphs.add_graph_node(graph_id, 'Board', number_of_outgoing_edges)\n",
    "\n",
    "print(\"Step 4: Preparing edge configuration (no edges, but required call)...\")\n",
    "graphs.prepare_edge_configuration()\n",
    "\n",
    "print(\"Step 5: Adding node properties based on FINAL board state...\")\n",
    "\n",
    "for graph_id in range(len(training_samples)):\n",
    "    if graph_id % 1000 == 0:\n",
    "        print(f\"  Processing graph {graph_id}/{len(training_samples)}\")\n",
    "\n",
    "    # node_features: shape (board_dim^2, 3)\n",
    "    node_features = training_samples[graph_id]['node_features']\n",
    "\n",
    "    for node_id in range(BOARD_DIM * BOARD_DIM):\n",
    "        i = node_id // BOARD_DIM\n",
    "        j = node_id % BOARD_DIM\n",
    "\n",
    "        if node_features[node_id, 0] == 1:\n",
    "            # Player 0 stone at (i,j)\n",
    "            graphs.add_graph_node_property(graph_id, 'Board', f\"P0_{i}_{j}\")\n",
    "        elif node_features[node_id, 1] == 1:\n",
    "            # Player 1 stone at (i,j)\n",
    "            graphs.add_graph_node_property(graph_id, 'Board', f\"P1_{i}_{j}\")\n",
    "        # empty cells add no property\n",
    "\n",
    "print(\"Step 6: Encoding graphs...\")\n",
    "graphs.encode()\n",
    "\n",
    "print(f\"\\n✓ Prepared {len(training_samples)} graphs\")\n",
    "print(f\"  Nodes per graph: {num_nodes}\")\n",
    "print(f\"  Symbols per graph node: up to {BOARD_DIM*BOARD_DIM*2} (stones only)\")\n",
    "unique_labels, label_counts = np.unique(Y, return_counts=True)\n",
    "label_dist = \", \".join([f\"Winner {label}={count}\" for label, count in zip(unique_labels, label_counts)])\n",
    "print(f\"  Label distribution: {label_dist}\")\n"
   ],
   "id": "prepare_gtm_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data in GTM Graphs format (MNIST-style)...\n",
      "Step 1: Setting number of nodes for each graph to 1...\n",
      "Step 2: Preparing node configuration...\n",
      "Step 3: Adding the single 'Board' node to each graph...\n",
      "Step 4: Preparing edge configuration (no edges, but required call)...\n",
      "Step 5: Adding node properties based on FINAL board state...\n",
      "  Processing graph 0/1000\n",
      "Step 6: Encoding graphs...\n",
      "\n",
      "✓ Prepared 1000 graphs\n",
      "  Nodes per graph: 1\n",
      "  Symbols per graph node: up to 242 (stones only)\n",
      "  Label distribution: Winner 0=505, Winner 1=495\n"
     ]
    }
   ],
   "execution_count": 318
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Graph Tsetlin Machine\n",
    "\n",
    "Train the model on the prepared graph data."
   ],
   "id": "train_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:19:19.932001Z",
     "start_time": "2025-12-05T16:18:05.082482Z"
    }
   },
   "source": "tm, predictions = train_model(graphs, Y, epochs=100)",
   "id": "train_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Graph Tsetlin Machine...\n",
      "  Clauses: 3000\n",
      "  T: 25000\n",
      "  s: 10.0\n",
      "  Depth: 3\n",
      "  Message Size: 128\n",
      "Initialization of sparse structure.\n",
      "\n",
      "Class distribution before balancing (winner classes):\n",
      "  Winner 0: 505 states\n",
      "  Winner 1: 495 states\n",
      "After balancing: 1000 total samples\n",
      "\n",
      "Starting training for 100 epochs...\n",
      "============================================================\n",
      "Epoch 1/100 - Acc: 64.20% (Winner 0 states: 37.0%, Winner 1 states: 91.9%) - 1.31s\n",
      "Epoch 2/100 - Acc: 72.60% (Winner 0 states: 55.4%, Winner 1 states: 90.1%) - 0.64s\n",
      "Epoch 3/100 - Acc: 79.30% (Winner 0 states: 76.0%, Winner 1 states: 82.6%) - 0.65s\n",
      "Epoch 4/100 - Acc: 80.10% (Winner 0 states: 82.6%, Winner 1 states: 77.6%) - 0.64s\n",
      "Epoch 5/100 - Acc: 80.20% (Winner 0 states: 80.4%, Winner 1 states: 80.0%) - 0.65s\n",
      "Epoch 6/100 - Acc: 83.70% (Winner 0 states: 85.0%, Winner 1 states: 82.4%) - 0.65s\n",
      "Epoch 7/100 - Acc: 82.80% (Winner 0 states: 84.0%, Winner 1 states: 81.6%) - 0.66s\n",
      "Epoch 8/100 - Acc: 83.40% (Winner 0 states: 83.2%, Winner 1 states: 83.6%) - 0.66s\n",
      "Epoch 9/100 - Acc: 85.30% (Winner 0 states: 85.3%, Winner 1 states: 85.3%) - 0.66s\n",
      "Epoch 10/100 - Acc: 85.60% (Winner 0 states: 87.7%, Winner 1 states: 83.4%) - 0.66s\n",
      "Epoch 11/100 - Acc: 87.50% (Winner 0 states: 87.3%, Winner 1 states: 87.7%) - 0.66s\n",
      "Epoch 12/100 - Acc: 87.40% (Winner 0 states: 88.3%, Winner 1 states: 86.5%) - 0.66s\n",
      "Epoch 13/100 - Acc: 87.80% (Winner 0 states: 87.7%, Winner 1 states: 87.9%) - 0.66s\n",
      "Epoch 14/100 - Acc: 88.90% (Winner 0 states: 88.7%, Winner 1 states: 89.1%) - 0.66s\n",
      "Epoch 15/100 - Acc: 89.90% (Winner 0 states: 88.5%, Winner 1 states: 91.3%) - 0.66s\n",
      "Epoch 16/100 - Acc: 90.10% (Winner 0 states: 89.1%, Winner 1 states: 91.1%) - 0.65s\n",
      "Epoch 17/100 - Acc: 91.10% (Winner 0 states: 90.1%, Winner 1 states: 92.1%) - 0.65s\n",
      "Epoch 18/100 - Acc: 91.90% (Winner 0 states: 91.3%, Winner 1 states: 92.5%) - 0.65s\n",
      "Epoch 19/100 - Acc: 92.20% (Winner 0 states: 91.5%, Winner 1 states: 92.9%) - 0.65s\n",
      "Epoch 20/100 - Acc: 92.80% (Winner 0 states: 91.7%, Winner 1 states: 93.9%) - 0.65s\n",
      "Epoch 21/100 - Acc: 94.40% (Winner 0 states: 93.7%, Winner 1 states: 95.2%) - 0.64s\n",
      "Epoch 22/100 - Acc: 94.20% (Winner 0 states: 94.7%, Winner 1 states: 93.7%) - 0.64s\n",
      "Epoch 23/100 - Acc: 94.80% (Winner 0 states: 94.3%, Winner 1 states: 95.4%) - 0.64s\n",
      "Epoch 24/100 - Acc: 96.00% (Winner 0 states: 95.4%, Winner 1 states: 96.6%) - 0.64s\n",
      "Epoch 25/100 - Acc: 96.40% (Winner 0 states: 95.8%, Winner 1 states: 97.0%) - 0.63s\n",
      "Epoch 26/100 - Acc: 96.30% (Winner 0 states: 95.4%, Winner 1 states: 97.2%) - 0.63s\n",
      "Epoch 27/100 - Acc: 96.70% (Winner 0 states: 96.0%, Winner 1 states: 97.4%) - 0.63s\n",
      "Epoch 28/100 - Acc: 96.70% (Winner 0 states: 96.2%, Winner 1 states: 97.2%) - 0.63s\n",
      "Epoch 29/100 - Acc: 97.50% (Winner 0 states: 96.2%, Winner 1 states: 98.8%) - 0.62s\n",
      "Epoch 30/100 - Acc: 97.80% (Winner 0 states: 96.8%, Winner 1 states: 98.8%) - 0.62s\n",
      "Epoch 31/100 - Acc: 98.00% (Winner 0 states: 97.4%, Winner 1 states: 98.6%) - 0.61s\n",
      "Epoch 32/100 - Acc: 98.20% (Winner 0 states: 97.4%, Winner 1 states: 99.0%) - 0.61s\n",
      "Epoch 33/100 - Acc: 98.30% (Winner 0 states: 97.8%, Winner 1 states: 98.8%) - 0.61s\n",
      "Epoch 34/100 - Acc: 98.70% (Winner 0 states: 98.0%, Winner 1 states: 99.4%) - 0.60s\n",
      "Epoch 35/100 - Acc: 98.70% (Winner 0 states: 97.8%, Winner 1 states: 99.6%) - 0.60s\n",
      "Epoch 36/100 - Acc: 99.10% (Winner 0 states: 98.4%, Winner 1 states: 99.8%) - 0.59s\n",
      "Epoch 37/100 - Acc: 99.50% (Winner 0 states: 99.0%, Winner 1 states: 100.0%) - 0.59s\n",
      "Epoch 38/100 - Acc: 99.50% (Winner 0 states: 99.0%, Winner 1 states: 100.0%) - 0.59s\n",
      "Epoch 39/100 - Acc: 99.50% (Winner 0 states: 99.2%, Winner 1 states: 99.8%) - 0.59s\n",
      "Epoch 40/100 - Acc: 99.50% (Winner 0 states: 99.2%, Winner 1 states: 99.8%) - 0.58s\n",
      "Epoch 41/100 - Acc: 99.60% (Winner 0 states: 99.2%, Winner 1 states: 100.0%) - 0.58s\n",
      "Epoch 42/100 - Acc: 99.80% (Winner 0 states: 99.6%, Winner 1 states: 100.0%) - 0.58s\n",
      "Epoch 43/100 - Acc: 99.80% (Winner 0 states: 99.6%, Winner 1 states: 100.0%) - 0.57s\n",
      "Epoch 44/100 - Acc: 99.90% (Winner 0 states: 99.8%, Winner 1 states: 100.0%) - 0.57s\n",
      "Epoch 45/100 - Acc: 99.80% (Winner 0 states: 99.6%, Winner 1 states: 100.0%) - 0.57s\n",
      "Epoch 46/100 - Acc: 99.90% (Winner 0 states: 99.8%, Winner 1 states: 100.0%) - 0.57s\n",
      "Epoch 47/100 - Acc: 99.80% (Winner 0 states: 99.6%, Winner 1 states: 100.0%) - 0.56s\n",
      "Epoch 48/100 - Acc: 99.80% (Winner 0 states: 99.6%, Winner 1 states: 100.0%) - 0.56s\n",
      "Epoch 49/100 - Acc: 99.90% (Winner 0 states: 99.8%, Winner 1 states: 100.0%) - 0.55s\n",
      "Epoch 50/100 - Acc: 99.90% (Winner 0 states: 99.8%, Winner 1 states: 100.0%) - 0.55s\n",
      "Epoch 51/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.55s\n",
      "Epoch 52/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.54s\n",
      "Epoch 53/100 - Acc: 99.90% (Winner 0 states: 99.8%, Winner 1 states: 100.0%) - 0.54s\n",
      "Epoch 54/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.54s\n",
      "Epoch 55/100 - Acc: 99.90% (Winner 0 states: 99.8%, Winner 1 states: 100.0%) - 0.54s\n",
      "Epoch 56/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.54s\n",
      "Epoch 57/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.53s\n",
      "Epoch 58/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.53s\n",
      "Epoch 59/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.53s\n",
      "Epoch 60/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.53s\n",
      "Epoch 61/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.52s\n",
      "Epoch 62/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.52s\n",
      "Epoch 63/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.52s\n",
      "Epoch 64/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.52s\n",
      "Epoch 65/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.51s\n",
      "Epoch 66/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.51s\n",
      "Epoch 67/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.51s\n",
      "Epoch 68/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.50s\n",
      "Epoch 69/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.53s\n",
      "Epoch 70/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.50s\n",
      "Epoch 71/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.50s\n",
      "Epoch 72/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.50s\n",
      "Epoch 73/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.50s\n",
      "Epoch 74/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.50s\n",
      "Epoch 75/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.49s\n",
      "Epoch 76/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.49s\n",
      "Epoch 77/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.49s\n",
      "Epoch 78/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.48s\n",
      "Epoch 79/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.48s\n",
      "Epoch 80/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.48s\n",
      "Epoch 81/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.48s\n",
      "Epoch 82/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.47s\n",
      "Epoch 83/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.47s\n",
      "Epoch 84/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.47s\n",
      "Epoch 85/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.47s\n",
      "Epoch 86/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.46s\n",
      "Epoch 87/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.46s\n",
      "Epoch 88/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.46s\n",
      "Epoch 89/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.45s\n",
      "Epoch 90/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.46s\n",
      "Epoch 91/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.45s\n",
      "Epoch 92/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.45s\n",
      "Epoch 93/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.45s\n",
      "Epoch 94/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.45s\n",
      "Epoch 95/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.44s\n",
      "Epoch 96/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.44s\n",
      "Epoch 97/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.44s\n",
      "Epoch 98/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.44s\n",
      "Epoch 99/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.44s\n",
      "Epoch 100/100 - Acc: 100.00% (Winner 0 states: 100.0%, Winner 1 states: 100.0%) - 0.43s\n",
      "\n",
      "============================================================\n",
      "✓ Training completed in 74.63s (1.24 minutes)\n",
      "\n",
      "Final Evaluation...\n",
      "\n",
      "Overall Accuracy: 100.00%\n",
      "Winner 0 states: 100.00% (505/505)\n",
      "Winner 1 states: 100.00% (495/495)\n"
     ]
    }
   ],
   "execution_count": 319
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the Trained Model",
   "id": "fc63affabb52eeaa"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:19:20.138771Z",
     "start_time": "2025-12-05T16:19:20.116611Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "model_path = \"TsetlinMachine/hex_tm_model.pkl\"\n",
    "print(f\"Saving trained model to {model_path}...\")\n",
    "\n",
    "# Get the model state (weights, clauses, etc.) instead of the whole object\n",
    "model_state = tm.get_state()\n",
    "\n",
    "# Save the state along with model configuration\n",
    "model_save_data = {\n",
    "    'state': model_state,\n",
    "    'config': {\n",
    "        'number_of_clauses': tm.number_of_clauses,\n",
    "        'T': tm.T,\n",
    "        's': tm.s,\n",
    "        'number_of_state_bits': tm.number_of_state_bits,\n",
    "        'depth': tm.depth,\n",
    "        'message_size': tm.message_size,\n",
    "        'message_bits': tm.message_bits,\n",
    "        'max_included_literals': tm.max_included_literals,\n",
    "        'grid': (16 * 13, 1, 1),\n",
    "        'block': (128, 1, 1)\n",
    "    },\n",
    "    'symbols': symbols,\n",
    "    'num_nodes': num_nodes,\n",
    "    'board_dim': BOARD_DIM\n",
    "}\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model_save_data, f)\n",
    "\n",
    "print(\"✓ Model saved successfully\")\n",
    "\n",
    "# Show some example predictions\n",
    "print(\"\\nExample predictions (first 10):\")\n",
    "for i in range(min(10, len(predictions))):\n",
    "    pred = predictions[i]\n",
    "    true = Y[i]\n",
    "    status = \"✓\" if pred == true else \"✗\"\n",
    "    print(f\"{status} Sample {i}: Pred={pred}, True={true}\")"
   ],
   "id": "save_model_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model to TsetlinMachine/hex_tm_model.pkl...\n",
      "✓ Model saved successfully\n",
      "\n",
      "Example predictions (first 10):\n",
      "✓ Sample 0: Pred=1, True=1\n",
      "✓ Sample 1: Pred=0, True=0\n",
      "✓ Sample 2: Pred=1, True=1\n",
      "✓ Sample 3: Pred=0, True=0\n",
      "✓ Sample 4: Pred=1, True=1\n",
      "✓ Sample 5: Pred=0, True=0\n",
      "✓ Sample 6: Pred=1, True=1\n",
      "✓ Sample 7: Pred=1, True=1\n",
      "✓ Sample 8: Pred=0, True=0\n",
      "✓ Sample 9: Pred=1, True=1\n"
     ]
    }
   ],
   "execution_count": 320
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Trained Model (Optional)\n",
    "\n",
    "Use this to load a previously trained model."
   ],
   "id": "load_model_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:19:20.212325Z",
     "start_time": "2025-12-05T16:19:20.171716Z"
    }
   },
   "source": [
    "def load_trained_model(model_path):\n",
    "    \"\"\"Load a previously trained Tsetlin Machine\"\"\"\n",
    "    import pickle\n",
    "    from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "\n",
    "    # Recreate the model with saved configuration\n",
    "    config = model_data['config']\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        number_of_clauses=config['number_of_clauses'],\n",
    "        T=config['T'],\n",
    "        s=config['s'],\n",
    "        number_of_state_bits=config['number_of_state_bits'],\n",
    "        depth=config['depth'],\n",
    "        message_size=config['message_size'],\n",
    "        message_bits=config['message_bits'],\n",
    "        max_included_literals=config['max_included_literals'],\n",
    "        grid=config['grid'],\n",
    "        block=config['block']\n",
    "    )\n",
    "\n",
    "    # Restore the model state\n",
    "    tm.set_state(model_data['state'])\n",
    "\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "\n",
    "    return tm, model_data\n",
    "\n",
    "# Example usage:\n",
    "loaded_tm, loaded_data = load_trained_model(\"TsetlinMachine/hex_tm_model.pkl\")"
   ],
   "id": "load_model_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from TsetlinMachine/hex_tm_model.pkl...\n",
      "Initialization of sparse structure.\n",
      "✓ Model loaded successfully\n"
     ]
    }
   ],
   "execution_count": 321
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:19:20.243112Z",
     "start_time": "2025-12-05T16:19:20.236765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import contextlib\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_trained_model_quiet(\n",
    "    model_path=\"TsetlinMachine/hex_tm_model.pkl\",\n",
    "    num_test_games=200,\n",
    "    hypervector_size=1024,\n",
    "    hypervector_bits=2\n",
    "):\n",
    "    \"\"\"Quiet evaluation: suppress all internal prints, show only final metrics.\"\"\"\n",
    "\n",
    "    # Suppress prints using redirect_stdout\n",
    "    def silent_call(fn, *args, **kwargs):\n",
    "        buf = io.StringIO()\n",
    "        with contextlib.redirect_stdout(buf):\n",
    "            return fn(*args, **kwargs)\n",
    "\n",
    "    # 1) Load model\n",
    "    tm, model_data = silent_call(load_trained_model, model_path)\n",
    "    board_dim = model_data.get(\"board_dim\", BOARD_DIM)\n",
    "    print(\"✓ Model loaded\")\n",
    "\n",
    "    # 2) Generate new test games (suppress print spam)\n",
    "    test_games = silent_call(generate_game_data, num_test_games)\n",
    "\n",
    "    if not test_games:\n",
    "        print(\"ERROR: No test games generated.\")\n",
    "        return\n",
    "\n",
    "    # 3) Convert games → samples (quiet)\n",
    "    test_samples = []\n",
    "    for g in test_games:\n",
    "        samples = silent_call(\n",
    "            create_training_data_from_game,\n",
    "            g[\"moves\"],\n",
    "            g[\"winner\"],\n",
    "            board_dim\n",
    "        )\n",
    "        test_samples.extend(samples)\n",
    "\n",
    "    if len(test_samples) == 0:\n",
    "        print(\"ERROR: No test samples created.\")\n",
    "        return\n",
    "\n",
    "    Y_test = np.array([s[\"label\"] for s in test_samples], dtype=np.int32)\n",
    "\n",
    "    # 4) Build graphs (quiet)\n",
    "    graphs_test, Y_check = silent_call(\n",
    "        prepare_gtm_data,\n",
    "        test_samples,\n",
    "        board_dim,\n",
    "        hypervector_size,\n",
    "        hypervector_bits\n",
    "    )\n",
    "\n",
    "    print(\"✓ Test data prepared\")\n",
    "\n",
    "    # 5) Predict (quiet)\n",
    "    preds = silent_call(tm.predict, graphs_test).astype(int)\n",
    "\n",
    "    # 6) Accuracy\n",
    "    overall = 100 * (preds == Y_test).mean()\n",
    "\n",
    "    # Winner-wise accuracy\n",
    "    mask0 = (Y_test == 0)\n",
    "    mask1 = (Y_test == 1)\n",
    "\n",
    "    acc0 = 100 * (preds[mask0] == 0).mean() if mask0.any() else 0\n",
    "    acc1 = 100 * (preds[mask1] == 1).mean() if mask1.any() else 0\n",
    "\n",
    "    # Print only relevant things\n",
    "    print(f\"Overall accuracy: {overall:.2f}%\")\n",
    "    print(f\"Winner 0 accuracy: {acc0:.2f}%\")\n",
    "    print(f\"Winner 1 accuracy: {acc1:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"overall\": overall,\n",
    "        \"winner0\": acc0,\n",
    "        \"winner1\": acc1,\n",
    "        \"preds\": preds,\n",
    "        \"labels\": Y_test\n",
    "    }\n"
   ],
   "id": "5feccd4e2254f885",
   "outputs": [],
   "execution_count": 322
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:19:27.709925Z",
     "start_time": "2025-12-05T16:19:20.275746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = evaluate_trained_model_quiet(\n",
    "    \"TsetlinMachine/hex_tm_model.pkl\",\n",
    "    num_test_games=300,\n",
    "    hypervector_size=1024,\n",
    "    hypervector_bits=2\n",
    ")\n"
   ],
   "id": "2a5fa0dfa43a2d2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRecursionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[323], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_trained_model_quiet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTsetlinMachine/hex_tm_model.pkl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_test_games\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_bits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\n\u001B[1;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[322], line 49\u001B[0m, in \u001B[0;36mevaluate_trained_model_quiet\u001B[0;34m(model_path, num_test_games, hypervector_size, hypervector_bits)\u001B[0m\n\u001B[1;32m     46\u001B[0m Y_test \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([s[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m test_samples], dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint32)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# 4) Build graphs (quiet)\u001B[39;00m\n\u001B[0;32m---> 49\u001B[0m graphs_test, Y_check \u001B[38;5;241m=\u001B[39m \u001B[43msilent_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprepare_gtm_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43mboard_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_bits\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✓ Test data prepared\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;66;03m# 5) Predict (quiet)\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[322], line 17\u001B[0m, in \u001B[0;36mevaluate_trained_model_quiet.<locals>.silent_call\u001B[0;34m(fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     15\u001B[0m buf \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mStringIO()\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m contextlib\u001B[38;5;241m.\u001B[39mredirect_stdout(buf):\n\u001B[0;32m---> 17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[316], line 236\u001B[0m, in \u001B[0;36mprepare_gtm_data\u001B[0;34m(training_samples, board_dim, hypervector_size, hypervector_bits)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  Number of symbols: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(symbols)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  Hypervector size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhypervector_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, bits: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhypervector_bits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 236\u001B[0m graphs, Y \u001B[38;5;241m=\u001B[39m \u001B[43mprepare_gtm_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43mboard_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBOARD_DIM\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhypervector_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_bits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhypervector_bits\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;66;03m# 1) Set number of nodes\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStep 1: Setting number of nodes per graph...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[316], line 236\u001B[0m, in \u001B[0;36mprepare_gtm_data\u001B[0;34m(training_samples, board_dim, hypervector_size, hypervector_bits)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  Number of symbols: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(symbols)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  Hypervector size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhypervector_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, bits: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhypervector_bits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 236\u001B[0m graphs, Y \u001B[38;5;241m=\u001B[39m \u001B[43mprepare_gtm_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43mboard_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBOARD_DIM\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhypervector_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_bits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhypervector_bits\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;66;03m# 1) Set number of nodes\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStep 1: Setting number of nodes per graph...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "    \u001B[0;31m[... skipping similar frames: prepare_gtm_data at line 236 (2968 times)]\u001B[0m\n",
      "Cell \u001B[0;32mIn[316], line 236\u001B[0m, in \u001B[0;36mprepare_gtm_data\u001B[0;34m(training_samples, board_dim, hypervector_size, hypervector_bits)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  Number of symbols: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(symbols)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  Hypervector size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhypervector_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, bits: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhypervector_bits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 236\u001B[0m graphs, Y \u001B[38;5;241m=\u001B[39m \u001B[43mprepare_gtm_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43mboard_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBOARD_DIM\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhypervector_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhypervector_bits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhypervector_bits\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;66;03m# 1) Set number of nodes\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStep 1: Setting number of nodes per graph...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[316], line 222\u001B[0m, in \u001B[0;36mprepare_gtm_data\u001B[0;34m(training_samples, board_dim, hypervector_size, hypervector_bits)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;124;03mBuild a Graphs object where each board cell is a node, etc...\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mGraphTsetlinMachine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraphs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Graphs\n\u001B[0;32m--> 222\u001B[0m Y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43m[\u001B[49m\u001B[43ms\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtraining_samples\u001B[49m\u001B[43m]\u001B[49m, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint32)\n\u001B[1;32m    224\u001B[0m num_graphs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(training_samples)\n\u001B[1;32m    225\u001B[0m num_nodes \u001B[38;5;241m=\u001B[39m board_dim \u001B[38;5;241m*\u001B[39m board_dim\n",
      "\u001B[0;31mRecursionError\u001B[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "execution_count": 323
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
