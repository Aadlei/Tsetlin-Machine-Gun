{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Methods - Optimized Version",
   "id": "4e5dbf9bcd5c3f2d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T20:41:06.088266Z",
     "start_time": "2025-12-07T20:41:06.055652Z"
    }
   },
   "source": [
    "from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "from GraphTsetlinMachine.graphs import Graphs\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "BOARD_DIM = 11\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"Tsetlin.ipynb\"))\n",
    "HEX_DIR = os.path.join(NOTEBOOK_DIR, \"TsetlinMachine/hex\")\n",
    "\n",
    "if not os.path.exists(HEX_DIR):\n",
    "    raise FileNotFoundError(f\"ERROR: Cannot find hex.c at {HEX_DIR}\")\n",
    "\n",
    "print(\"Building hex using make...\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"make\"],\n",
    "        cwd=HEX_DIR,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    print(\"=== Make Output ===\")\n",
    "    print(result.stdout)\n",
    "    if result.stderr.strip():\n",
    "        print(\"=== Make Errors ===\")\n",
    "        print(result.stderr)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n✓ Build successful!\")\n",
    "    else:\n",
    "        print(\"\\n❌ Build failed! See errors above.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Exception when running make:\", e)\n",
    "\n",
    "def c_position_to_node_id(c_position, board_dim=BOARD_DIM):\n",
    "    padded_dim = board_dim + 2\n",
    "    i = c_position // padded_dim\n",
    "    j = c_position % padded_dim\n",
    "    node_id = (i - 1) * board_dim + (j - 1)\n",
    "\n",
    "    if node_id < 0 or node_id >= board_dim * board_dim:\n",
    "        return None\n",
    "    return node_id\n",
    "\n",
    "def get_hex_edges(board_dim=BOARD_DIM):\n",
    "    edges = []\n",
    "    neighbor_offsets = [(0, 1), (0, -1), (-1, 1), (1, -1), (-1, 0), (1, 0)]\n",
    "\n",
    "    for i in range(board_dim):\n",
    "        for j in range(board_dim):\n",
    "            node_id = i * board_dim + j\n",
    "            for di, dj in neighbor_offsets:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < board_dim and 0 <= nj < board_dim:\n",
    "                    neighbor_id = ni * board_dim + nj\n",
    "                    edges.append((node_id, neighbor_id))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def parse_game_output(output):\n",
    "    games = []\n",
    "    current_game = None\n",
    "\n",
    "    for line in output.split('\\n'):\n",
    "        line = line.strip()\n",
    "\n",
    "        if line == \"GAME_START\":\n",
    "            current_game = {'moves': [], 'winner': -1}\n",
    "        elif line.startswith(\"MOVE\"):\n",
    "            if current_game is not None:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 3:\n",
    "                    position = int(parts[1])\n",
    "                    player = int(parts[2])\n",
    "                    current_game['moves'].append((position, player))\n",
    "        elif line.startswith(\"WINNER\"):\n",
    "            if current_game is not None:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    current_game['winner'] = int(parts[1])\n",
    "        elif line == \"GAME_END\":\n",
    "            if current_game and current_game['winner'] != -1:\n",
    "                games.append(current_game)\n",
    "            current_game = None\n",
    "\n",
    "    return games\n",
    "\n",
    "def create_training_data_from_game(moves, winner, board_dim=BOARD_DIM):\n",
    "    \"\"\"\n",
    "    Create ONE training sample per game:\n",
    "      - board_state: final board (0=empty, 1=player0, 2=player1)\n",
    "      - label: winner of the game (0 or 1)\n",
    "\n",
    "    We keep node_features as before for compatibility, but the main\n",
    "    object we care about is the final board_state.\n",
    "    \"\"\"\n",
    "    num_nodes = board_dim * board_dim\n",
    "    board_state = np.zeros(num_nodes, dtype=np.int32)\n",
    "    edges = get_hex_edges(board_dim)  # not used in new Graphs, but kept\n",
    "\n",
    "    # Play through the whole game to get the final board\n",
    "    for c_position, player in moves:\n",
    "        node_id = c_position_to_node_id(c_position, board_dim)\n",
    "        if node_id is None:\n",
    "            print(f\"Skipping invalid move: c_pos={c_position}\")\n",
    "            continue\n",
    "        board_state[node_id] = player + 1  # 1 = player 0, 2 = player 1\n",
    "\n",
    "    # Build node_features from the FINAL full board_state\n",
    "    node_features = np.zeros((num_nodes, 3), dtype=np.int32)\n",
    "    for nid in range(num_nodes):\n",
    "        if board_state[nid] == 1:\n",
    "            node_features[nid, 0] = 1  # player_0 stone\n",
    "        elif board_state[nid] == 2:\n",
    "            node_features[nid, 1] = 1  # player_1 stone\n",
    "        else:\n",
    "            node_features[nid, 2] = 1  # empty\n",
    "\n",
    "    label = int(winner)  # 0 or 1\n",
    "\n",
    "    sample = {\n",
    "        'board_state': board_state.reshape(board_dim, board_dim),\n",
    "        'node_features': node_features,   # still there if you need it\n",
    "        'edges': edges,                   # unused in new Graph building\n",
    "        'position': -1,                   # not used now\n",
    "        'player': -1,                     # not used now\n",
    "        'label': label\n",
    "    }\n",
    "\n",
    "    # Return as a list to match old API\n",
    "    return [sample]\n",
    "\n",
    "\n",
    "def prepare_training_data(games, board_dim=BOARD_DIM):\n",
    "    \"\"\"\n",
    "    Turn a list of games into a list of FINAL-state → winner samples.\n",
    "    Exactly one sample per game.\n",
    "    \"\"\"\n",
    "    all_samples = []\n",
    "\n",
    "    print(f\"Processing {len(games)} games into training samples...\")\n",
    "\n",
    "    # Game-level statistics\n",
    "    player_0_wins = sum(1 for g in games if g['winner'] == 0)\n",
    "    player_1_wins = sum(1 for g in games if g['winner'] == 1)\n",
    "    print(f\"Game outcomes (per game):\")\n",
    "    print(f\"  Player 0 wins: {player_0_wins}\")\n",
    "    print(f\"  Player 1 wins: {player_1_wins}\")\n",
    "\n",
    "    for game in tqdm(games, desc=\"Processing games\"):\n",
    "        samples = create_training_data_from_game(game['moves'], game['winner'], board_dim)\n",
    "        all_samples.extend(samples)\n",
    "\n",
    "    if len(all_samples) == 0:\n",
    "        print(\"ERROR: No training samples created! Check your logic.\")\n",
    "        return all_samples\n",
    "\n",
    "    labels = [s['label'] for s in all_samples]\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"\\nLabel distribution (winner classes, per FINAL board):\")\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"  Winner {label}: {count} games ({count/len(labels)*100:.1f}%)\")\n",
    "\n",
    "    # Quick sanity check of final board states\n",
    "    print(\"\\nSample final board state check (first 5 samples):\")\n",
    "    for i in range(min(5, len(all_samples))):\n",
    "        sample = all_samples[i]\n",
    "        pieces = np.sum(sample['node_features'][:, :2])\n",
    "        empties = np.sum(sample['node_features'][:, 2])\n",
    "        print(f\"  Sample {i}: {pieces} stones, {empties} empty cells, label(winner)={sample['label']}\")\n",
    "\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    return all_samples\n",
    "\n",
    "\n",
    "def generate_game_data(num_games=1000, hex_dir=HEX_DIR):\n",
    "    hex_executable = os.path.join(hex_dir, \"hex\")\n",
    "\n",
    "    if not os.path.exists(hex_executable):\n",
    "        print(f\"Executable not found at {hex_executable}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Generating {num_games} games...\")\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [hex_executable, str(num_games)],\n",
    "            cwd=hex_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=120\n",
    "        )\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error running hex executable:\")\n",
    "            print(result.stderr)\n",
    "            return []\n",
    "\n",
    "        games = parse_game_output(result.stdout)\n",
    "        print(f\"Successfully parsed {len(games)} games from output\")\n",
    "        return games\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running hex executable: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def prepare_gtm_data(training_samples, board_dim=BOARD_DIM,\n",
    "                     hypervector_size=1024, hypervector_bits=2):\n",
    "    \"\"\"\n",
    "    Build a Graphs object where each board cell is a node, etc...\n",
    "    \"\"\"\n",
    "    from GraphTsetlinMachine.graphs import Graphs\n",
    "\n",
    "    Y = np.array([s['label'] for s in training_samples], dtype=np.int32)\n",
    "\n",
    "    num_graphs = len(training_samples)\n",
    "    num_nodes = board_dim * board_dim\n",
    "\n",
    "    symbols = ['player_0', 'player_1', 'empty']\n",
    "\n",
    "    graphs = Graphs(\n",
    "        num_graphs,\n",
    "        symbols=symbols,\n",
    "        hypervector_size=hypervector_size,\n",
    "        hypervector_bits=hypervector_bits\n",
    "    )\n",
    "\n",
    "    # 1) Set number of nodes\n",
    "    print(\"Step 1: Setting number of nodes per graph...\")\n",
    "    for graph_id in tqdm(range(num_graphs), desc=\"Setting nodes\"):\n",
    "        graphs.set_number_of_graph_nodes(graph_id, num_nodes)\n",
    "\n",
    "    # 2) Node configuration\n",
    "    print(\"Step 2: Preparing node configuration...\")\n",
    "    graphs.prepare_node_configuration()\n",
    "\n",
    "    # 3) Add nodes with edge counts\n",
    "    print(\"Step 3: Adding nodes with edge counts...\")\n",
    "    hex_edges = get_hex_edges(board_dim)\n",
    "\n",
    "    edge_counts = np.zeros(num_nodes, dtype=np.uint32)\n",
    "    for src, _ in hex_edges:\n",
    "        edge_counts[src] += 1\n",
    "\n",
    "    for graph_id in tqdm(range(num_graphs), desc=\"Adding nodes\"):\n",
    "        for node_id in range(num_nodes):\n",
    "            graphs.add_graph_node(graph_id, node_id, int(edge_counts[node_id]))\n",
    "\n",
    "    # 4) Edge configuration\n",
    "    print(\"Step 4: Preparing edge configuration...\")\n",
    "    graphs.prepare_edge_configuration()\n",
    "\n",
    "    # 5) Add edges\n",
    "    print(\"Step 5: Adding edges...\")\n",
    "    edge_type_name = \"hex_neighbor\"\n",
    "    if edge_type_name not in graphs.edge_type_id:\n",
    "        graphs.edge_type_id[edge_type_name] = len(graphs.edge_type_id)\n",
    "    edge_type_id = graphs.edge_type_id[edge_type_name]\n",
    "\n",
    "    edge_data = [(src, dst, edge_type_id) for (src, dst) in hex_edges]\n",
    "\n",
    "    for graph_id in tqdm(range(num_graphs), desc=\"Populating edges\"):\n",
    "        node_index = graphs.node_index[graph_id]\n",
    "\n",
    "        for src_node_id, dest_node_id, etype in edge_data:\n",
    "            base = graphs.edge_index[node_index + src_node_id]\n",
    "            offset = graphs.graph_node_edge_counter[node_index + src_node_id]\n",
    "            edge_idx = base + offset\n",
    "\n",
    "            graphs.edge[edge_idx][0] = dest_node_id\n",
    "            graphs.edge[edge_idx][1] = etype\n",
    "            graphs.graph_node_edge_counter[node_index + src_node_id] += 1\n",
    "\n",
    "    # 6) Add node properties\n",
    "    print(\"Step 6: Adding node properties (stone occupancy)...\")\n",
    "    for graph_id in tqdm(range(num_graphs), desc=\"Adding properties\"):\n",
    "        node_features = training_samples[graph_id]['node_features']\n",
    "        for node_id in range(num_nodes):\n",
    "            if node_features[node_id, 0] == 1:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"player_0\")\n",
    "            elif node_features[node_id, 1] == 1:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"player_1\")\n",
    "            else:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"empty\")\n",
    "\n",
    "    # 7) Encode graphs\n",
    "    print(\"Step 7: Encoding graphs...\")\n",
    "    graphs.encode()\n",
    "\n",
    "    print(f\"\\n✓ Prepared {num_graphs} multi-node Hex graphs\")\n",
    "    unique_labels, label_counts = np.unique(Y, return_counts=True)\n",
    "    label_dist = \", \".join([f\"Winner {lab}={cnt}\" for lab, cnt in zip(unique_labels, label_counts)])\n",
    "    print(f\"  Label distribution: {label_dist}\")\n",
    "\n",
    "    return graphs, Y\n",
    "\n",
    "\n",
    "\n",
    "def train_model(graphs, Y, epochs=100):\n",
    "    \"\"\"\n",
    "    Train a MultiClassGraphTsetlinMachine to predict the WINNER (0 or 1)\n",
    "    from a given board state.\n",
    "    \"\"\"\n",
    "    NUMBER_OF_CLAUSES = 3000\n",
    "    T = 25000\n",
    "    S = 10.0\n",
    "    DEPTH = 3\n",
    "    MESSAGE_SIZE = 128\n",
    "    MESSAGE_BITS = 2\n",
    "\n",
    "    print(\"Initializing Graph Tsetlin Machine...\")\n",
    "    print(f\"  Clauses: {NUMBER_OF_CLAUSES}\")\n",
    "    print(f\"  T: {T}\")\n",
    "    print(f\"  s: {S}\")\n",
    "    print(f\"  Depth: {DEPTH}\")\n",
    "    print(f\"  Message Size: {MESSAGE_SIZE}\")\n",
    "\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        number_of_clauses=NUMBER_OF_CLAUSES,\n",
    "        T=T,\n",
    "        s=S,\n",
    "        number_of_state_bits=8,\n",
    "        depth=DEPTH,\n",
    "        message_size=MESSAGE_SIZE,\n",
    "        message_bits=MESSAGE_BITS,\n",
    "        max_included_literals=32,\n",
    "        grid=(16 * 13, 1, 1),\n",
    "        block=(128, 1, 1)\n",
    "    )\n",
    "\n",
    "    # Class balancing: oversample minority class of winner\n",
    "    class_0_indices = np.where(Y == 0)[0]\n",
    "    class_1_indices = np.where(Y == 1)[0]\n",
    "\n",
    "    print(f\"\\nClass distribution before balancing (winner classes):\")\n",
    "    print(f\"  Winner 0: {len(class_0_indices)} states\")\n",
    "    print(f\"  Winner 1: {len(class_1_indices)} states\")\n",
    "\n",
    "    if len(class_0_indices) > 0 and len(class_1_indices) > 0:\n",
    "        # Balance by repeating minority class\n",
    "        if len(class_0_indices) < len(class_1_indices):\n",
    "            oversample_ratio = len(class_1_indices) // len(class_0_indices)\n",
    "            class_0_indices = np.tile(class_0_indices, oversample_ratio)\n",
    "        else:\n",
    "            oversample_ratio = len(class_0_indices) // len(class_1_indices)\n",
    "            class_1_indices = np.tile(class_1_indices, oversample_ratio)\n",
    "\n",
    "        balanced_indices = np.concatenate([class_0_indices, class_1_indices])\n",
    "        np.random.shuffle(balanced_indices)\n",
    "        print(f\"After balancing: {len(balanced_indices)} total samples\")\n",
    "    else:\n",
    "        balanced_indices = np.arange(len(Y))\n",
    "        print(\"Warning: only one winner class present; no balancing applied.\")\n",
    "\n",
    "    print(f\"\\nStarting training for {epochs} epochs...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    start_total = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        # NOTE: current GTM implementation uses full graph set; balancing\n",
    "        # is mainly informational here. To actually subsample, GTM would need\n",
    "        # support for graph subsets.\n",
    "        tm.fit(graphs, Y, epochs=1, incremental=True)\n",
    "        elapsed = time.time() - start_epoch\n",
    "\n",
    "        predictions = tm.predict(graphs)\n",
    "        accuracy = 100 * (predictions == Y).mean()\n",
    "\n",
    "        class_0_mask = (Y == 0)\n",
    "        class_1_mask = (Y == 1)\n",
    "        class_0_acc = 100 * (predictions[class_0_mask] == 0).mean() if class_0_mask.any() else 0\n",
    "        class_1_acc = 100 * (predictions[class_1_mask] == 1).mean() if class_1_mask.any() else 0\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Acc: {accuracy:.2f}% \"\n",
    "              f\"(Winner 0 states: {class_0_acc:.1f}%, Winner 1 states: {class_1_acc:.1f}%) - {elapsed:.2f}s\")\n",
    "\n",
    "    total_time = time.time() - start_total\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"✓ Training completed in {total_time:.2f}s ({total_time/60:.2f} minutes)\")\n",
    "\n",
    "    print(\"\\nFinal Evaluation...\")\n",
    "    predictions = tm.predict(graphs)\n",
    "\n",
    "    accuracy = 100 * (predictions == Y).mean()\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    for class_id in [0, 1]:\n",
    "        mask = Y == class_id\n",
    "        if mask.any():\n",
    "            class_acc = 100 * (predictions[mask] == class_id).mean()\n",
    "            print(f\"Winner {class_id} states: {class_acc:.2f}% \"\n",
    "                  f\"({(predictions[mask] == class_id).sum()}/{mask.sum()})\")\n",
    "\n",
    "    return tm, predictions\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building hex using make...\n",
      "=== Make Output ===\n",
      "make: 'hex' is up to date.\n",
      "\n",
      "\n",
      "✓ Build successful!\n"
     ]
    }
   ],
   "execution_count": 361
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Game Data\n",
    "\n",
    "Run this cell to generate Hex games and create training samples."
   ],
   "id": "generate_data_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:41:06.665230Z",
     "start_time": "2025-12-07T20:41:06.108520Z"
    }
   },
   "source": [
    "# Generate games\n",
    "NUM_GAMES = 1000  # Adjust as needed\n",
    "\n",
    "print(f\"Generating {NUM_GAMES} Hex games...\")\n",
    "games = generate_game_data(NUM_GAMES)\n",
    "\n",
    "if not games:\n",
    "    raise Exception(\"No games generated! Check hex executable.\")\n",
    "\n",
    "print(f\"\\n✓ Successfully generated {len(games)} games\")\n",
    "\n",
    "# Process into training samples (FINAL state -> winner)\n",
    "training_samples = prepare_training_data(games, BOARD_DIM)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC: Checking final board states:\")\n",
    "print(\"=\"*60)\n",
    "for i in range(min(10, len(training_samples))):\n",
    "    sample = training_samples[i]\n",
    "    non_zero = np.sum(sample['node_features'][:, :2])  # Count player pieces\n",
    "    empty = np.sum(sample['node_features'][:, 2])      # Count empty cells\n",
    "    print(f\"Sample {i}: {non_zero} stones on board, {empty} empty cells, label(winner)={sample['label']}\")\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(f\"\\n✓ Training data ready: {len(training_samples)} samples\")\n"
   ],
   "id": "generate_data_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1000 Hex games...\n",
      "Generating 1000 games...\n",
      "Successfully parsed 1000 games from output\n",
      "\n",
      "✓ Successfully generated 1000 games\n",
      "Processing 1000 games into training samples...\n",
      "Game outcomes (per game):\n",
      "  Player 0 wins: 505\n",
      "  Player 1 wins: 495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games: 100%|██████████| 1000/1000 [00:00<00:00, 2384.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution (winner classes, per FINAL board):\n",
      "  Winner 0: 505 games (50.5%)\n",
      "  Winner 1: 495 games (49.5%)\n",
      "\n",
      "Sample final board state check (first 5 samples):\n",
      "  Sample 0: 116 stones, 5 empty cells, label(winner)=1\n",
      "  Sample 1: 115 stones, 6 empty cells, label(winner)=0\n",
      "  Sample 2: 108 stones, 13 empty cells, label(winner)=1\n",
      "  Sample 3: 115 stones, 6 empty cells, label(winner)=0\n",
      "  Sample 4: 112 stones, 9 empty cells, label(winner)=1\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "DIAGNOSTIC: Checking final board states:\n",
      "============================================================\n",
      "Sample 0: 116 stones on board, 5 empty cells, label(winner)=1\n",
      "Sample 1: 115 stones on board, 6 empty cells, label(winner)=0\n",
      "Sample 2: 108 stones on board, 13 empty cells, label(winner)=1\n",
      "Sample 3: 115 stones on board, 6 empty cells, label(winner)=0\n",
      "Sample 4: 112 stones on board, 9 empty cells, label(winner)=1\n",
      "Sample 5: 111 stones on board, 10 empty cells, label(winner)=0\n",
      "Sample 6: 102 stones on board, 19 empty cells, label(winner)=1\n",
      "Sample 7: 106 stones on board, 15 empty cells, label(winner)=1\n",
      "Sample 8: 109 stones on board, 12 empty cells, label(winner)=0\n",
      "Sample 9: 120 stones on board, 1 empty cells, label(winner)=1\n",
      "============================================================\n",
      "\n",
      "\n",
      "✓ Training data ready: 1000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 362
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Graph Tsetlin Machine\n",
    "\n",
    "Convert training samples into the GTM Graphs format."
   ],
   "id": "prepare_gtm_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:41:07.514409Z",
     "start_time": "2025-12-07T20:41:07.076802Z"
    }
   },
   "source": [
    "from GraphTsetlinMachine.graphs import Graphs\n",
    "\n",
    "# Extract labels (winner 0/1 per FINAL board)\n",
    "Y = np.array([s['label'] for s in training_samples], dtype=np.uint32)\n",
    "\n",
    "print(\"Preparing data in GTM Graphs format (MNIST-style)...\")\n",
    "\n",
    "# --- Define symbols: one for each (player, cell) ---\n",
    "\n",
    "symbols = []\n",
    "for i in range(BOARD_DIM):\n",
    "    for j in range(BOARD_DIM):\n",
    "        symbols.append(f\"P0_{i}_{j}\")  # player 0 stone at (i,j)\n",
    "        symbols.append(f\"P1_{i}_{j}\")  # player 1 stone at (i,j)\n",
    "\n",
    "num_nodes = 1  # ONE node per graph, just like 'Image Node' in MNIST example\n",
    "\n",
    "graphs = Graphs(\n",
    "    number_of_graphs=len(training_samples),\n",
    "    symbols=symbols,\n",
    "    hypervector_size=1024,\n",
    "    hypervector_bits=2,\n",
    "    double_hashing=False,\n",
    "    # one_hot_encoding=False by default unless you want one-hot\n",
    ")\n",
    "\n",
    "print(\"Step 1: Setting number of nodes for each graph to 1...\")\n",
    "for graph_id in range(len(training_samples)):\n",
    "    graphs.set_number_of_graph_nodes(graph_id, num_nodes)\n",
    "\n",
    "print(\"Step 2: Preparing node configuration...\")\n",
    "graphs.prepare_node_configuration()\n",
    "\n",
    "print(\"Step 3: Adding the single 'Board' node to each graph...\")\n",
    "for graph_id in range(len(training_samples)):\n",
    "    number_of_outgoing_edges = 0  # we don't use edges here\n",
    "    graphs.add_graph_node(graph_id, 'Board', number_of_outgoing_edges)\n",
    "\n",
    "print(\"Step 4: Preparing edge configuration (no edges, but required call)...\")\n",
    "graphs.prepare_edge_configuration()\n",
    "\n",
    "print(\"Step 5: Adding node properties based on FINAL board state...\")\n",
    "\n",
    "for graph_id in range(len(training_samples)):\n",
    "    if graph_id % 1000 == 0:\n",
    "        print(f\"  Processing graph {graph_id}/{len(training_samples)}\")\n",
    "\n",
    "    # node_features: shape (board_dim^2, 3)\n",
    "    node_features = training_samples[graph_id]['node_features']\n",
    "\n",
    "    for node_id in range(BOARD_DIM * BOARD_DIM):\n",
    "        i = node_id // BOARD_DIM\n",
    "        j = node_id % BOARD_DIM\n",
    "\n",
    "        if node_features[node_id, 0] == 1:\n",
    "            # Player 0 stone at (i,j)\n",
    "            graphs.add_graph_node_property(graph_id, 'Board', f\"P0_{i}_{j}\")\n",
    "        elif node_features[node_id, 1] == 1:\n",
    "            # Player 1 stone at (i,j)\n",
    "            graphs.add_graph_node_property(graph_id, 'Board', f\"P1_{i}_{j}\")\n",
    "        # empty cells add no property\n",
    "\n",
    "print(\"Step 6: Encoding graphs...\")\n",
    "graphs.encode()\n",
    "\n",
    "print(f\"\\n✓ Prepared {len(training_samples)} graphs\")\n",
    "print(f\"  Nodes per graph: {num_nodes}\")\n",
    "print(f\"  Symbols per graph node: up to {BOARD_DIM*BOARD_DIM*2} (stones only)\")\n",
    "unique_labels, label_counts = np.unique(Y, return_counts=True)\n",
    "label_dist = \", \".join([f\"Winner {label}={count}\" for label, count in zip(unique_labels, label_counts)])\n",
    "print(f\"  Label distribution: {label_dist}\")\n"
   ],
   "id": "prepare_gtm_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data in GTM Graphs format (MNIST-style)...\n",
      "Step 1: Setting number of nodes for each graph to 1...\n",
      "Step 2: Preparing node configuration...\n",
      "Step 3: Adding the single 'Board' node to each graph...\n",
      "Step 4: Preparing edge configuration (no edges, but required call)...\n",
      "Step 5: Adding node properties based on FINAL board state...\n",
      "  Processing graph 0/1000\n",
      "Step 6: Encoding graphs...\n",
      "\n",
      "✓ Prepared 1000 graphs\n",
      "  Nodes per graph: 1\n",
      "  Symbols per graph node: up to 242 (stones only)\n",
      "  Label distribution: Winner 0=505, Winner 1=495\n"
     ]
    }
   ],
   "execution_count": 363
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Graph Tsetlin Machine\n",
    "\n",
    "Train the model on the prepared graph data."
   ],
   "id": "train_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:41:34.445246Z",
     "start_time": "2025-12-07T20:41:07.555042Z"
    }
   },
   "source": "tm, predictions = train_model(graphs, Y, epochs=30)",
   "id": "train_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Graph Tsetlin Machine...\n",
      "  Clauses: 3000\n",
      "  T: 25000\n",
      "  s: 10.0\n",
      "  Depth: 3\n",
      "  Message Size: 128\n",
      "Initialization of sparse structure.\n",
      "\n",
      "Class distribution before balancing (winner classes):\n",
      "  Winner 0: 505 states\n",
      "  Winner 1: 495 states\n",
      "After balancing: 1000 total samples\n",
      "\n",
      "Starting training for 30 epochs...\n",
      "============================================================\n",
      "Epoch 1/30 - Acc: 59.30% (Winner 0 states: 24.2%, Winner 1 states: 95.2%) - 1.33s\n",
      "Epoch 2/30 - Acc: 75.00% (Winner 0 states: 69.9%, Winner 1 states: 80.2%) - 0.64s\n",
      "Epoch 3/30 - Acc: 79.10% (Winner 0 states: 84.4%, Winner 1 states: 73.7%) - 0.65s\n",
      "Epoch 4/30 - Acc: 80.20% (Winner 0 states: 78.6%, Winner 1 states: 81.8%) - 0.64s\n",
      "Epoch 5/30 - Acc: 80.60% (Winner 0 states: 77.2%, Winner 1 states: 84.0%) - 0.65s\n",
      "Epoch 6/30 - Acc: 82.60% (Winner 0 states: 83.2%, Winner 1 states: 82.0%) - 0.65s\n",
      "Epoch 7/30 - Acc: 83.00% (Winner 0 states: 83.0%, Winner 1 states: 83.0%) - 0.65s\n",
      "Epoch 8/30 - Acc: 84.30% (Winner 0 states: 81.4%, Winner 1 states: 87.3%) - 0.66s\n",
      "Epoch 9/30 - Acc: 85.40% (Winner 0 states: 84.4%, Winner 1 states: 86.5%) - 0.66s\n",
      "Epoch 10/30 - Acc: 87.50% (Winner 0 states: 86.3%, Winner 1 states: 88.7%) - 0.66s\n",
      "Epoch 11/30 - Acc: 87.10% (Winner 0 states: 88.5%, Winner 1 states: 85.7%) - 0.66s\n",
      "Epoch 12/30 - Acc: 87.70% (Winner 0 states: 88.1%, Winner 1 states: 87.3%) - 0.66s\n",
      "Epoch 13/30 - Acc: 88.90% (Winner 0 states: 88.3%, Winner 1 states: 89.5%) - 0.66s\n",
      "Epoch 14/30 - Acc: 90.00% (Winner 0 states: 89.5%, Winner 1 states: 90.5%) - 0.67s\n",
      "Epoch 15/30 - Acc: 90.20% (Winner 0 states: 90.9%, Winner 1 states: 89.5%) - 0.66s\n",
      "Epoch 16/30 - Acc: 91.10% (Winner 0 states: 90.5%, Winner 1 states: 91.7%) - 0.65s\n",
      "Epoch 17/30 - Acc: 91.40% (Winner 0 states: 90.3%, Winner 1 states: 92.5%) - 0.66s\n",
      "Epoch 18/30 - Acc: 91.00% (Winner 0 states: 90.9%, Winner 1 states: 91.1%) - 0.65s\n",
      "Epoch 19/30 - Acc: 91.90% (Winner 0 states: 90.9%, Winner 1 states: 92.9%) - 0.66s\n",
      "Epoch 20/30 - Acc: 93.10% (Winner 0 states: 92.7%, Winner 1 states: 93.5%) - 0.70s\n",
      "Epoch 21/30 - Acc: 93.40% (Winner 0 states: 92.5%, Winner 1 states: 94.3%) - 0.69s\n",
      "Epoch 22/30 - Acc: 93.80% (Winner 0 states: 93.1%, Winner 1 states: 94.5%) - 0.69s\n",
      "Epoch 23/30 - Acc: 94.30% (Winner 0 states: 93.3%, Winner 1 states: 95.4%) - 0.69s\n",
      "Epoch 24/30 - Acc: 95.10% (Winner 0 states: 94.7%, Winner 1 states: 95.6%) - 0.69s\n",
      "Epoch 25/30 - Acc: 95.50% (Winner 0 states: 95.2%, Winner 1 states: 95.8%) - 0.69s\n",
      "Epoch 26/30 - Acc: 96.10% (Winner 0 states: 96.2%, Winner 1 states: 96.0%) - 0.68s\n",
      "Epoch 27/30 - Acc: 96.50% (Winner 0 states: 96.0%, Winner 1 states: 97.0%) - 0.68s\n",
      "Epoch 28/30 - Acc: 96.90% (Winner 0 states: 95.8%, Winner 1 states: 98.0%) - 0.68s\n",
      "Epoch 29/30 - Acc: 97.40% (Winner 0 states: 97.4%, Winner 1 states: 97.4%) - 0.67s\n",
      "Epoch 30/30 - Acc: 97.80% (Winner 0 states: 97.4%, Winner 1 states: 98.2%) - 0.66s\n",
      "\n",
      "============================================================\n",
      "✓ Training completed in 26.63s (0.44 minutes)\n",
      "\n",
      "Final Evaluation...\n",
      "\n",
      "Overall Accuracy: 97.80%\n",
      "Winner 0 states: 97.43% (492/505)\n",
      "Winner 1 states: 98.18% (486/495)\n"
     ]
    }
   ],
   "execution_count": 364
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the Trained Model",
   "id": "fc63affabb52eeaa"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:04:08.626882Z",
     "start_time": "2025-12-07T21:04:08.623046Z"
    }
   },
   "source": [
    "import pickle\n",
    "def save_model(tm, filepath=\"TsetlinMachine/hex_tm_model.pkl\",\n",
    "               board_dim=11, additional_info=None):\n",
    "    \"\"\"Save trained model with metadata\"\"\"\n",
    "    print(f\"Saving model to {filepath}...\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "    # Use built-in save() method\n",
    "    state_dict = tm.save(fname=filepath)\n",
    "\n",
    "    # Add metadata\n",
    "    state_dict['board_dim'] = board_dim\n",
    "    if additional_info:\n",
    "        state_dict.update(additional_info)\n",
    "\n",
    "    # Re-save with metadata\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(state_dict, f)\n",
    "\n",
    "    print(f\"✓ Model saved successfully to {filepath}\")\n",
    "    return state_dict"
   ],
   "id": "save_model_cell",
   "outputs": [],
   "execution_count": 375
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Trained Model (Optional)\n",
    "\n",
    "Use this to load a previously trained model."
   ],
   "id": "load_model_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:04:10.390389Z",
     "start_time": "2025-12-07T21:04:10.385010Z"
    }
   },
   "source": [
    "def load_model(filepath=\"TsetlinMachine/hex_tm_model.pkl\"):\n",
    "    \"\"\"Load trained model with metadata\"\"\"\n",
    "    print(f\"Loading model from {filepath}...\")\n",
    "\n",
    "    # Load pickle file\n",
    "    with open(filepath, 'rb') as f:\n",
    "        state_dict = pickle.load(f)\n",
    "\n",
    "    # Extract metadata\n",
    "    metadata = {'board_dim': state_dict.get('board_dim', 11)}\n",
    "\n",
    "    standard_keys = {\n",
    "        'ta_state', 'message_ta_state', 'clause_weights', 'hypervectors',\n",
    "        'number_of_outputs', 'number_of_literals', 'number_of_message_literals',\n",
    "        'min_y', 'max_y', 'negative_clauses', 'max_number_of_graph_nodes',\n",
    "        'number_of_clauses', 'T', 's', 'q', 'max_included_literals',\n",
    "        'boost_true_positive_feedback', 'number_of_state_bits', 'depth',\n",
    "        'message_size', 'message_bits', 'double_hashing', 'one_hot_encoding',\n",
    "        'board_dim'\n",
    "    }\n",
    "\n",
    "    for key, value in state_dict.items():\n",
    "        if key not in standard_keys:\n",
    "            metadata[key] = value\n",
    "\n",
    "    # Create model with saved parameters\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        number_of_clauses=state_dict['number_of_clauses'],\n",
    "        T=state_dict['T'],\n",
    "        s=state_dict['s'],\n",
    "        q=state_dict['q'],\n",
    "        max_included_literals=state_dict['max_included_literals'],\n",
    "        boost_true_positive_feedback=state_dict['boost_true_positive_feedback'],\n",
    "        number_of_state_bits=state_dict['number_of_state_bits'],\n",
    "        depth=state_dict['depth'],\n",
    "        message_size=state_dict['message_size'],\n",
    "        message_bits=state_dict['message_bits'],\n",
    "        double_hashing=state_dict['double_hashing'],\n",
    "        one_hot_encoding=state_dict['one_hot_encoding']\n",
    "    )\n",
    "\n",
    "    # Load state using built-in load() method\n",
    "    tm.load(fname=filepath)\n",
    "\n",
    "    print(f\"✓ Model loaded successfully\")\n",
    "    print(f\"  Clauses: {state_dict['number_of_clauses']}, Depth: {state_dict['depth']}\")\n",
    "\n",
    "    return tm, metadata\n",
    "\n"
   ],
   "id": "load_model_cell",
   "outputs": [],
   "execution_count": 376
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:06:32.580071Z",
     "start_time": "2025-12-07T21:06:32.552445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "def evaluate_model(model_path=\"TsetlinMachine/hex_tm_model.pkl\",\n",
    "                   num_test_games=200, verbose=True):\n",
    "    \"\"\"Complete model evaluation\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    tm, metadata = load_model(model_path)\n",
    "    board_dim = metadata['board_dim']\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"MODEL EVALUATION\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "    # Generate test data\n",
    "    if verbose:\n",
    "        print(f\"\\nGenerating {num_test_games} test games...\")\n",
    "    test_games = generate_game_data(num_test_games)\n",
    "\n",
    "    test_samples = []\n",
    "    for g in test_games:\n",
    "        samples = create_training_data_from_game(g[\"moves\"], g[\"winner\"], board_dim)\n",
    "        test_samples.extend(samples)\n",
    "\n",
    "    Y_test = np.array([s[\"label\"] for s in test_samples], dtype=np.int32)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"✓ Created {len(test_samples)} test samples\")\n",
    "        print(f\"  Winner 0: {np.sum(Y_test==0)}, Winner 1: {np.sum(Y_test==1)}\")\n",
    "\n",
    "    # Prepare graphs\n",
    "    if verbose:\n",
    "        print(f\"Preparing graphs...\")\n",
    "\n",
    "    graphs_test, _ = prepare_gtm_data(\n",
    "        test_samples, board_dim=board_dim,\n",
    "        hypervector_size=1024, hypervector_bits=2\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"✓ Graphs prepared\\nMaking predictions...\")\n",
    "\n",
    "    # Predict\n",
    "    predictions = tm.predict(graphs_test).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    overall_acc = 100 * (predictions == Y_test).mean()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RESULTS - {len(test_samples)} samples from {num_test_games} games\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nOverall Accuracy: {overall_acc:.2f}%\")\n",
    "\n",
    "    # Per-class accuracy\n",
    "    for winner in [0, 1]:\n",
    "        mask = Y_test == winner\n",
    "        if mask.any():\n",
    "            acc = 100 * (predictions[mask] == winner).mean()\n",
    "            correct = (predictions[mask] == winner).sum()\n",
    "            total = mask.sum()\n",
    "            print(f\"Winner {winner} Accuracy: {acc:.2f}% ({correct}/{total})\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(Y_test, predictions)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"              Predicted\")\n",
    "    print(f\"              0      1\")\n",
    "    print(f\"Actual  0  [{cm[0,0]:4d}  {cm[0,1]:4d}]\")\n",
    "    print(f\"        1  [{cm[1,0]:4d}  {cm[1,1]:4d}]\")\n",
    "\n",
    "    # Additional metrics\n",
    "    p0 = precision_score(Y_test, predictions, pos_label=0, zero_division=0)\n",
    "    r0 = recall_score(Y_test, predictions, pos_label=0, zero_division=0)\n",
    "    f1_0 = f1_score(Y_test, predictions, pos_label=0, zero_division=0)\n",
    "\n",
    "    p1 = precision_score(Y_test, predictions, pos_label=1, zero_division=0)\n",
    "    r1 = recall_score(Y_test, predictions, pos_label=1, zero_division=0)\n",
    "    f1_1 = f1_score(Y_test, predictions, pos_label=1, zero_division=0)\n",
    "\n",
    "    print(f\"\\nDetailed Metrics:\")\n",
    "    print(f\"  Winner 0: Precision={p0:.3f}, Recall={r0:.3f}, F1={f1_0:.3f}\")\n",
    "    print(f\"  Winner 1: Precision={p1:.3f}, Recall={r1:.3f}, F1={f1_1:.3f}\")\n",
    "\n",
    "    # Sample predictions\n",
    "    if verbose:\n",
    "        print(f\"\\nSample Predictions:\")\n",
    "        for i in range(min(10, len(predictions))):\n",
    "            status = \"✓\" if predictions[i] == Y_test[i] else \"✗\"\n",
    "            print(f\"  {status} Actual={Y_test[i]}, Predicted={predictions[i]}\")\n",
    "\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return {\n",
    "        'accuracy': overall_acc,\n",
    "        'predictions': predictions,\n",
    "        'labels': Y_test,\n",
    "        'confusion_matrix': cm,\n",
    "        'metrics': {'p0': p0, 'r0': r0, 'f1_0': f1_0, 'p1': p1, 'r1': r1, 'f1_1': f1_1}\n",
    "    }"
   ],
   "id": "5feccd4e2254f885",
   "outputs": [],
   "execution_count": 380
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:06:33.292994Z",
     "start_time": "2025-12-07T21:06:33.237930Z"
    }
   },
   "cell_type": "code",
   "source": "results = evaluate_model(num_test_games=200)\n",
   "id": "2a5fa0dfa43a2d2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from TsetlinMachine/hex_tm_model.pkl...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'number_of_clauses'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[381], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_test_games\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[380], line 8\u001B[0m, in \u001B[0;36mevaluate_model\u001B[0;34m(model_path, num_test_games, verbose)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Complete model evaluation\"\"\"\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Load model\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m tm, metadata \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m board_dim \u001B[38;5;241m=\u001B[39m metadata[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mboard_dim\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "Cell \u001B[0;32mIn[376], line 28\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath)\u001B[0m\n\u001B[1;32m     24\u001B[0m         metadata[key] \u001B[38;5;241m=\u001B[39m value\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Create model with saved parameters\u001B[39;00m\n\u001B[1;32m     27\u001B[0m tm \u001B[38;5;241m=\u001B[39m MultiClassGraphTsetlinMachine(\n\u001B[0;32m---> 28\u001B[0m     number_of_clauses\u001B[38;5;241m=\u001B[39m\u001B[43mstate_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnumber_of_clauses\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m,\n\u001B[1;32m     29\u001B[0m     T\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     30\u001B[0m     s\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     31\u001B[0m     q\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     32\u001B[0m     max_included_literals\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_included_literals\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     33\u001B[0m     boost_true_positive_feedback\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mboost_true_positive_feedback\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     34\u001B[0m     number_of_state_bits\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumber_of_state_bits\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     35\u001B[0m     depth\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdepth\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     36\u001B[0m     message_size\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage_size\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     37\u001B[0m     message_bits\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage_bits\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     38\u001B[0m     double_hashing\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdouble_hashing\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     39\u001B[0m     one_hot_encoding\u001B[38;5;241m=\u001B[39mstate_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mone_hot_encoding\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     40\u001B[0m )\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# Load state using built-in load() method\u001B[39;00m\n\u001B[1;32m     43\u001B[0m tm\u001B[38;5;241m.\u001B[39mload(fname\u001B[38;5;241m=\u001B[39mfilepath)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'number_of_clauses'"
     ]
    }
   ],
   "execution_count": 381
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "92a23b5a504e4050"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
