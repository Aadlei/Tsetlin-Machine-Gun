{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Methods - Optimized Version",
   "id": "4e5dbf9bcd5c3f2d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T11:55:23.022020Z",
     "start_time": "2025-12-05T11:55:22.987065Z"
    }
   },
   "source": [
    "from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "from GraphTsetlinMachine.graphs import Graphs\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "BOARD_DIM = 11\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"Tsetlin.ipynb\"))\n",
    "HEX_DIR = os.path.join(NOTEBOOK_DIR, \"TsetlinMachine/hex\")\n",
    "\n",
    "if not os.path.exists(HEX_DIR):\n",
    "    raise FileNotFoundError(f\"ERROR: Cannot find hex.c at {HEX_DIR}\")\n",
    "\n",
    "print(\"Building hex using make...\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"make\"],\n",
    "        cwd=HEX_DIR,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    print(\"=== Make Output ===\")\n",
    "    print(result.stdout)\n",
    "    if result.stderr.strip():\n",
    "        print(\"=== Make Errors ===\")\n",
    "        print(result.stderr)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n✓ Build successful!\")\n",
    "    else:\n",
    "        print(\"\\n❌ Build failed! See errors above.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Exception when running make:\", e)\n",
    "\n",
    "def c_position_to_node_id(c_position, board_dim=BOARD_DIM):\n",
    "    padded_dim = board_dim + 2\n",
    "    i = c_position // padded_dim\n",
    "    j = c_position % padded_dim\n",
    "    node_id = (i - 1) * board_dim + (j - 1)\n",
    "\n",
    "    if node_id < 0 or node_id >= board_dim * board_dim:\n",
    "        return None\n",
    "    return node_id\n",
    "\n",
    "def get_hex_edges(board_dim=BOARD_DIM):\n",
    "    edges = []\n",
    "    neighbor_offsets = [(0, 1), (0, -1), (-1, 1), (1, -1), (-1, 0), (1, 0)]\n",
    "\n",
    "    for i in range(board_dim):\n",
    "        for j in range(board_dim):\n",
    "            node_id = i * board_dim + j\n",
    "            for di, dj in neighbor_offsets:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < board_dim and 0 <= nj < board_dim:\n",
    "                    neighbor_id = ni * board_dim + nj\n",
    "                    edges.append((node_id, neighbor_id))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def parse_game_output(output):\n",
    "    games = []\n",
    "    current_game = None\n",
    "\n",
    "    for line in output.split('\\n'):\n",
    "        line = line.strip()\n",
    "\n",
    "        if line == \"GAME_START\":\n",
    "            current_game = {'moves': [], 'winner': -1}\n",
    "        elif line.startswith(\"MOVE\"):\n",
    "            if current_game is not None:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 3:\n",
    "                    position = int(parts[1])\n",
    "                    player = int(parts[2])\n",
    "                    current_game['moves'].append((position, player))\n",
    "        elif line.startswith(\"WINNER\"):\n",
    "            if current_game is not None:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    current_game['winner'] = int(parts[1])\n",
    "        elif line == \"GAME_END\":\n",
    "            if current_game and current_game['winner'] != -1:\n",
    "                games.append(current_game)\n",
    "            current_game = None\n",
    "\n",
    "    return games\n",
    "\n",
    "def create_training_data_from_game(moves, winner, board_dim=BOARD_DIM):\n",
    "    \"\"\"\n",
    "    Create ONE training sample per game:\n",
    "      - board_state: final board (0=empty, 1=player0, 2=player1)\n",
    "      - label: winner of the game (0 or 1)\n",
    "\n",
    "    We keep node_features as before for compatibility, but the main\n",
    "    object we care about is the final board_state.\n",
    "    \"\"\"\n",
    "    num_nodes = board_dim * board_dim\n",
    "    board_state = np.zeros(num_nodes, dtype=np.int32)\n",
    "    edges = get_hex_edges(board_dim)  # not used in new Graphs, but kept\n",
    "\n",
    "    # Play through the whole game to get the final board\n",
    "    for c_position, player in moves:\n",
    "        node_id = c_position_to_node_id(c_position, board_dim)\n",
    "        if node_id is None:\n",
    "            print(f\"Skipping invalid move: c_pos={c_position}\")\n",
    "            continue\n",
    "        board_state[node_id] = player + 1  # 1 = player 0, 2 = player 1\n",
    "\n",
    "    # Build node_features from the FINAL full board_state\n",
    "    node_features = np.zeros((num_nodes, 3), dtype=np.int32)\n",
    "    for nid in range(num_nodes):\n",
    "        if board_state[nid] == 1:\n",
    "            node_features[nid, 0] = 1  # player_0 stone\n",
    "        elif board_state[nid] == 2:\n",
    "            node_features[nid, 1] = 1  # player_1 stone\n",
    "        else:\n",
    "            node_features[nid, 2] = 1  # empty\n",
    "\n",
    "    label = int(winner)  # 0 or 1\n",
    "\n",
    "    sample = {\n",
    "        'board_state': board_state.reshape(board_dim, board_dim),\n",
    "        'node_features': node_features,   # still there if you need it\n",
    "        'edges': edges,                   # unused in new Graph building\n",
    "        'position': -1,                   # not used now\n",
    "        'player': -1,                     # not used now\n",
    "        'label': label\n",
    "    }\n",
    "\n",
    "    # Return as a list to match old API\n",
    "    return [sample]\n",
    "\n",
    "\n",
    "def prepare_training_data(games, board_dim=BOARD_DIM):\n",
    "    \"\"\"\n",
    "    Turn a list of games into a list of FINAL-state → winner samples.\n",
    "    Exactly one sample per game.\n",
    "    \"\"\"\n",
    "    all_samples = []\n",
    "\n",
    "    print(f\"Processing {len(games)} games into training samples...\")\n",
    "\n",
    "    # Game-level statistics\n",
    "    player_0_wins = sum(1 for g in games if g['winner'] == 0)\n",
    "    player_1_wins = sum(1 for g in games if g['winner'] == 1)\n",
    "    print(f\"Game outcomes (per game):\")\n",
    "    print(f\"  Player 0 wins: {player_0_wins}\")\n",
    "    print(f\"  Player 1 wins: {player_1_wins}\")\n",
    "\n",
    "    for game in tqdm(games, desc=\"Processing games\"):\n",
    "        samples = create_training_data_from_game(game['moves'], game['winner'], board_dim)\n",
    "        all_samples.extend(samples)\n",
    "\n",
    "    if len(all_samples) == 0:\n",
    "        print(\"ERROR: No training samples created! Check your logic.\")\n",
    "        return all_samples\n",
    "\n",
    "    labels = [s['label'] for s in all_samples]\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"\\nLabel distribution (winner classes, per FINAL board):\")\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"  Winner {label}: {count} games ({count/len(labels)*100:.1f}%)\")\n",
    "\n",
    "    # Quick sanity check of final board states\n",
    "    print(\"\\nSample final board state check (first 5 samples):\")\n",
    "    for i in range(min(5, len(all_samples))):\n",
    "        sample = all_samples[i]\n",
    "        pieces = np.sum(sample['node_features'][:, :2])\n",
    "        empties = np.sum(sample['node_features'][:, 2])\n",
    "        print(f\"  Sample {i}: {pieces} stones, {empties} empty cells, label(winner)={sample['label']}\")\n",
    "\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    return all_samples\n",
    "\n",
    "\n",
    "def generate_game_data(num_games=1000, hex_dir=HEX_DIR):\n",
    "    hex_executable = os.path.join(hex_dir, \"hex\")\n",
    "\n",
    "    if not os.path.exists(hex_executable):\n",
    "        print(f\"Executable not found at {hex_executable}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Generating {num_games} games...\")\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [hex_executable, str(num_games)],\n",
    "            cwd=hex_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=120\n",
    "        )\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error running hex executable:\")\n",
    "            print(result.stderr)\n",
    "            return []\n",
    "\n",
    "        games = parse_game_output(result.stdout)\n",
    "        print(f\"Successfully parsed {len(games)} games from output\")\n",
    "        return games\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running hex executable: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def prepare_gtm_data(training_samples, board_dim=BOARD_DIM):\n",
    "    Y = np.array([s['label'] for s in training_samples], dtype=np.int32)\n",
    "\n",
    "    symbols = ['player_0', 'player_1', 'empty']\n",
    "    num_nodes = board_dim * board_dim\n",
    "\n",
    "    print(\"Creating Graphs object...\")\n",
    "    graphs = Graphs(\n",
    "        number_of_graphs=len(training_samples),\n",
    "        symbols=symbols,\n",
    "        hypervector_size=1024,\n",
    "        hypervector_bits=2,\n",
    "        double_hashing=False\n",
    "    )\n",
    "\n",
    "    print(\"Setting number of nodes...\")\n",
    "    for graph_id in tqdm(range(len(training_samples)), desc=\"Setting nodes\"):\n",
    "        graphs.set_number_of_graph_nodes(graph_id, num_nodes)\n",
    "\n",
    "    graphs.prepare_node_configuration()\n",
    "\n",
    "    print(\"Adding nodes...\")\n",
    "    hex_edges = get_hex_edges(board_dim)\n",
    "    edge_counts = np.zeros(num_nodes, dtype=np.uint32)\n",
    "    for node_id, _ in hex_edges:\n",
    "        edge_counts[node_id] += 1\n",
    "\n",
    "    for graph_id in tqdm(range(len(training_samples)), desc=\"Adding nodes\"):\n",
    "        for node_id in range(num_nodes):\n",
    "            graphs.add_graph_node(graph_id, node_id, edge_counts[node_id])\n",
    "\n",
    "    graphs.prepare_edge_configuration()\n",
    "\n",
    "    print(\"Adding edges...\")\n",
    "    edge_data = []\n",
    "    for node_id, neighbor_id in hex_edges:\n",
    "        edge_type_id = graphs.edge_type_id.get(\"hex_neighbor\")\n",
    "        if edge_type_id is None:\n",
    "            graphs.edge_type_id[\"hex_neighbor\"] = len(graphs.edge_type_id)\n",
    "            edge_type_id = graphs.edge_type_id[\"hex_neighbor\"]\n",
    "        edge_data.append((node_id, neighbor_id, edge_type_id))\n",
    "\n",
    "    for graph_id in tqdm(range(len(training_samples)), desc=\"Adding edges\"):\n",
    "        node_index = graphs.node_index[graph_id]\n",
    "        for source_node_id, dest_node_id, edge_type_id in edge_data:\n",
    "            edge_idx = (graphs.edge_index[node_index + source_node_id] +\n",
    "                       graphs.graph_node_edge_counter[node_index + source_node_id])\n",
    "            graphs.edge[edge_idx][0] = dest_node_id\n",
    "            graphs.edge[edge_idx][1] = edge_type_id\n",
    "            graphs.graph_node_edge_counter[node_index + source_node_id] += 1\n",
    "\n",
    "    print(\"Adding node properties...\")\n",
    "    for graph_id in tqdm(range(len(training_samples)), desc=\"Adding properties\"):\n",
    "        node_features = training_samples[graph_id]['node_features']\n",
    "        for node_id in range(num_nodes):\n",
    "            if node_features[node_id, 0] == 1:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"player_0\")\n",
    "            elif node_features[node_id, 1] == 1:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"player_1\")\n",
    "            else:\n",
    "                graphs.add_graph_node_property(graph_id, node_id, \"empty\")\n",
    "\n",
    "    print(\"Encoding graphs...\")\n",
    "    graphs.encode()\n",
    "\n",
    "    print(f\"\\n✓ Prepared {len(training_samples)} graphs\")\n",
    "    print(f\"  Nodes per graph: {num_nodes}\")\n",
    "    print(f\"  Features per node: {len(symbols)}\")\n",
    "\n",
    "    return graphs, Y\n",
    "\n",
    "\n",
    "def train_model(graphs, Y, epochs=100):\n",
    "    \"\"\"\n",
    "    Train a MultiClassGraphTsetlinMachine to predict the WINNER (0 or 1)\n",
    "    from a given board state.\n",
    "    \"\"\"\n",
    "    NUMBER_OF_CLAUSES = 12000\n",
    "    T = 100\n",
    "    S = 5.0\n",
    "    DEPTH = 2\n",
    "    MESSAGE_SIZE = 128\n",
    "    MESSAGE_BITS = 2\n",
    "\n",
    "    print(\"Initializing Graph Tsetlin Machine...\")\n",
    "    print(f\"  Clauses: {NUMBER_OF_CLAUSES}\")\n",
    "    print(f\"  T: {T}\")\n",
    "    print(f\"  s: {S}\")\n",
    "    print(f\"  Depth: {DEPTH}\")\n",
    "    print(f\"  Message Size: {MESSAGE_SIZE}\")\n",
    "\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        number_of_clauses=NUMBER_OF_CLAUSES,\n",
    "        T=T,\n",
    "        s=S,\n",
    "        number_of_state_bits=8,\n",
    "        depth=DEPTH,\n",
    "        message_size=MESSAGE_SIZE,\n",
    "        message_bits=MESSAGE_BITS,\n",
    "        max_included_literals=32,\n",
    "        grid=(16 * 13, 1, 1),\n",
    "        block=(128, 1, 1)\n",
    "    )\n",
    "\n",
    "    # Class balancing: oversample minority class of winner\n",
    "    class_0_indices = np.where(Y == 0)[0]\n",
    "    class_1_indices = np.where(Y == 1)[0]\n",
    "\n",
    "    print(f\"\\nClass distribution before balancing (winner classes):\")\n",
    "    print(f\"  Winner 0: {len(class_0_indices)} states\")\n",
    "    print(f\"  Winner 1: {len(class_1_indices)} states\")\n",
    "\n",
    "    if len(class_0_indices) > 0 and len(class_1_indices) > 0:\n",
    "        # Balance by repeating minority class\n",
    "        if len(class_0_indices) < len(class_1_indices):\n",
    "            oversample_ratio = len(class_1_indices) // len(class_0_indices)\n",
    "            class_0_indices = np.tile(class_0_indices, oversample_ratio)\n",
    "        else:\n",
    "            oversample_ratio = len(class_0_indices) // len(class_1_indices)\n",
    "            class_1_indices = np.tile(class_1_indices, oversample_ratio)\n",
    "\n",
    "        balanced_indices = np.concatenate([class_0_indices, class_1_indices])\n",
    "        np.random.shuffle(balanced_indices)\n",
    "        print(f\"After balancing: {len(balanced_indices)} total samples\")\n",
    "    else:\n",
    "        balanced_indices = np.arange(len(Y))\n",
    "        print(\"Warning: only one winner class present; no balancing applied.\")\n",
    "\n",
    "    print(f\"\\nStarting training for {epochs} epochs...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    start_total = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        # NOTE: current GTM implementation uses full graph set; balancing\n",
    "        # is mainly informational here. To actually subsample, GTM would need\n",
    "        # support for graph subsets.\n",
    "        tm.fit(graphs, Y, epochs=1, incremental=True)\n",
    "        elapsed = time.time() - start_epoch\n",
    "\n",
    "        predictions = tm.predict(graphs)\n",
    "        accuracy = 100 * (predictions == Y).mean()\n",
    "\n",
    "        class_0_mask = (Y == 0)\n",
    "        class_1_mask = (Y == 1)\n",
    "        class_0_acc = 100 * (predictions[class_0_mask] == 0).mean() if class_0_mask.any() else 0\n",
    "        class_1_acc = 100 * (predictions[class_1_mask] == 1).mean() if class_1_mask.any() else 0\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Acc: {accuracy:.2f}% \"\n",
    "              f\"(Winner 0 states: {class_0_acc:.1f}%, Winner 1 states: {class_1_acc:.1f}%) - {elapsed:.2f}s\")\n",
    "\n",
    "    total_time = time.time() - start_total\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"✓ Training completed in {total_time:.2f}s ({total_time/60:.2f} minutes)\")\n",
    "\n",
    "    print(\"\\nFinal Evaluation...\")\n",
    "    predictions = tm.predict(graphs)\n",
    "\n",
    "    accuracy = 100 * (predictions == Y).mean()\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    for class_id in [0, 1]:\n",
    "        mask = Y == class_id\n",
    "        if mask.any():\n",
    "            class_acc = 100 * (predictions[mask] == class_id).mean()\n",
    "            print(f\"Winner {class_id} states: {class_acc:.2f}% \"\n",
    "                  f\"({(predictions[mask] == class_id).sum()}/{mask.sum()})\")\n",
    "\n",
    "    return tm, predictions\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building hex using make...\n",
      "=== Make Output ===\n",
      "make: 'hex' is up to date.\n",
      "\n",
      "\n",
      "✓ Build successful!\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Game Data\n",
    "\n",
    "Run this cell to generate Hex games and create training samples."
   ],
   "id": "generate_data_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-05T11:55:23.046452Z"
    }
   },
   "source": [
    "# Generate games\n",
    "NUM_GAMES = 1000000  # Adjust as needed\n",
    "\n",
    "print(f\"Generating {NUM_GAMES} Hex games...\")\n",
    "games = generate_game_data(NUM_GAMES)\n",
    "\n",
    "if not games:\n",
    "    raise Exception(\"No games generated! Check hex executable.\")\n",
    "\n",
    "print(f\"\\n✓ Successfully generated {len(games)} games\")\n",
    "\n",
    "# Process into training samples (FINAL state -> winner)\n",
    "training_samples = prepare_training_data(games, BOARD_DIM)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC: Checking final board states:\")\n",
    "print(\"=\"*60)\n",
    "for i in range(min(10, len(training_samples))):\n",
    "    sample = training_samples[i]\n",
    "    non_zero = np.sum(sample['node_features'][:, :2])  # Count player pieces\n",
    "    empty = np.sum(sample['node_features'][:, 2])      # Count empty cells\n",
    "    print(f\"Sample {i}: {non_zero} stones on board, {empty} empty cells, label(winner)={sample['label']}\")\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(f\"\\n✓ Training data ready: {len(training_samples)} samples\")\n"
   ],
   "id": "generate_data_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1000000 Hex games...\n",
      "Generating 1000000 games...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Graph Tsetlin Machine\n",
    "\n",
    "Convert training samples into the GTM Graphs format."
   ],
   "id": "prepare_gtm_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:53:45.553944Z",
     "start_time": "2025-12-05T11:53:45.000412Z"
    }
   },
   "source": [
    "from GraphTsetlinMachine.graphs import Graphs\n",
    "\n",
    "# Extract labels (winner 0/1 per FINAL board)\n",
    "Y = np.array([s['label'] for s in training_samples], dtype=np.uint32)\n",
    "\n",
    "print(\"Preparing data in GTM Graphs format (MNIST-style)...\")\n",
    "\n",
    "# --- Define symbols: one for each (player, cell) ---\n",
    "\n",
    "symbols = []\n",
    "for i in range(BOARD_DIM):\n",
    "    for j in range(BOARD_DIM):\n",
    "        symbols.append(f\"P0_{i}_{j}\")  # player 0 stone at (i,j)\n",
    "        symbols.append(f\"P1_{i}_{j}\")  # player 1 stone at (i,j)\n",
    "\n",
    "num_nodes = 1  # ONE node per graph, just like 'Image Node' in MNIST example\n",
    "\n",
    "graphs = Graphs(\n",
    "    number_of_graphs=len(training_samples),\n",
    "    symbols=symbols,\n",
    "    hypervector_size=128,\n",
    "    hypervector_bits=2,\n",
    "    double_hashing=False,\n",
    "    # one_hot_encoding=False by default unless you want one-hot\n",
    ")\n",
    "\n",
    "print(\"Step 1: Setting number of nodes for each graph to 1...\")\n",
    "for graph_id in range(len(training_samples)):\n",
    "    graphs.set_number_of_graph_nodes(graph_id, num_nodes)\n",
    "\n",
    "print(\"Step 2: Preparing node configuration...\")\n",
    "graphs.prepare_node_configuration()\n",
    "\n",
    "print(\"Step 3: Adding the single 'Board' node to each graph...\")\n",
    "for graph_id in range(len(training_samples)):\n",
    "    number_of_outgoing_edges = 0  # we don't use edges here\n",
    "    graphs.add_graph_node(graph_id, 'Board', number_of_outgoing_edges)\n",
    "\n",
    "print(\"Step 4: Preparing edge configuration (no edges, but required call)...\")\n",
    "graphs.prepare_edge_configuration()\n",
    "\n",
    "print(\"Step 5: Adding node properties based on FINAL board state...\")\n",
    "\n",
    "for graph_id in range(len(training_samples)):\n",
    "    if graph_id % 1000 == 0:\n",
    "        print(f\"  Processing graph {graph_id}/{len(training_samples)}\")\n",
    "\n",
    "    # node_features: shape (board_dim^2, 3)\n",
    "    node_features = training_samples[graph_id]['node_features']\n",
    "\n",
    "    for node_id in range(BOARD_DIM * BOARD_DIM):\n",
    "        i = node_id // BOARD_DIM\n",
    "        j = node_id % BOARD_DIM\n",
    "\n",
    "        if node_features[node_id, 0] == 1:\n",
    "            # Player 0 stone at (i,j)\n",
    "            graphs.add_graph_node_property(graph_id, 'Board', f\"P0_{i}_{j}\")\n",
    "        elif node_features[node_id, 1] == 1:\n",
    "            # Player 1 stone at (i,j)\n",
    "            graphs.add_graph_node_property(graph_id, 'Board', f\"P1_{i}_{j}\")\n",
    "        # empty cells add no property\n",
    "\n",
    "print(\"Step 6: Encoding graphs...\")\n",
    "graphs.encode()\n",
    "\n",
    "print(f\"\\n✓ Prepared {len(training_samples)} graphs\")\n",
    "print(f\"  Nodes per graph: {num_nodes}\")\n",
    "print(f\"  Symbols per graph node: up to {BOARD_DIM*BOARD_DIM*2} (stones only)\")\n",
    "unique_labels, label_counts = np.unique(Y, return_counts=True)\n",
    "label_dist = \", \".join([f\"Winner {label}={count}\" for label, count in zip(unique_labels, label_counts)])\n",
    "print(f\"  Label distribution: {label_dist}\")\n"
   ],
   "id": "prepare_gtm_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data in GTM Graphs format (MNIST-style)...\n",
      "Step 1: Setting number of nodes for each graph to 1...\n",
      "Step 2: Preparing node configuration...\n",
      "Step 3: Adding the single 'Board' node to each graph...\n",
      "Step 4: Preparing edge configuration (no edges, but required call)...\n",
      "Step 5: Adding node properties based on FINAL board state...\n",
      "  Processing graph 0/1000\n",
      "Step 6: Encoding graphs...\n",
      "\n",
      "✓ Prepared 1000 graphs\n",
      "  Nodes per graph: 1\n",
      "  Symbols per graph node: up to 242 (stones only)\n",
      "  Label distribution: Winner 0=505, Winner 1=495\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Graph Tsetlin Machine\n",
    "\n",
    "Train the model on the prepared graph data."
   ],
   "id": "train_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:54:19.096125Z",
     "start_time": "2025-12-05T11:53:45.580757Z"
    }
   },
   "source": "tm, predictions = train_model(graphs, Y, epochs=100)",
   "id": "train_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Graph Tsetlin Machine...\n",
      "  Clauses: 12000\n",
      "  T: 100\n",
      "  s: 5.0\n",
      "  Depth: 2\n",
      "  Message Size: 128\n",
      "Initialization of sparse structure.\n",
      "\n",
      "Class distribution before balancing (winner classes):\n",
      "  Winner 0: 505 states\n",
      "  Winner 1: 495 states\n",
      "After balancing: 1000 total samples\n",
      "\n",
      "Starting training for 100 epochs...\n",
      "============================================================\n",
      "Epoch 1/100 - Acc: 49.60% (Winner 0 states: 0.2%, Winner 1 states: 100.0%) - 0.92s\n",
      "Epoch 2/100 - Acc: 49.80% (Winner 0 states: 0.6%, Winner 1 states: 100.0%) - 0.23s\n",
      "Epoch 3/100 - Acc: 50.90% (Winner 0 states: 3.2%, Winner 1 states: 99.6%) - 0.24s\n",
      "Epoch 4/100 - Acc: 54.20% (Winner 0 states: 11.7%, Winner 1 states: 97.6%) - 0.24s\n",
      "Epoch 5/100 - Acc: 56.30% (Winner 0 states: 17.0%, Winner 1 states: 96.4%) - 0.25s\n",
      "Epoch 6/100 - Acc: 57.70% (Winner 0 states: 20.2%, Winner 1 states: 96.0%) - 0.24s\n",
      "Epoch 7/100 - Acc: 59.10% (Winner 0 states: 97.6%, Winner 1 states: 19.8%) - 0.24s\n",
      "Epoch 8/100 - Acc: 69.80% (Winner 0 states: 56.4%, Winner 1 states: 83.4%) - 0.23s\n",
      "Epoch 9/100 - Acc: 58.40% (Winner 0 states: 97.8%, Winner 1 states: 18.2%) - 0.24s\n",
      "Epoch 10/100 - Acc: 62.20% (Winner 0 states: 97.6%, Winner 1 states: 26.1%) - 0.23s\n",
      "Epoch 11/100 - Acc: 66.60% (Winner 0 states: 97.0%, Winner 1 states: 35.6%) - 0.23s\n",
      "Epoch 12/100 - Acc: 67.30% (Winner 0 states: 96.6%, Winner 1 states: 37.4%) - 0.23s\n",
      "Epoch 13/100 - Acc: 75.20% (Winner 0 states: 89.1%, Winner 1 states: 61.0%) - 0.23s\n",
      "Epoch 14/100 - Acc: 72.20% (Winner 0 states: 93.3%, Winner 1 states: 50.7%) - 0.23s\n",
      "Epoch 15/100 - Acc: 77.70% (Winner 0 states: 89.5%, Winner 1 states: 65.7%) - 0.23s\n",
      "Epoch 16/100 - Acc: 73.60% (Winner 0 states: 53.5%, Winner 1 states: 94.1%) - 0.23s\n",
      "Epoch 17/100 - Acc: 78.30% (Winner 0 states: 92.5%, Winner 1 states: 63.8%) - 0.22s\n",
      "Epoch 18/100 - Acc: 68.20% (Winner 0 states: 39.0%, Winner 1 states: 98.0%) - 0.22s\n",
      "Epoch 19/100 - Acc: 77.00% (Winner 0 states: 59.2%, Winner 1 states: 95.2%) - 0.23s\n",
      "Epoch 20/100 - Acc: 72.30% (Winner 0 states: 98.2%, Winner 1 states: 45.9%) - 0.23s\n",
      "Epoch 21/100 - Acc: 80.40% (Winner 0 states: 95.6%, Winner 1 states: 64.8%) - 0.22s\n",
      "Epoch 22/100 - Acc: 76.40% (Winner 0 states: 97.0%, Winner 1 states: 55.4%) - 0.22s\n",
      "Epoch 23/100 - Acc: 69.10% (Winner 0 states: 98.8%, Winner 1 states: 38.8%) - 0.22s\n",
      "Epoch 24/100 - Acc: 71.30% (Winner 0 states: 98.4%, Winner 1 states: 43.6%) - 0.22s\n",
      "Epoch 25/100 - Acc: 79.80% (Winner 0 states: 96.2%, Winner 1 states: 63.0%) - 0.21s\n",
      "Epoch 26/100 - Acc: 74.40% (Winner 0 states: 98.2%, Winner 1 states: 50.1%) - 0.21s\n",
      "Epoch 27/100 - Acc: 81.40% (Winner 0 states: 96.8%, Winner 1 states: 65.7%) - 0.21s\n",
      "Epoch 28/100 - Acc: 85.60% (Winner 0 states: 86.3%, Winner 1 states: 84.8%) - 0.21s\n",
      "Epoch 29/100 - Acc: 82.40% (Winner 0 states: 69.9%, Winner 1 states: 95.2%) - 0.21s\n",
      "Epoch 30/100 - Acc: 72.60% (Winner 0 states: 99.4%, Winner 1 states: 45.3%) - 0.21s\n",
      "Epoch 31/100 - Acc: 84.20% (Winner 0 states: 72.7%, Winner 1 states: 96.0%) - 0.21s\n",
      "Epoch 32/100 - Acc: 86.60% (Winner 0 states: 77.8%, Winner 1 states: 95.6%) - 0.21s\n",
      "Epoch 33/100 - Acc: 78.10% (Winner 0 states: 99.4%, Winner 1 states: 56.4%) - 0.21s\n",
      "Epoch 34/100 - Acc: 78.40% (Winner 0 states: 58.8%, Winner 1 states: 98.4%) - 0.21s\n",
      "Epoch 35/100 - Acc: 86.40% (Winner 0 states: 96.0%, Winner 1 states: 76.6%) - 0.21s\n",
      "Epoch 36/100 - Acc: 74.30% (Winner 0 states: 99.6%, Winner 1 states: 48.5%) - 0.21s\n",
      "Epoch 37/100 - Acc: 86.40% (Winner 0 states: 75.2%, Winner 1 states: 97.8%) - 0.21s\n",
      "Epoch 38/100 - Acc: 88.10% (Winner 0 states: 96.0%, Winner 1 states: 80.0%) - 0.21s\n",
      "Epoch 39/100 - Acc: 77.20% (Winner 0 states: 98.8%, Winner 1 states: 55.2%) - 0.21s\n",
      "Epoch 40/100 - Acc: 90.40% (Winner 0 states: 91.5%, Winner 1 states: 89.3%) - 0.21s\n",
      "Epoch 41/100 - Acc: 74.30% (Winner 0 states: 99.6%, Winner 1 states: 48.5%) - 0.21s\n",
      "Epoch 42/100 - Acc: 80.70% (Winner 0 states: 62.6%, Winner 1 states: 99.2%) - 0.21s\n",
      "Epoch 43/100 - Acc: 87.50% (Winner 0 states: 97.2%, Winner 1 states: 77.6%) - 0.21s\n",
      "Epoch 44/100 - Acc: 83.30% (Winner 0 states: 68.1%, Winner 1 states: 98.8%) - 0.20s\n",
      "Epoch 45/100 - Acc: 88.50% (Winner 0 states: 96.2%, Winner 1 states: 80.6%) - 0.20s\n",
      "Epoch 46/100 - Acc: 87.80% (Winner 0 states: 97.6%, Winner 1 states: 77.8%) - 0.20s\n",
      "Epoch 47/100 - Acc: 81.40% (Winner 0 states: 63.6%, Winner 1 states: 99.6%) - 0.20s\n",
      "Epoch 48/100 - Acc: 84.90% (Winner 0 states: 70.9%, Winner 1 states: 99.2%) - 0.20s\n",
      "Epoch 49/100 - Acc: 92.80% (Winner 0 states: 91.9%, Winner 1 states: 93.7%) - 0.20s\n",
      "Epoch 50/100 - Acc: 84.80% (Winner 0 states: 70.5%, Winner 1 states: 99.4%) - 0.20s\n",
      "Epoch 51/100 - Acc: 91.80% (Winner 0 states: 97.2%, Winner 1 states: 86.3%) - 0.20s\n",
      "Epoch 52/100 - Acc: 85.60% (Winner 0 states: 71.7%, Winner 1 states: 99.8%) - 0.20s\n",
      "Epoch 53/100 - Acc: 80.20% (Winner 0 states: 61.4%, Winner 1 states: 99.4%) - 0.20s\n",
      "Epoch 54/100 - Acc: 92.60% (Winner 0 states: 93.1%, Winner 1 states: 92.1%) - 0.20s\n",
      "Epoch 55/100 - Acc: 88.30% (Winner 0 states: 78.4%, Winner 1 states: 98.4%) - 0.20s\n",
      "Epoch 56/100 - Acc: 81.00% (Winner 0 states: 63.2%, Winner 1 states: 99.2%) - 0.20s\n",
      "Epoch 57/100 - Acc: 93.90% (Winner 0 states: 95.2%, Winner 1 states: 92.5%) - 0.20s\n",
      "Epoch 58/100 - Acc: 87.50% (Winner 0 states: 98.0%, Winner 1 states: 76.8%) - 0.20s\n",
      "Epoch 59/100 - Acc: 93.60% (Winner 0 states: 89.7%, Winner 1 states: 97.6%) - 0.20s\n",
      "Epoch 60/100 - Acc: 91.60% (Winner 0 states: 85.0%, Winner 1 states: 98.4%) - 0.20s\n",
      "Epoch 61/100 - Acc: 87.30% (Winner 0 states: 99.2%, Winner 1 states: 75.2%) - 0.20s\n",
      "Epoch 62/100 - Acc: 84.80% (Winner 0 states: 70.3%, Winner 1 states: 99.6%) - 0.20s\n",
      "Epoch 63/100 - Acc: 82.00% (Winner 0 states: 64.6%, Winner 1 states: 99.8%) - 0.20s\n",
      "Epoch 64/100 - Acc: 91.80% (Winner 0 states: 85.7%, Winner 1 states: 98.0%) - 0.20s\n",
      "Epoch 65/100 - Acc: 94.20% (Winner 0 states: 95.0%, Winner 1 states: 93.3%) - 0.20s\n",
      "Epoch 66/100 - Acc: 87.20% (Winner 0 states: 74.7%, Winner 1 states: 100.0%) - 0.20s\n",
      "Epoch 67/100 - Acc: 95.30% (Winner 0 states: 97.2%, Winner 1 states: 93.3%) - 0.20s\n",
      "Epoch 68/100 - Acc: 92.60% (Winner 0 states: 96.8%, Winner 1 states: 88.3%) - 0.20s\n",
      "Epoch 69/100 - Acc: 88.30% (Winner 0 states: 77.4%, Winner 1 states: 99.4%) - 0.20s\n",
      "Epoch 70/100 - Acc: 85.70% (Winner 0 states: 71.7%, Winner 1 states: 100.0%) - 0.20s\n",
      "Epoch 71/100 - Acc: 90.20% (Winner 0 states: 81.2%, Winner 1 states: 99.4%) - 0.20s\n",
      "Epoch 72/100 - Acc: 90.60% (Winner 0 states: 98.6%, Winner 1 states: 82.4%) - 0.20s\n",
      "Epoch 73/100 - Acc: 94.20% (Winner 0 states: 97.6%, Winner 1 states: 90.7%) - 0.20s\n",
      "Epoch 74/100 - Acc: 94.80% (Winner 0 states: 92.9%, Winner 1 states: 96.8%) - 0.20s\n",
      "Epoch 75/100 - Acc: 84.70% (Winner 0 states: 69.9%, Winner 1 states: 99.8%) - 0.20s\n",
      "Epoch 76/100 - Acc: 96.00% (Winner 0 states: 93.9%, Winner 1 states: 98.2%) - 0.19s\n",
      "Epoch 77/100 - Acc: 93.30% (Winner 0 states: 87.1%, Winner 1 states: 99.6%) - 0.20s\n",
      "Epoch 78/100 - Acc: 88.90% (Winner 0 states: 78.0%, Winner 1 states: 100.0%) - 0.19s\n",
      "Epoch 79/100 - Acc: 86.10% (Winner 0 states: 100.0%, Winner 1 states: 71.9%) - 0.20s\n",
      "Epoch 80/100 - Acc: 93.00% (Winner 0 states: 86.9%, Winner 1 states: 99.2%) - 0.20s\n",
      "Epoch 81/100 - Acc: 94.00% (Winner 0 states: 98.4%, Winner 1 states: 89.5%) - 0.20s\n",
      "Epoch 82/100 - Acc: 93.50% (Winner 0 states: 87.9%, Winner 1 states: 99.2%) - 0.20s\n",
      "Epoch 83/100 - Acc: 94.20% (Winner 0 states: 98.2%, Winner 1 states: 90.1%) - 0.20s\n",
      "Epoch 84/100 - Acc: 87.00% (Winner 0 states: 74.5%, Winner 1 states: 99.8%) - 0.20s\n",
      "Epoch 85/100 - Acc: 81.60% (Winner 0 states: 63.6%, Winner 1 states: 100.0%) - 0.19s\n",
      "Epoch 86/100 - Acc: 97.00% (Winner 0 states: 95.6%, Winner 1 states: 98.4%) - 0.19s\n",
      "Epoch 87/100 - Acc: 90.10% (Winner 0 states: 80.8%, Winner 1 states: 99.6%) - 0.19s\n",
      "Epoch 88/100 - Acc: 86.50% (Winner 0 states: 73.3%, Winner 1 states: 100.0%) - 0.20s\n",
      "Epoch 89/100 - Acc: 96.50% (Winner 0 states: 94.9%, Winner 1 states: 98.2%) - 0.20s\n",
      "Epoch 90/100 - Acc: 96.10% (Winner 0 states: 95.0%, Winner 1 states: 97.2%) - 0.20s\n",
      "Epoch 91/100 - Acc: 88.10% (Winner 0 states: 76.6%, Winner 1 states: 99.8%) - 0.20s\n",
      "Epoch 92/100 - Acc: 91.50% (Winner 0 states: 83.4%, Winner 1 states: 99.8%) - 0.20s\n",
      "Epoch 93/100 - Acc: 94.40% (Winner 0 states: 90.7%, Winner 1 states: 98.2%) - 0.20s\n",
      "Epoch 94/100 - Acc: 86.60% (Winner 0 states: 73.5%, Winner 1 states: 100.0%) - 0.20s\n",
      "Epoch 95/100 - Acc: 96.80% (Winner 0 states: 96.2%, Winner 1 states: 97.4%) - 0.19s\n",
      "Epoch 96/100 - Acc: 95.70% (Winner 0 states: 91.9%, Winner 1 states: 99.6%) - 0.20s\n",
      "Epoch 97/100 - Acc: 91.10% (Winner 0 states: 82.6%, Winner 1 states: 99.8%) - 0.19s\n",
      "Epoch 98/100 - Acc: 94.80% (Winner 0 states: 90.7%, Winner 1 states: 99.0%) - 0.19s\n",
      "Epoch 99/100 - Acc: 95.50% (Winner 0 states: 93.7%, Winner 1 states: 97.4%) - 0.19s\n",
      "Epoch 100/100 - Acc: 95.60% (Winner 0 states: 92.1%, Winner 1 states: 99.2%) - 0.19s\n",
      "\n",
      "============================================================\n",
      "✓ Training completed in 33.21s (0.55 minutes)\n",
      "\n",
      "Final Evaluation...\n",
      "\n",
      "Overall Accuracy: 95.60%\n",
      "Winner 0 states: 92.08% (465/505)\n",
      "Winner 1 states: 99.19% (491/495)\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Trained Model"
   ],
   "id": "save_model_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:54:19.160399Z",
     "start_time": "2025-12-05T11:54:19.146287Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "model_path = \"TsetlinMachine/hex_tm_model.pkl\"\n",
    "print(f\"Saving trained model to {model_path}...\")\n",
    "\n",
    "# Get the model state (weights, clauses, etc.) instead of the whole object\n",
    "model_state = tm.get_state()\n",
    "\n",
    "# Save the state along with model configuration\n",
    "model_save_data = {\n",
    "    'state': model_state,\n",
    "    'config': {\n",
    "        'number_of_clauses': tm.number_of_clauses,\n",
    "        'T': tm.T,\n",
    "        's': tm.s,\n",
    "        'number_of_state_bits': tm.number_of_state_bits,\n",
    "        'depth': tm.depth,\n",
    "        'message_size': tm.message_size,\n",
    "        'message_bits': tm.message_bits,\n",
    "        'max_included_literals': tm.max_included_literals,\n",
    "        'grid': (16 * 13, 1, 1),\n",
    "        'block': (128, 1, 1)\n",
    "    },\n",
    "    'symbols': symbols,\n",
    "    'num_nodes': num_nodes,\n",
    "    'board_dim': BOARD_DIM\n",
    "}\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model_save_data, f)\n",
    "\n",
    "print(\"✓ Model saved successfully\")\n",
    "\n",
    "# Show some example predictions\n",
    "print(\"\\nExample predictions (first 10):\")\n",
    "for i in range(min(10, len(predictions))):\n",
    "    pred = predictions[i]\n",
    "    true = Y[i]\n",
    "    status = \"✓\" if pred == true else \"✗\"\n",
    "    print(f\"{status} Sample {i}: Pred={pred}, True={true}\")"
   ],
   "id": "save_model_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model to TsetlinMachine/hex_tm_model.pkl...\n",
      "✓ Model saved successfully\n",
      "\n",
      "Example predictions (first 10):\n",
      "✓ Sample 0: Pred=1, True=1\n",
      "✓ Sample 1: Pred=0, True=0\n",
      "✓ Sample 2: Pred=1, True=1\n",
      "✓ Sample 3: Pred=0, True=0\n",
      "✓ Sample 4: Pred=1, True=1\n",
      "✓ Sample 5: Pred=0, True=0\n",
      "✓ Sample 6: Pred=1, True=1\n",
      "✓ Sample 7: Pred=1, True=1\n",
      "✓ Sample 8: Pred=0, True=0\n",
      "✓ Sample 9: Pred=1, True=1\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Trained Model (Optional)\n",
    "\n",
    "Use this to load a previously trained model."
   ],
   "id": "load_model_section"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:54:19.220261Z",
     "start_time": "2025-12-05T11:54:19.216531Z"
    }
   },
   "source": [
    "def load_trained_model(model_path):\n",
    "    \"\"\"Load a previously trained Tsetlin Machine\"\"\"\n",
    "    import pickle\n",
    "    from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "\n",
    "    # Recreate the model with saved configuration\n",
    "    config = model_data['config']\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        number_of_clauses=config['number_of_clauses'],\n",
    "        T=config['T'],\n",
    "        s=config['s'],\n",
    "        number_of_state_bits=config['number_of_state_bits'],\n",
    "        depth=config['depth'],\n",
    "        message_size=config['message_size'],\n",
    "        message_bits=config['message_bits'],\n",
    "        max_included_literals=config['max_included_literals'],\n",
    "        grid=config['grid'],\n",
    "        block=config['block']\n",
    "    )\n",
    "\n",
    "    # Restore the model state\n",
    "    tm.set_state(model_data['state'])\n",
    "\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "\n",
    "    return tm, model_data\n",
    "\n",
    "# Example usage:\n",
    "# loaded_tm, loaded_data = load_trained_model(\"TsetlinMachine/hex_tm_model.pkl\")"
   ],
   "id": "load_model_cell",
   "outputs": [],
   "execution_count": 130
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
