{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header_cell",
   "metadata": {},
   "source": [
    "# Hex Game - GTM Analysis & Experiments\n",
    "\n",
    "This notebook performs a comprehensive analysis of the Graph Tsetlin Machine (GTM) on the Hex game.\n",
    "It implements:\n",
    "1.  **Robust Data Generation**: Reproducible, seeded games (saved to CSV).\n",
    "2.  **End-Game Analysis**: Evaluation at Final, End-2, and End-5 moves.\n",
    "3.  **Parameter Search**: Experiments for Model Capacity (Clauses) and Message Passing (Depth).\n",
    "4.  **Scaling**: Flexible configuration for 3x3, 11x11, etc.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "imports",
   "metadata": {},
   "source": [
    "import os\n",
    "import pickle\n",
    "import subprocess\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import gc\n",
    "\n",
    "# Try importing GTM\n",
    "try:\n",
    "    from GraphTsetlinMachine.graphs import Graphs\n",
    "    from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "    HAS_GTM = True\n",
    "    print(\"‚úì GraphTsetlinMachine detected.\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: GraphTsetlinMachine not installed. Training will fail.\")\n",
    "    HAS_GTM = False\n",
    "\n",
    "# Set Plotting Style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 120"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "config",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "#            GLOBAL CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "BOARD_DIM = 11        # 7x7 board\n",
    "N_GAMES = 8000      # CRITICAL: Need MORE data for 7x7!\n",
    "SEED = 20\n",
    "\n",
    "# OPTIMIZED HYPERPARAMETERS FOR 7x7\n",
    "# These are specifically tuned for the connectivity problem\n",
    "if BOARD_DIM == 7:\n",
    "    # START CONSERVATIVE - we can scale up if needed\n",
    "    CLAUSES = 2000        # Moderate capacity\n",
    "    T = 50              # Not too permissive (prevents collapse)\n",
    "    S = 0.8              # Balanced feature selection\n",
    "    DEPTH = 3            # Moderate message passing\n",
    "    EPOCHS = 100          # More epochs to allow convergence\n",
    "    HYPERVECTOR_SIZE = 256\n",
    "    MESSAGE_SIZE = 256\n",
    "    GRID_MULT = 3\n",
    "\n",
    "\n",
    "elif BOARD_DIM == 3:\n",
    "    CLAUSES = 400\n",
    "    T = 400\n",
    "    S = 2.5\n",
    "    DEPTH = 3\n",
    "    EPOCHS = 100\n",
    "    HYPERVECTOR_SIZE = 256\n",
    "    MESSAGE_SIZE = 256\n",
    "    GRID_MULT = 1\n",
    "\n",
    "elif BOARD_DIM == 11:\n",
    "    CLAUSES = 2000\n",
    "    T = 60\n",
    "    S = 0.9\n",
    "    DEPTH = 3\n",
    "    EPOCHS = 40\n",
    "    HYPERVECTOR_SIZE = 1024\n",
    "    MESSAGE_SIZE = 1024\n",
    "    GRID_MULT = 4\n",
    "    USE_ROTATION_AUGMENTATION = True\n",
    "\n",
    "else:\n",
    "    # Fallback\n",
    "    CLAUSES = 200\n",
    "    T = 400\n",
    "    S = 2.5\n",
    "    DEPTH = 3\n",
    "    EPOCHS = 25\n",
    "    HYPERVECTOR_SIZE = 256\n",
    "    MESSAGE_SIZE = 256\n",
    "    GRID_MULT = 1\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  CONFIGURATION: {BOARD_DIM}x{BOARD_DIM} Hex Board\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Games:         {N_GAMES:,}\")\n",
    "print(f\"  Seed:          {SEED}\")\n",
    "print(f\"  Clauses:       {CLAUSES:,}\")\n",
    "print(f\"  T:             {T}\")\n",
    "print(f\"  S:             {S}\")\n",
    "print(f\"  Depth:         {DEPTH}\")\n",
    "print(f\"  Epochs:        {EPOCHS}\")\n",
    "print(f\"  Hypervec Size: {HYPERVECTOR_SIZE}\")\n",
    "print(f\"  Message Size:  {MESSAGE_SIZE}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Paths\n",
    "RUNS_DIR = \"runs\"\n",
    "os.makedirs(RUNS_DIR, exist_ok=True)\n",
    "CSV_PATH = os.path.join(RUNS_DIR, f\"hex_moves_dim{BOARD_DIM}_n{N_GAMES}.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "data_gen_markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation & Processing\n",
    "We use the C engine to generate games and save them to CSV. This ensures we have a permanent, reproducible dataset."
   ]
  },
  {
   "cell_type": "code",
   "id": "data_gen_funcs",
   "metadata": {},
   "source": [
    "def generate_data():\n",
    "    \"\"\"Generates game data using ./scripts/run_hex.sh\"\"\"\n",
    "    if os.path.exists(CSV_PATH):\n",
    "        print(f\"Found existing data: {CSV_PATH}\")\n",
    "        # You can uncomment the next line to force regeneration\n",
    "        # os.remove(CSV_PATH)\n",
    "        return\n",
    "        \n",
    "    print(f\"Generating {N_GAMES} games for {BOARD_DIM}x{BOARD_DIM} (Seed {SEED})...\")\n",
    "    cmd = [\n",
    "        \"./scripts/run_hex.sh\",\n",
    "        \"--games\", str(N_GAMES),\n",
    "        \"--seed\", str(SEED),\n",
    "        \"--dump-moves\", CSV_PATH\n",
    "    ]\n",
    "    \n",
    "    env = os.environ.copy()\n",
    "    env[\"BOARD_DIM\"] = str(BOARD_DIM)\n",
    "    \n",
    "    start = time.time()\n",
    "    subprocess.run(cmd, env=env, check=True)\n",
    "    print(f\"Done in {time.time() - start:.2f}s\")\n",
    "\n",
    "def load_and_process_data(offset=0):\n",
    "    \"\"\"\n",
    "    Loads CSV and reconstructs board states.\n",
    "    offset: Number of moves before the end to capture (0=End, 2=End-2, etc.)\n",
    "    \"\"\"\n",
    "    print(f\"Processing data with Offset={offset}...\")\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    \n",
    "    n_nodes = BOARD_DIM * BOARD_DIM\n",
    "    x_feat = []\n",
    "    o_feat = []\n",
    "    labels = []\n",
    "    \n",
    "    # Group by game\n",
    "    for game_id, group in tqdm(df.groupby(\"game_id\"), desc=\"Replaying Games\"):\n",
    "        # Skip if game is too short\n",
    "        if len(group) <= offset:\n",
    "            continue\n",
    "            \n",
    "        # Slice moves\n",
    "        moves = group.iloc[:-offset] if offset > 0 else group\n",
    "        winner = group[\"winner\"].iloc[0]\n",
    "        \n",
    "        p0 = np.zeros(n_nodes, dtype=np.int8)\n",
    "        p1 = np.zeros(n_nodes, dtype=np.int8)\n",
    "        \n",
    "        for _, row in moves.iterrows():\n",
    "            r, c, p = int(row['row']), int(row['col']), int(row['player'])\n",
    "            idx = r * BOARD_DIM + c\n",
    "            if 0 <= idx < n_nodes:\n",
    "                if p == 0: p0[idx] = 1\n",
    "                else: p1[idx] = 1\n",
    "                    \n",
    "        x_feat.append(p0)\n",
    "        o_feat.append(p1)\n",
    "        labels.append(winner)\n",
    "        \n",
    "    return np.array(x_feat), np.array(o_feat), np.array(labels)\n",
    "\n",
    "def prepare_graphs(x, o, init_with=None):\n",
    "    \"\"\"Converts Feature Maps -> GTM Graphs using explicit E/X/O symbols\"\"\"\n",
    "    if not HAS_GTM: return None\n",
    "\n",
    "    n_samples = len(x)\n",
    "    n_nodes = BOARD_DIM * BOARD_DIM\n",
    "\n",
    "    # Convert to string representation\n",
    "    board_strings = []\n",
    "    for i in range(n_samples):\n",
    "        board_str = []\n",
    "        for node in range(n_nodes):\n",
    "            if x[i][node] == 1:\n",
    "                board_str.append(\"X\")\n",
    "            elif o[i][node] == 1:\n",
    "                board_str.append(\"O\")\n",
    "            else:\n",
    "                board_str.append(\"E\")\n",
    "        board_strings.append(board_str)\n",
    "\n",
    "    graphs = Graphs(\n",
    "        n_samples,\n",
    "        symbols=[\"E\", \"X\", \"O\"],  # Explicit order\n",
    "        hypervector_size=HYPERVECTOR_SIZE,\n",
    "        hypervector_bits=2,\n",
    "        init_with=init_with\n",
    "    )\n",
    "\n",
    "    # Hex Edges - 6-neighbor topology\n",
    "    offsets = [(0, 1), (0, -1), (-1, 1), (1, -1), (-1, 0), (1, 0)]\n",
    "    adjacency = {}\n",
    "    for r in range(BOARD_DIM):\n",
    "        for c in range(BOARD_DIM):\n",
    "            u = r * BOARD_DIM + c\n",
    "            adjacency[u] = []\n",
    "            for dr, dc in offsets:\n",
    "                nr, nc = r + dr, c + dc\n",
    "                if 0 <= nr < BOARD_DIM and 0 <= nc < BOARD_DIM:\n",
    "                    adjacency[u].append(nr * BOARD_DIM + nc)\n",
    "\n",
    "    # Node Config\n",
    "    for i in range(n_samples):\n",
    "        graphs.set_number_of_graph_nodes(i, n_nodes)\n",
    "    graphs.prepare_node_configuration()\n",
    "\n",
    "    # Edge Config\n",
    "    for i in range(n_samples):\n",
    "        for u in range(n_nodes):\n",
    "            graphs.add_graph_node(i, u, len(adjacency[u]))\n",
    "    graphs.prepare_edge_configuration()\n",
    "\n",
    "    # Add Edges (bidirectional)\n",
    "    for i in range(n_samples):\n",
    "        for u in range(n_nodes):\n",
    "            for v in adjacency[u]:\n",
    "                graphs.add_graph_node_edge(i, u, v, 0)\n",
    "\n",
    "    # Add Properties using string symbols\n",
    "    for i in range(n_samples):\n",
    "        for u in range(n_nodes):\n",
    "            graphs.add_graph_node_property(i, u, board_strings[i][u])\n",
    "\n",
    "    graphs.encode()\n",
    "    return graphs\n",
    "\n",
    "# ============================================================\n",
    "#         ROTATION AUGMENTATION (Optional Enhancement)\n",
    "# ============================================================\n",
    "\n",
    "USE_ROTATION_AUGMENTATION = False  # Set to True to enable\n",
    "\n",
    "def rotate_board_90(board_1d, board_dim):\n",
    "    \"\"\"Rotate board 90 degrees clockwise\"\"\"\n",
    "    board_2d = board_1d.reshape(board_dim, board_dim)\n",
    "    rotated = np.rot90(board_2d, k=-1)  # k=-1 = clockwise\n",
    "    return rotated.flatten()\n",
    "\n",
    "def augment_with_rotation(X_raw, O_raw, Y):\n",
    "    \"\"\"\n",
    "    Double dataset by adding 90¬∞ rotated versions.\n",
    "    When rotated, TOP-BOTTOM becomes LEFT-RIGHT, so labels swap.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  APPLYING ROTATION AUGMENTATION\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    X_augmented = []\n",
    "    O_augmented = []\n",
    "    Y_augmented = []\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        # Original board\n",
    "        X_augmented.append(X_raw[i])\n",
    "        O_augmented.append(O_raw[i])\n",
    "        Y_augmented.append(Y[i])\n",
    "\n",
    "        # Rotated board (90¬∞ clockwise)\n",
    "        X_rot = rotate_board_90(X_raw[i], BOARD_DIM)\n",
    "        O_rot = rotate_board_90(O_raw[i], BOARD_DIM)\n",
    "\n",
    "        # CRITICAL: Swap labels after rotation\n",
    "        # What was vertical (W0) is now horizontal (W1)\n",
    "        Y_rot = 1 - Y[i]\n",
    "\n",
    "        X_augmented.append(X_rot)\n",
    "        O_augmented.append(O_rot)\n",
    "        Y_augmented.append(Y_rot)\n",
    "\n",
    "    X_augmented = np.array(X_augmented)\n",
    "    O_augmented = np.array(O_augmented)\n",
    "    Y_augmented = np.array(Y_augmented)\n",
    "\n",
    "    print(f\"Original samples:   {len(Y):,}\")\n",
    "    print(f\"Augmented samples:  {len(Y_augmented):,} (2x)\")\n",
    "    print(f\"Winner 0: {np.sum(Y_augmented==0):,} ({100*np.mean(Y_augmented==0):.1f}%)\")\n",
    "    print(f\"Winner 1: {np.sum(Y_augmented==1):,} ({100*np.mean(Y_augmented==1):.1f}%)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    return X_augmented, O_augmented, Y_augmented\n",
    "\n",
    "if USE_ROTATION_AUGMENTATION:\n",
    "    print(\"\\n‚ö†Ô∏è ROTATION AUGMENTATION ENABLED\")\n",
    "    print(\"   Training data will be doubled with 90¬∞ rotations\")\n",
    "else:\n",
    "    print(\"\\nüìä Using standard data (no augmentation)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "generate_cell",
   "metadata": {},
   "source": [
    "### Generate Data Now"
   ]
  },
  {
   "cell_type": "code",
   "id": "run_gen",
   "metadata": {},
   "source": [
    "generate_data()\n",
    "print(\"Data Ready!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # ============================================================\n",
    "# #         SYSTEMATIC PARAMETER SEARCH - Find Best Config\n",
    "# # ============================================================\n",
    "# \n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"  üî¨ SYSTEMATIC PARAMETER SEARCH\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"Board: {BOARD_DIM}√ó{BOARD_DIM}\")\n",
    "# print(f\"Strategy: Test configs with short training to find most promising\")\n",
    "# print(f\"Goal: Maximize Winner 0 accuracy while keeping overall >50%\")\n",
    "# print(\"=\"*70 + \"\\n\")\n",
    "# \n",
    "# # Load data once\n",
    "# print(\"Loading dataset...\")\n",
    "# X_raw_base, O_raw_base, Y_base = load_and_process_data(offset=0)\n",
    "# \n",
    "# # Test with smaller subset for speed\n",
    "# N_SEARCH_SAMPLES = min(3000, len(Y_base))\n",
    "# X_search = X_raw_base[:N_SEARCH_SAMPLES]\n",
    "# O_search = O_raw_base[:N_SEARCH_SAMPLES]\n",
    "# Y_search = Y_base[:N_SEARCH_SAMPLES]\n",
    "# \n",
    "# print(f\"Using {N_SEARCH_SAMPLES:,} samples for parameter search\")\n",
    "# print(f\"Winner 0: {np.sum(Y_search==0)} ({100*np.mean(Y_search==0):.1f}%)\")\n",
    "# print(f\"Winner 1: {np.sum(Y_search==1)} ({100*np.mean(Y_search==1):.1f}%)\")\n",
    "# \n",
    "# baseline = max(np.mean(Y_search==0), np.mean(Y_search==1))\n",
    "# print(f\"Baseline: {baseline*100:.1f}%\\n\")\n",
    "# \n",
    "# # Define parameter grid to search\n",
    "# search_configs = [\n",
    "#     # Format: {name, clauses, T, s, depth, use_rotation}\n",
    "# \n",
    "#     # Baseline configurations (no rotation)\n",
    "#     {\"name\": \"Baseline_Conservative\", \"clauses\": 1600, \"T\": 200, \"s\": 2.0, \"depth\": 5, \"rotation\": False},\n",
    "#     {\"name\": \"Baseline_Permissive\", \"clauses\": 1600, \"T\": 100, \"s\": 1.0, \"depth\": 3, \"rotation\": False},\n",
    "#     {\"name\": \"Baseline_LowT\", \"clauses\": 2000, \"T\": 80, \"s\": 1.2, \"depth\": 4, \"rotation\": False},\n",
    "# \n",
    "#     # High capacity variations\n",
    "#     {\"name\": \"HighCap_Conservative\", \"clauses\": 2500, \"T\": 150, \"s\": 1.5, \"depth\": 5, \"rotation\": False},\n",
    "#     {\"name\": \"HighCap_Permissive\", \"clauses\": 3000, \"T\": 100, \"s\": 1.0, \"depth\": 4, \"rotation\": False},\n",
    "# \n",
    "#     # Deep message passing\n",
    "#     {\"name\": \"Deep_Moderate\", \"clauses\": 1800, \"T\": 120, \"s\": 1.3, \"depth\": 8, \"rotation\": False},\n",
    "#     {\"name\": \"Deep_Permissive\", \"clauses\": 2000, \"T\": 80, \"s\": 1.0, \"depth\": 10, \"rotation\": False},\n",
    "# \n",
    "#     # Shallow but huge\n",
    "#     {\"name\": \"Shallow_Huge\", \"clauses\": 3500, \"T\": 100, \"s\": 1.0, \"depth\": 2, \"rotation\": False},\n",
    "# \n",
    "#     # Ultra-low threshold\n",
    "#     {\"name\": \"UltraLowT_1\", \"clauses\": 2000, \"T\": 60, \"s\": 0.9, \"depth\": 3, \"rotation\": False},\n",
    "#     {\"name\": \"UltraLowT_2\", \"clauses\": 2500, \"T\": 40, \"s\": 0.8, \"depth\": 3, \"rotation\": False},\n",
    "# \n",
    "#     # WITH ROTATION - Best performing configs from above\n",
    "#     {\"name\": \"Rotation_Permissive\", \"clauses\": 1600, \"T\": 100, \"s\": 1.0, \"depth\": 3, \"rotation\": True},\n",
    "#     {\"name\": \"Rotation_HighCap\", \"clauses\": 2500, \"T\": 100, \"s\": 1.0, \"depth\": 4, \"rotation\": True},\n",
    "#     {\"name\": \"Rotation_LowT\", \"clauses\": 2000, \"T\": 60, \"s\": 0.9, \"depth\": 3, \"rotation\": True},\n",
    "#     {\"name\": \"Rotation_Deep\", \"clauses\": 2000, \"T\": 80, \"s\": 1.0, \"depth\": 8, \"rotation\": True},\n",
    "# ]\n",
    "# \n",
    "# SEARCH_EPOCHS = 20  # Short training for quick evaluation\n",
    "# EVAL_EVERY = 5\n",
    "# \n",
    "# print(f\"Testing {len(search_configs)} configurations ({SEARCH_EPOCHS} epochs each)\")\n",
    "# print(f\"Estimated time: ~{len(search_configs) * 3:.0f} minutes\\n\")\n",
    "# \n",
    "# search_results = []\n",
    "# \n",
    "# for i, cfg in enumerate(search_configs, 1):\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(f\"  [{i}/{len(search_configs)}] {cfg['name']}\")\n",
    "#     print(f\"{'='*70}\")\n",
    "#     print(f\"  Clauses: {cfg['clauses']}, T: {cfg['T']}, s: {cfg['s']}, Depth: {cfg['depth']}\")\n",
    "#     print(f\"  Rotation: {'YES' if cfg['rotation'] else 'NO'}\")\n",
    "# \n",
    "#     start_time = time.time()\n",
    "# \n",
    "#     try:\n",
    "#         # Prepare data (with or without rotation)\n",
    "#         if cfg['rotation']:\n",
    "#             print(\"  Applying rotation augmentation...\")\n",
    "#             X_data, O_data, Y_data = augment_with_rotation(X_search, O_search, Y_search)\n",
    "#         else:\n",
    "#             X_data, O_data, Y_data = X_search.copy(), O_search.copy(), Y_search.copy()\n",
    "# \n",
    "#         # Build graphs\n",
    "#         print(\"  Building graphs...\", end=\"\", flush=True)\n",
    "#         g_search = prepare_graphs(X_data, O_data)\n",
    "#         print(\" Done!\")\n",
    "# \n",
    "#         # Create model\n",
    "#         tm = MultiClassGraphTsetlinMachine(\n",
    "#             number_of_clauses=cfg['clauses'],\n",
    "#             T=cfg['T'],\n",
    "#             s=cfg['s'],\n",
    "#             depth=cfg['depth'],\n",
    "#             message_size=512,\n",
    "#             message_bits=2,\n",
    "#             max_included_literals=96,\n",
    "#             grid=(16*13*3, 1, 1),\n",
    "#             block=(128, 1, 1)\n",
    "#         )\n",
    "# \n",
    "#         # Training with tracking\n",
    "#         print(f\"  Training {SEARCH_EPOCHS} epochs...\", end=\"\", flush=True)\n",
    "# \n",
    "#         epoch_results = []\n",
    "#         best_w0 = 0\n",
    "#         best_overall = 0\n",
    "# \n",
    "#         for ep in range(SEARCH_EPOCHS):\n",
    "#             tm.fit(g_search, Y_data, epochs=1, incremental=True)\n",
    "# \n",
    "#             if (ep + 1) % EVAL_EVERY == 0:\n",
    "#                 preds = tm.predict(g_search)\n",
    "#                 acc = accuracy_score(Y_data, preds)\n",
    "#                 acc0 = accuracy_score(Y_data[Y_data==0], preds[Y_data==0]) if np.sum(Y_data==0) > 0 else 0\n",
    "#                 acc1 = accuracy_score(Y_data[Y_data==1], preds[Y_data==1]) if np.sum(Y_data==1) > 0 else 0\n",
    "# \n",
    "#                 epoch_results.append({\n",
    "#                     'epoch': ep + 1,\n",
    "#                     'overall': acc,\n",
    "#                     'w0': acc0,\n",
    "#                     'w1': acc1\n",
    "#                 })\n",
    "# \n",
    "#                 if acc0 > best_w0:\n",
    "#                     best_w0 = acc0\n",
    "#                 if acc > best_overall:\n",
    "#                     best_overall = acc\n",
    "# \n",
    "#                 print(\".\", end=\"\", flush=True)\n",
    "# \n",
    "#         print(\" Done!\")\n",
    "# \n",
    "#         # Final evaluation\n",
    "#         final_preds = tm.predict(g_search)\n",
    "#         final_acc = accuracy_score(Y_data, final_preds)\n",
    "#         final_acc0 = accuracy_score(Y_data[Y_data==0], final_preds[Y_data==0]) if np.sum(Y_data==0) > 0 else 0\n",
    "#         final_acc1 = accuracy_score(Y_data[Y_data==1], final_preds[Y_data==1]) if np.sum(Y_data==1) > 0 else 0\n",
    "# \n",
    "#         pred_counts = np.bincount(final_preds, minlength=2)\n",
    "# \n",
    "#         # Calculate \"improvement score\" - prioritizes W0 improvement\n",
    "#         w0_improvement = final_acc0 - (0.5 if cfg['rotation'] else baseline)\n",
    "#         overall_improvement = final_acc - (0.5 if cfg['rotation'] else baseline)\n",
    "# \n",
    "#         # Weighted score: W0 is 3x more important since it's the problem\n",
    "#         improvement_score = (w0_improvement * 3.0) + overall_improvement\n",
    "# \n",
    "#         training_time = time.time() - start_time\n",
    "# \n",
    "#         # Store results\n",
    "#         result = {\n",
    "#             'name': cfg['name'],\n",
    "#             'clauses': cfg['clauses'],\n",
    "#             'T': cfg['T'],\n",
    "#             's': cfg['s'],\n",
    "#             'depth': cfg['depth'],\n",
    "#             'rotation': cfg['rotation'],\n",
    "#             'final_overall': final_acc * 100,\n",
    "#             'final_w0': final_acc0 * 100,\n",
    "#             'final_w1': final_acc1 * 100,\n",
    "#             'best_w0': best_w0 * 100,\n",
    "#             'best_overall': best_overall * 100,\n",
    "#             'gap': abs(final_acc0 - final_acc1) * 100,\n",
    "#             'improvement_score': improvement_score * 100,\n",
    "#             'pred_w0_count': int(pred_counts[0]),\n",
    "#             'pred_w1_count': int(pred_counts[1]),\n",
    "#             'time_sec': training_time,\n",
    "#             'epoch_history': epoch_results\n",
    "#         }\n",
    "# \n",
    "#         search_results.append(result)\n",
    "# \n",
    "#         # Print summary\n",
    "#         print(f\"\\n  Results:\")\n",
    "#         print(f\"    Overall: {final_acc*100:5.1f}% | W0: {final_acc0*100:5.1f}% | W1: {final_acc1*100:5.1f}%\")\n",
    "#         print(f\"    Best W0: {best_w0*100:5.1f}% | Gap: {abs(final_acc0-final_acc1)*100:5.1f}%\")\n",
    "#         print(f\"    Improvement Score: {improvement_score*100:+.1f}\")\n",
    "#         print(f\"    Predictions: W0={pred_counts[0]}, W1={pred_counts[1]}\")\n",
    "#         print(f\"    Time: {training_time:.1f}s\")\n",
    "# \n",
    "#         # Memory cleanup\n",
    "#         del tm, g_search\n",
    "#         gc.collect()\n",
    "# \n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n  ‚úó FAILED: {str(e)[:100]}\")\n",
    "#         search_results.append({\n",
    "#             'name': cfg['name'],\n",
    "#             'error': str(e),\n",
    "#             'failed': True\n",
    "#         })\n",
    "#         continue\n",
    "# \n",
    "# # ============================================================\n",
    "# #  ANALYSIS & RECOMMENDATIONS\n",
    "# # ============================================================\n",
    "# \n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"  üìä PARAMETER SEARCH COMPLETE\")\n",
    "# print(\"=\"*70)\n",
    "# \n",
    "# successful_results = [r for r in search_results if 'error' not in r]\n",
    "# \n",
    "# if successful_results:\n",
    "#     # Sort by different metrics\n",
    "#     by_score = sorted(successful_results, key=lambda x: x['improvement_score'], reverse=True)\n",
    "#     by_w0 = sorted(successful_results, key=lambda x: x['final_w0'], reverse=True)\n",
    "#     by_overall = sorted(successful_results, key=lambda x: x['final_overall'], reverse=True)\n",
    "#     by_balanced = sorted(successful_results, key=lambda x: x['gap'])\n",
    "# \n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"  üèÜ TOP 5 CONFIGURATIONS BY IMPROVEMENT SCORE\")\n",
    "#     print(\"=\"*70)\n",
    "#     print(f\"{'Rank':<5} {'Config':<25} {'Overall':>8} {'W0':>8} {'W1':>8} {'Gap':>8} {'Score':>8}\")\n",
    "#     print(\"-\"*70)\n",
    "# \n",
    "#     for rank, r in enumerate(by_score[:5], 1):\n",
    "#         marker = \"üåü\" if r['rotation'] else \"  \"\n",
    "#         print(f\"{rank:<5} {marker}{r['name']:<23} {r['final_overall']:7.1f}% {r['final_w0']:7.1f}% \"\n",
    "#               f\"{r['final_w1']:7.1f}% {r['gap']:7.1f}% {r['improvement_score']:7.1f}\")\n",
    "# \n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"  üéØ TOP 5 BY WINNER 0 ACCURACY (The Hard One)\")\n",
    "#     print(\"=\"*70)\n",
    "#     print(f\"{'Rank':<5} {'Config':<25} {'W0':>8} {'Overall':>8} {'Gap':>8}\")\n",
    "#     print(\"-\"*70)\n",
    "# \n",
    "#     for rank, r in enumerate(by_w0[:5], 1):\n",
    "#         marker = \"üåü\" if r['rotation'] else \"  \"\n",
    "#         print(f\"{rank:<5} {marker}{r['name']:<23} {r['final_w0']:7.1f}% {r['final_overall']:7.1f}% {r['gap']:7.1f}%\")\n",
    "# \n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"  ‚öñÔ∏è TOP 5 MOST BALANCED (Lowest Gap)\")\n",
    "#     print(\"=\"*70)\n",
    "#     print(f\"{'Rank':<5} {'Config':<25} {'Gap':>8} {'W0':>8} {'W1':>8}\")\n",
    "#     print(\"-\"*70)\n",
    "# \n",
    "#     for rank, r in enumerate(by_balanced[:5], 1):\n",
    "#         marker = \"üåü\" if r['rotation'] else \"  \"\n",
    "#         print(f\"{rank:<5} {marker}{r['name']:<23} {r['gap']:7.1f}% {r['final_w0']:7.1f}% {r['final_w1']:7.1f}%\")\n",
    "# \n",
    "#     # Comparison: With vs Without Rotation\n",
    "#     with_rot = [r for r in successful_results if r['rotation']]\n",
    "#     without_rot = [r for r in successful_results if not r['rotation']]\n",
    "# \n",
    "#     if with_rot and without_rot:\n",
    "#         print(\"\\n\" + \"=\"*70)\n",
    "#         print(\"  üîÑ ROTATION AUGMENTATION ANALYSIS\")\n",
    "#         print(\"=\"*70)\n",
    "# \n",
    "#         avg_w0_with = np.mean([r['final_w0'] for r in with_rot])\n",
    "#         avg_w0_without = np.mean([r['final_w0'] for r in without_rot])\n",
    "#         avg_overall_with = np.mean([r['final_overall'] for r in with_rot])\n",
    "#         avg_overall_without = np.mean([r['final_overall'] for r in without_rot])\n",
    "# \n",
    "#         print(f\"\\nAverage Winner 0 Accuracy:\")\n",
    "#         print(f\"  Without rotation: {avg_w0_without:.1f}%\")\n",
    "#         print(f\"  With rotation:    {avg_w0_with:.1f}%\")\n",
    "#         print(f\"  Difference:       {avg_w0_with - avg_w0_without:+.1f}%\")\n",
    "# \n",
    "#         print(f\"\\nAverage Overall Accuracy:\")\n",
    "#         print(f\"  Without rotation: {avg_overall_without:.1f}%\")\n",
    "#         print(f\"  With rotation:    {avg_overall_with:.1f}%\")\n",
    "#         print(f\"  Difference:       {avg_overall_with - avg_overall_without:+.1f}%\")\n",
    "# \n",
    "#         if avg_w0_with > avg_w0_without + 5:\n",
    "#             print(f\"\\n‚úÖ Rotation provides meaningful W0 improvement (+{avg_w0_with - avg_w0_without:.1f}%)\")\n",
    "#         elif avg_w0_with > avg_w0_without:\n",
    "#             print(f\"\\n‚ö†Ô∏è Rotation provides marginal improvement (+{avg_w0_with - avg_w0_without:.1f}%)\")\n",
    "#         else:\n",
    "#             print(f\"\\n‚ùå Rotation does not help ({avg_w0_with - avg_w0_without:.1f}%)\")\n",
    "# \n",
    "#     # Save results\n",
    "#     results_df = pd.DataFrame([{\n",
    "#         'name': r['name'],\n",
    "#         'clauses': r['clauses'],\n",
    "#         'T': r['T'],\n",
    "#         's': r['s'],\n",
    "#         'depth': r['depth'],\n",
    "#         'rotation': r['rotation'],\n",
    "#         'overall': r['final_overall'],\n",
    "#         'w0': r['final_w0'],\n",
    "#         'w1': r['final_w1'],\n",
    "#         'gap': r['gap'],\n",
    "#         'score': r['improvement_score']\n",
    "#     } for r in successful_results])\n",
    "# \n",
    "#     results_file = os.path.join(RUNS_DIR, f'parameter_search_{BOARD_DIM}x{BOARD_DIM}.csv')\n",
    "#     results_df.to_csv(results_file, index=False)\n",
    "#     print(f\"\\nüìÅ Results saved to: {results_file}\")\n",
    "# \n",
    "#     # RECOMMENDATION\n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"  üí° RECOMMENDATION FOR FULL TRAINING\")\n",
    "#     print(\"=\"*70)\n",
    "# \n",
    "#     best = by_score[0]\n",
    "#     print(f\"\\nBest Configuration: {best['name']}\")\n",
    "#     print(f\"  Clauses:  {best['clauses']}\")\n",
    "#     print(f\"  T:        {best['T']}\")\n",
    "#     print(f\"  s:        {best['s']}\")\n",
    "#     print(f\"  Depth:    {best['depth']}\")\n",
    "#     print(f\"  Rotation: {'YES' if best['rotation'] else 'NO'}\")\n",
    "#     print(f\"\\nExpected Performance (full training):\")\n",
    "#     print(f\"  Overall:  {best['final_overall']:.1f}% ‚Üí ~{best['final_overall']+2:.1f}%\")\n",
    "#     print(f\"  Winner 0: {best['final_w0']:.1f}% ‚Üí ~{best['final_w0']+3:.1f}%\")\n",
    "#     print(f\"  Winner 1: {best['final_w1']:.1f}% ‚Üí ~{best['final_w1']-2:.1f}%\")\n",
    "# \n",
    "#     if best['final_w0'] < 30:\n",
    "#         print(f\"\\n‚ö†Ô∏è WARNING: Even best config has low W0 accuracy ({best['final_w0']:.1f}%)\")\n",
    "#         print(f\"   This confirms the fundamental limitation for {BOARD_DIM}√ó{BOARD_DIM} boards.\")\n",
    "# \n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "# \n",
    "# else:\n",
    "#     print(\"\\n‚ùå No successful configurations\")\n",
    "# \n",
    "# print(\"\\n‚úì Parameter search complete!\")"
   ],
   "id": "cd8d35944e881f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c8dc67880a4aaff0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "exp1_markdown",
   "metadata": {},
   "source": [
    "## 2. Main Experiment: End, End-2, End-5 Analysis\n",
    "We train and test the model on three different game states:\n",
    "1.  **End**: The final position (Easy).\n",
    "2.  **End-2**: Two moves before the end (Harder).\n",
    "3.  **End-5**: Five moves before the end (Hardest).\n",
    "\n",
    "This uses the parameters configured at the top."
   ]
  },
  {
   "cell_type": "code",
   "id": "exp_offsets",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "offsets = [0, 2, 5]\n",
    "results_main = []\n",
    "\n",
    "if HAS_GTM:\n",
    "    for off in offsets:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  Running OFFSET = {off} ({BOARD_DIM}x{BOARD_DIM})\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # 1. Load\n",
    "        X_raw, O_raw, Y = load_and_process_data(offset=off)\n",
    "\n",
    "        if USE_ROTATION_AUGMENTATION:\n",
    "            X_raw, O_raw, Y = augment_with_rotation(X_raw, O_raw, Y)\n",
    "\n",
    "        # 2. Split (80/20)\n",
    "        split = int(0.8 * len(Y))\n",
    "        X_train = (X_raw[:split], O_raw[:split])\n",
    "        Y_train = Y[:split]\n",
    "        X_test = (X_raw[split:], O_raw[split:])\n",
    "        Y_test = Y[split:]\n",
    "\n",
    "        print(f\"Train: {len(Y_train):,}, Test: {len(Y_test):,}\")\n",
    "        print(f\"Winner 0: {np.sum(Y_train==0):,} ({100*np.mean(Y_train==0):.1f}%)\")\n",
    "        print(f\"Winner 1: {np.sum(Y_train==1):,} ({100*np.mean(Y_train==1):.1f}%)\")\n",
    "\n",
    "        # 3. Graphs\n",
    "        print(\"\\nBuilding Graphs...\")\n",
    "        t0 = time.time()\n",
    "        g_train = prepare_graphs(X_train[0], X_train[1])\n",
    "        g_test = prepare_graphs(X_test[0], X_test[1], init_with=g_train)\n",
    "        print(f\"Done in {time.time()-t0:.1f}s\")\n",
    "\n",
    "        # 4. Train\n",
    "        print(f\"\\nTraining GTM...\")\n",
    "        tm = MultiClassGraphTsetlinMachine(\n",
    "            number_of_clauses=CLAUSES,\n",
    "            T=T,\n",
    "            s=S,\n",
    "            depth=DEPTH,\n",
    "            message_size=MESSAGE_SIZE,  # Use config value\n",
    "            message_bits=2,\n",
    "            max_included_literals=min(64, int(32 * GRID_MULT)),  # Scale with board\n",
    "            grid=(16*13*GRID_MULT, 1, 1),  # Scale grid with complexity\n",
    "            block=(128, 1, 1)\n",
    "        )\n",
    "\n",
    "        history = []\n",
    "        eval_interval = max(1, EPOCHS // 10)  # Evaluate 10 times total\n",
    "\n",
    "        t_start = time.time()\n",
    "        for ep in tqdm(range(EPOCHS), desc=f\"Offset {off}\"):\n",
    "            tm.fit(g_train, Y_train, epochs=1, incremental=True)\n",
    "\n",
    "            # Periodic evaluation (not every epoch - saves time)\n",
    "            if (ep + 1) % eval_interval == 0 or ep == 0 or ep == EPOCHS-1:\n",
    "                p_train = tm.predict(g_train)\n",
    "                acc = accuracy_score(Y_train, p_train)\n",
    "                history.append((ep+1, acc * 100))\n",
    "                tqdm.write(f\"  Epoch {ep+1:3d}: Train Acc = {acc*100:.1f}%\")\n",
    "\n",
    "        training_time = time.time() - t_start\n",
    "\n",
    "        # 5. Final Evaluation\n",
    "        print(f\"\\nEvaluating...\")\n",
    "        preds = tm.predict(g_test)\n",
    "        final_acc = accuracy_score(Y_test, preds)\n",
    "        cm = confusion_matrix(Y_test, preds)\n",
    "\n",
    "        # Per-class accuracy\n",
    "        acc0 = accuracy_score(Y_test[Y_test==0], preds[Y_test==0]) if np.sum(Y_test==0) > 0 else 0\n",
    "        acc1 = accuracy_score(Y_test[Y_test==1], preds[Y_test==1]) if np.sum(Y_test==1) > 0 else 0\n",
    "\n",
    "        # Metrics\n",
    "        from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "        p0 = precision_score(Y_test, preds, pos_label=0, zero_division=0)\n",
    "        p1 = precision_score(Y_test, preds, pos_label=1, zero_division=0)\n",
    "        r0 = recall_score(Y_test, preds, pos_label=0, zero_division=0)\n",
    "        r1 = recall_score(Y_test, preds, pos_label=1, zero_division=0)\n",
    "        f1_0 = f1_score(Y_test, preds, pos_label=0, zero_division=0)\n",
    "        f1_1 = f1_score(Y_test, preds, pos_label=1, zero_division=0)\n",
    "\n",
    "        print(f\"Precision:  W0={p0*100:.2f}% | W1={p1*100:.2f}%\")\n",
    "        print(f\"Recall:     W0={r0*100:.2f}% | W1={r1*100:.2f}%\")\n",
    "        print(f\"F1 Score:   W0={f1_0*100:.2f}% | W1={f1_1*100:.2f}%\")\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  RESULTS - Offset {off}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Overall Accuracy:  {final_acc*100:.2f}%\")\n",
    "        print(f\"Winner 0 Accuracy: {acc0*100:.2f}%\")\n",
    "        print(f\"Winner 1 Accuracy: {acc1*100:.2f}%\")\n",
    "        print(f\"Class Gap:         {abs(acc0-acc1)*100:.2f}%\")\n",
    "        print(f\"Training Time:     {training_time/60:.1f} min\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "        results_main.append({\n",
    "            \"offset\": off,\n",
    "            \"acc\": final_acc * 100,\n",
    "            \"acc0\": acc0 * 100,\n",
    "            \"acc1\": acc1 * 100,\n",
    "            \"gap\": abs(acc0-acc1) * 100,\n",
    "            \"recall0\": r0 * 100,      # ADD THIS\n",
    "            \"recall1\": r1 * 100,      # ADD THIS\n",
    "            \"f1_0\": f1_0 * 100,       # ADD THIS\n",
    "            \"f1_1\": f1_1 * 100,       # ADD THIS\n",
    "            \"history\": history,\n",
    "            \"cm\": cm,\n",
    "            \"preds\": preds,\n",
    "            \"y_test\": Y_test,\n",
    "            \"training_time\": training_time\n",
    "        })\n",
    "\n",
    "        # Memory cleanup\n",
    "        del tm, g_train, g_test\n",
    "        gc.collect()\n",
    "\n",
    "    # Save results summary\n",
    "    summary_df = pd.DataFrame([{\n",
    "        'offset': r['offset'],\n",
    "        'accuracy': r['acc'],\n",
    "        'acc_winner0': r['acc0'],\n",
    "        'acc_winner1': r['acc1'],\n",
    "        'gap': r['gap'],\n",
    "        'time_min': r['training_time']/60\n",
    "    } for r in results_main])\n",
    "\n",
    "    summary_path = os.path.join(RUNS_DIR, f\"main_results_{BOARD_DIM}x{BOARD_DIM}.csv\")\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"‚úì Results saved to {summary_path}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Replaying Games:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5659/8000 [00:16<00:06, 351.52it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "viz_main",
   "metadata": {},
   "source": [
    "# =========================================================\n",
    "#       PARAMETER EXPERIMENTS (Scalable)\n",
    "# =========================================================\n",
    "\n",
    "# Define experiment ranges based on board size\n",
    "if BOARD_DIM <= 5:\n",
    "    # Small boards: test more granular\n",
    "    CLAUSE_TESTS = [int(CLAUSES * f) for f in [0.5, 1.0, 2.0, 4.0]]\n",
    "    DEPTH_TESTS = [max(1, DEPTH-2), DEPTH, DEPTH+2, DEPTH+5]\n",
    "    REDUCED_EPOCHS = max(15, EPOCHS // 2)\n",
    "elif BOARD_DIM <= 11:\n",
    "    # Medium boards: test around optimal\n",
    "    CLAUSE_TESTS = [int(CLAUSES * f) for f in [0.67, 1.0, 1.5, 2.0]]\n",
    "    DEPTH_TESTS = [max(1, DEPTH-3), DEPTH, DEPTH+3, DEPTH+6]\n",
    "    REDUCED_EPOCHS = max(20, EPOCHS // 2)\n",
    "else:\n",
    "    # Large boards: test fewer configs (time-expensive)\n",
    "    CLAUSE_TESTS = [int(CLAUSES * f) for f in [0.75, 1.0, 1.5]]\n",
    "    DEPTH_TESTS = [DEPTH-3, DEPTH, DEPTH+5]\n",
    "    REDUCED_EPOCHS = max(25, EPOCHS // 2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"  PARAMETER EXPERIMENTS - {BOARD_DIM}x{BOARD_DIM}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Clause tests: {CLAUSE_TESTS}\")\n",
    "print(f\"  Depth tests:  {DEPTH_TESTS}\")\n",
    "print(f\"  Epochs:       {REDUCED_EPOCHS} (reduced for speed)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Use offset=0 (final position) for all experiments\n",
    "if results_main:\n",
    "    X_raw, O_raw, Y = load_and_process_data(offset=0)\n",
    "    split = int(0.8 * len(Y))\n",
    "    X_train = (X_raw[:split], O_raw[:split])\n",
    "    Y_train = Y[:split]\n",
    "    X_test = (X_raw[split:], O_raw[split:])\n",
    "    Y_test = Y[split:]\n",
    "\n",
    "    print(\"Building graphs for experiments...\")\n",
    "    g_train = prepare_graphs(X_train[0], X_train[1])\n",
    "    g_test = prepare_graphs(X_test[0], X_test[1], init_with=g_train)\n",
    "    print(\"Done!\\n\")\n",
    "\n",
    "    # === EXPERIMENT 1: Model Capacity ===\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"EXPERIMENT 1: Model Capacity (Varying Clauses)\")\n",
    "    print(\"-\"*60 + \"\\n\")\n",
    "\n",
    "    results_capacity = []\n",
    "\n",
    "    for c in CLAUSE_TESTS:\n",
    "        print(f\"Testing {c} clauses...\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        tm = MultiClassGraphTsetlinMachine(\n",
    "            number_of_clauses=c,\n",
    "            T=T, s=S, depth=DEPTH,  # Keep depth constant\n",
    "            message_size=MESSAGE_SIZE,\n",
    "            message_bits=2,\n",
    "            max_included_literals=min(64, int(32 * GRID_MULT)),\n",
    "            grid=(16*13*GRID_MULT, 1, 1),\n",
    "            block=(128, 1, 1)\n",
    "        )\n",
    "\n",
    "        for _ in tqdm(range(REDUCED_EPOCHS), desc=f\"  {c} clauses\", leave=False):\n",
    "            tm.fit(g_train, Y_train, epochs=1, incremental=True)\n",
    "\n",
    "        preds = tm.predict(g_test)\n",
    "        acc = accuracy_score(Y_test, preds)\n",
    "        acc0 = accuracy_score(Y_test[Y_test==0], preds[Y_test==0]) if np.sum(Y_test==0) > 0 else 0\n",
    "        acc1 = accuracy_score(Y_test[Y_test==1], preds[Y_test==1]) if np.sum(Y_test==1) > 0 else 0\n",
    "\n",
    "        elapsed = time.time() - t0\n",
    "\n",
    "        results_capacity.append({\n",
    "            \"clauses\": c,\n",
    "            \"overall\": acc*100,\n",
    "            \"winner0\": acc0*100,\n",
    "            \"winner1\": acc1*100,\n",
    "            \"gap\": abs(acc0-acc1)*100,\n",
    "            \"time_min\": elapsed/60\n",
    "        })\n",
    "\n",
    "        print(f\"  ‚Üí Overall: {acc*100:.1f}% | W0: {acc0*100:.1f}% | W1: {acc1*100:.1f}% | Time: {elapsed/60:.1f}min\\n\")\n",
    "\n",
    "        del tm\n",
    "        gc.collect()\n",
    "\n",
    "    # === EXPERIMENT 2: Message Passing Depth ===\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"EXPERIMENT 2: Message Passing Depth\")\n",
    "    print(\"-\"*60 + \"\\n\")\n",
    "\n",
    "    results_depth = []\n",
    "\n",
    "    for d in DEPTH_TESTS:\n",
    "        if d < 1:\n",
    "            continue  # Skip invalid depths\n",
    "\n",
    "        print(f\"Testing depth {d}...\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        tm = MultiClassGraphTsetlinMachine(\n",
    "            number_of_clauses=CLAUSES,  # Keep clauses constant\n",
    "            T=T, s=S, depth=d,\n",
    "            message_size=MESSAGE_SIZE,\n",
    "            message_bits=2,\n",
    "            max_included_literals=min(64, int(32 * GRID_MULT)),\n",
    "            grid=(16*13*GRID_MULT, 1, 1),\n",
    "            block=(128, 1, 1)\n",
    "        )\n",
    "\n",
    "        for _ in tqdm(range(REDUCED_EPOCHS), desc=f\"  Depth {d}\", leave=False):\n",
    "            tm.fit(g_train, Y_train, epochs=1, incremental=True)\n",
    "\n",
    "        preds = tm.predict(g_test)\n",
    "        acc = accuracy_score(Y_test, preds)\n",
    "        acc0 = accuracy_score(Y_test[Y_test==0], preds[Y_test==0]) if np.sum(Y_test==0) > 0 else 0\n",
    "        acc1 = accuracy_score(Y_test[Y_test==1], preds[Y_test==1]) if np.sum(Y_test==1) > 0 else 0\n",
    "\n",
    "        elapsed = time.time() - t0\n",
    "\n",
    "        results_depth.append({\n",
    "            \"depth\": d,\n",
    "            \"overall\": acc*100,\n",
    "            \"winner0\": acc0*100,\n",
    "            \"winner1\": acc1*100,\n",
    "            \"gap\": abs(acc0-acc1)*100,\n",
    "            \"time_min\": elapsed/60\n",
    "        })\n",
    "\n",
    "        print(f\"  ‚Üí Overall: {acc*100:.1f}% | W0: {acc0*100:.1f}% | W1: {acc1*100:.1f}% | Time: {elapsed/60:.1f}min\\n\")\n",
    "\n",
    "        del tm\n",
    "        gc.collect()\n",
    "\n",
    "    # Save results\n",
    "    df_cap = pd.DataFrame(results_capacity)\n",
    "    df_depth = pd.DataFrame(results_depth)\n",
    "\n",
    "    cap_path = os.path.join(RUNS_DIR, f\"capacity_{BOARD_DIM}x{BOARD_DIM}.csv\")\n",
    "    depth_path = os.path.join(RUNS_DIR, f\"depth_{BOARD_DIM}x{BOARD_DIM}.csv\")\n",
    "\n",
    "    df_cap.to_csv(cap_path, index=False)\n",
    "    df_depth.to_csv(depth_path, index=False)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚úì Results saved!\")\n",
    "    print(f\"  {cap_path}\")\n",
    "    print(f\"  {depth_path}\")\n",
    "    print(f\"{'='*60}\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "exp_param_markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter Search (Capacity & Depth)\n",
    "Use these experiments to find the best configuration for scaling to 11x11.\n",
    "This runs on the **Final** board state (Offset 0) by default to save time."
   ]
  },
  {
   "cell_type": "code",
   "id": "viz_params",
   "metadata": {},
   "source": [
    "# === COMPREHENSIVE VISUALIZATION ===\n",
    "if 'results_capacity' in dir() and 'results_depth' in dir():\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "    df_cap = pd.DataFrame(results_capacity)\n",
    "    df_depth = pd.DataFrame(results_depth)\n",
    "\n",
    "    # --- ROW 1: Main Experiment Results ---\n",
    "    if results_main:\n",
    "        ax1 = fig.add_subplot(gs[0, :])\n",
    "        for res in results_main:\n",
    "            epochs, accs = zip(*res['history'])\n",
    "            ax1.plot(epochs, accs, 'o-', label=f\"Offset {res['offset']} (Final: {res['acc']:.1f}%)\", linewidth=2)\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Training Accuracy (%)\")\n",
    "        ax1.set_title(f\"Learning Curves - {BOARD_DIM}x{BOARD_DIM} Board\", fontsize=14, fontweight='bold')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # --- ROW 2: Capacity Experiment ---\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax2.plot(df_cap['clauses'], df_cap['overall'], 'o-', color='black', linewidth=2, markersize=8, label='Overall')\n",
    "    ax2.plot(df_cap['clauses'], df_cap['winner0'], 's--', color='blue', linewidth=1.5, markersize=6, label='Winner 0')\n",
    "    ax2.plot(df_cap['clauses'], df_cap['winner1'], '^--', color='red', linewidth=1.5, markersize=6, label='Winner 1')\n",
    "    ax2.set_xlabel(\"Number of Clauses\")\n",
    "    ax2.set_ylabel(\"Accuracy (%)\")\n",
    "    ax2.set_title(\"Model Capacity vs Accuracy\", fontsize=12, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    ax3.bar(df_cap['clauses'].astype(str), df_cap['gap'], color='coral', alpha=0.7)\n",
    "    ax3.set_xlabel(\"Number of Clauses\")\n",
    "    ax3.set_ylabel(\"Accuracy Gap (%)\")\n",
    "    ax3.set_title(\"Class Imbalance (Winner 0 - Winner 1)\", fontsize=12, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # --- ROW 3: Depth Experiment ---\n",
    "    ax4 = fig.add_subplot(gs[2, 0])\n",
    "    ax4.plot(df_depth['depth'], df_depth['overall'], 'o-', color='black', linewidth=2, markersize=8, label='Overall')\n",
    "    ax4.plot(df_depth['depth'], df_depth['winner0'], 's--', color='blue', linewidth=1.5, markersize=6, label='Winner 0')\n",
    "    ax4.plot(df_depth['depth'], df_depth['winner1'], '^--', color='red', linewidth=1.5, markersize=6, label='Winner 1')\n",
    "    ax4.set_xlabel(\"Message Passing Depth\")\n",
    "    ax4.set_ylabel(\"Accuracy (%)\")\n",
    "    ax4.set_title(\"Depth vs Accuracy\", fontsize=12, fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    ax5 = fig.add_subplot(gs[2, 1])\n",
    "    ax5.bar(df_depth['depth'].astype(str), df_depth['gap'], color='skyblue', alpha=0.7)\n",
    "    ax5.set_xlabel(\"Message Passing Depth\")\n",
    "    ax5.set_ylabel(\"Accuracy Gap (%)\")\n",
    "    ax5.set_title(\"Class Imbalance (Winner 0 - Winner 1)\", fontsize=12, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    plt.suptitle(f\"GTM Analysis - {BOARD_DIM}x{BOARD_DIM} Hex Board\", fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "    plot_path = os.path.join(RUNS_DIR, f\"full_analysis_{BOARD_DIM}x{BOARD_DIM}.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  FINAL SUMMARY - {BOARD_DIM}x{BOARD_DIM} Board\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    print(\"CAPACITY EXPERIMENT:\")\n",
    "    print(df_cap.to_string(index=False))\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"DEPTH EXPERIMENT:\")\n",
    "    print(df_depth.to_string(index=False))\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìä Plot saved: {plot_path}\")\n",
    "    print(f\"{'='*70}\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "#         GENERATE LATEX TABLE FOR REPORT\n",
    "# ============================================================\n",
    "\n",
    "if results_main:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  LATEX TABLE - Copy this into your report\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    print(\"\\\\begin{table}[htbp]\")\n",
    "    print(\"\\\\centering\")\n",
    "    print(\"\\\\begin{tabular}{|c|c|c|c|c|c|}\")\n",
    "    print(\"\\\\hline\")\n",
    "    print(\"\\\\textbf{Offset} & \\\\textbf{Samples} & \\\\textbf{Accuracy} & \\\\textbf{Recall W0} & \\\\textbf{Recall W1} & \\\\textbf{F1 (W1)} \\\\\\\\\")\n",
    "    print(\"\\\\hline\")\n",
    "\n",
    "    for res in results_main:\n",
    "        offset = res['offset']\n",
    "        n_samples = len(res['y_test'])\n",
    "        acc = res['acc']\n",
    "        recall0 = res['recall0']\n",
    "        recall1 = res['recall1']\n",
    "        f1_w1 = res['f1_1']\n",
    "\n",
    "        if offset == 0:\n",
    "            label = \"0 (End)\"\n",
    "        elif offset == 2:\n",
    "            label = \"2 (End-2)\"\n",
    "        elif offset == 5:\n",
    "            label = \"5 (End-5)\"\n",
    "        else:\n",
    "            label = str(offset)\n",
    "\n",
    "        print(f\"{label:9s} & {n_samples:4d} & {acc:5.2f}\\\\% & {recall0:5.2f}\\\\% & {recall1:5.2f}\\\\% & {f1_w1:5.2f}\\\\% \\\\\\\\\")\n",
    "\n",
    "    print(\"\\\\hline\")\n",
    "    print(\"\\\\end{tabular}\")\n",
    "    print(\"\\\\caption{Test results for the required offset evaluation on $3\\\\times3$.}\")\n",
    "    print(\"\\\\label{tab:3x3-offset-results}\")\n",
    "    print(\"\\\\end{table}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ],
   "id": "d0248ff7c3c57a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === SAVE PLOTS WITH CORRECT NAMES ===\n",
    "if results_main:\n",
    "    # Learning curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for res in results_main:\n",
    "        epochs, accs = zip(*res['history']) if isinstance(res['history'][0], tuple) else (range(1, len(res['history'])+1), res['history'])\n",
    "        label_map = {0: \"End (Offset 0)\", 2: \"End-2 (Offset 2)\", 5: \"End-5 (Offset 5)\"}\n",
    "        plt.plot(epochs, accs, 'o-', label=label_map.get(res['offset'], f\"Offset {res['offset']}\"), linewidth=2)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Training Accuracy (%)\")\n",
    "    plt.title(\"Learning Curves: End vs End-2 vs End-5\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(RUNS_DIR, \"11x11_learningcurve.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion matrices\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    for i, res in enumerate(results_main):\n",
    "        sns.heatmap(res['cm'], annot=True, fmt='d', cmap='Blues', ax=axes[i], annot_kws={'size': 14})\n",
    "        label_map = {0: \"End\", 2: \"End-2\", 5: \"End-5\"}\n",
    "\n",
    "        # Fix: Extract label separately to avoid nested f-strings\n",
    "        label = label_map.get(res['offset'], f\"Offset {res['offset']}\")\n",
    "        axes[i].set_title(f\"{label} (Acc: {res['acc']:.1f}%)\")\n",
    "\n",
    "        axes[i].set_xlabel(\"Predicted\")\n",
    "        axes[i].set_ylabel(\"Actual\")\n",
    "    plt.suptitle(\"Confusion Matrices\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RUNS_DIR, \"11x11_confusionmatrix.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Capacity and Depth plots\n",
    "if 'results_capacity' in dir() and 'results_depth' in dir():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    df_cap = pd.DataFrame(results_capacity)\n",
    "    ax1.plot(df_cap['clauses'], df_cap['overall'], 'o-', color='black', linewidth=2, markersize=8, label='Overall')\n",
    "    ax1.plot(df_cap['clauses'], df_cap['winner0'], 's--', color='blue', linewidth=1.5, markersize=6, label='Winner 0')\n",
    "    ax1.plot(df_cap['clauses'], df_cap['winner1'], '^--', color='red', linewidth=1.5, markersize=6, label='Winner 1')\n",
    "    ax1.set_xlabel(\"Number of Clauses\")\n",
    "    ax1.set_ylabel(\"Accuracy (%)\")\n",
    "    ax1.set_title(\"Model Capacity\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    df_depth = pd.DataFrame(results_depth)\n",
    "    ax2.plot(df_depth['depth'], df_depth['overall'], 'o-', color='black', linewidth=2, markersize=8, label='Overall')\n",
    "    ax2.plot(df_depth['depth'], df_depth['winner0'], 's--', color='blue', linewidth=1.5, markersize=6, label='Winner 0')\n",
    "    ax2.plot(df_depth['depth'], df_depth['winner1'], '^--', color='red', linewidth=1.5, markersize=6, label='Winner 1')\n",
    "    ax2.set_xlabel(\"Message Passing Depth\")\n",
    "    ax2.set_ylabel(\"Accuracy (%)\")\n",
    "    ax2.set_title(\"Message Passing Depth\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RUNS_DIR, \"11x11_model_message.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Class gap plots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    ax1.bar(df_cap['clauses'].astype(str), df_cap['gap'], color='coral', alpha=0.7)\n",
    "    ax1.set_xlabel(\"Number of Clauses\")\n",
    "    ax1.set_ylabel(\"Class Gap (%)\")\n",
    "    ax1.set_title(\"Capacity vs Class Gap\")\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    ax2.bar(df_depth['depth'].astype(str), df_depth['gap'], color='skyblue', alpha=0.7)\n",
    "    ax2.set_xlabel(\"Message Passing Depth\")\n",
    "    ax2.set_ylabel(\"Class Gap (%)\")\n",
    "    ax2.set_title(\"Depth vs Class Gap\")\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RUNS_DIR, \"11x11_classgap_capacity_depth.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\n‚úì All plots saved to {RUNS_DIR}/\")"
   ],
   "id": "cd35955be5999178",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
